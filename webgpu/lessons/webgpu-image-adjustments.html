<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-image-adjustments.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Image Adjustments">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-image-adjustments_en.jpg">

<meta property="og:title" content="WebGPU Post Processing - Image Adjustments">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-image-adjustments_en.jpg">
<meta property="og:description" content="Image Adjustments">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Post Processing - Image Adjustments">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html">
<meta name="twitter:description" content="Image Adjustments">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-image-adjustments_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-image-adjustments_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html",
      "inLanguage":"en",
      "name":"WebGPU Post Processing - Image Adjustments",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-image-adjustments.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Post Processing - Image Adjustments</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">

<link rel="stylesheet" href="/webgpu/lessons/lang.css">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-image-adjustments.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-image-adjustments.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-image-adjustments.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-image-adjustments.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-image-adjustments.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-image-adjustments.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-image-adjustments.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-image-adjustments.html">简体中文
</option></select>


    <a href="#toc">Table of Contents</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub">
  <div>
    <div><a href="https://github.com/webgpu/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div>
  </div>
</div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Post Processing - Image Adjustments</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>This is article is the 1st in a short series
about image adjustments. Each one builds on the previous lesson so you may find
them easiest to understand by reading them in order.</p>
<ol>
<li><a href="webgpu-image-adjustments.html">Image Adjustments</a> ⬅ you are here</li>
<li><a href="webgpu-1dlut.html">1D Lookup Tables</a></li>
<li><a href="webgpu-3dlut.html">3D Lookup Tables</a></li>
</ol>
<p>In <a href="webgpu-post-processing.html">a previous article</a> we covered how to do
<a href="webgpu-post-processing.html">post processing</a>. Some common operations to
want to do are often called, image adjustments as seen in
image editing programs like Photoshop, gIMP, Affinity Photo, etc…</p>
<p>In preparation, lets make an example that load an image and has
a post processing step. This will be effectively the first part
of <a href="webgpu-post-processing.html">the previous article</a> merged
with our example of loading an image from
<a href="webgpu-importing-textures.html">the article on loading images into textures</a>.</p>
<p>Remember, in the previous post processing article, first we drew something
to a texture. Then we applied a post processing pass to get that texture
to the canvas. Here we’ll have a similar setup but for the first part, instead
of drawing a bunch of moving circles we’ll just draw an image. <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p>Here’s the shaders</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct VSOutput {
  @builtin(position) position: vec4f,
  @location(0) texcoord: vec2f,
};

struct Uniforms {
  matrix: mat4x4f,
};

@group(0) @binding(0) var&lt;uniform&gt; uni: Uniforms;
@group(0) @binding(1) var tex: texture_2d&lt;f32&gt;;
@group(0) @binding(2) var smp: sampler;

@vertex fn vs(@builtin(vertex_index) vNdx: u32) -&gt; VSOutput {
  let positions = array(
    vec2f( 0,  0),
    vec2f( 1,  0),
    vec2f( 0,  1),
    vec2f( 0,  1),
    vec2f( 1,  0),
    vec2f( 1,  1),
  );
  let pos = positions[vNdx];
  return VSOutput(
    uni.matrix * vec4f(pos, 0, 1),
    pos,
  );
}

@fragment fn fs(fsInput: VSOutput) -&gt; @location(0) vec4f {
  return textureSample(tex, smp, fsInput.texcoord);
}
</pre>
<p>This shader is hard coded to draw a unit quad, a 1x1 unit rectangle, in the top right
corner. This is effectively what we had in the first example of
<a href="webgpu-importing-textures.html">loading an image into a texture</a>. The difference
this time is we multiply quad’s positions by a matrix we pass in in a uniform buffer.
This will let us orient, position, and scale the quad.</p>
<p>Here’s the code to use it</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">import {mat4} from '../3rdparty/wgpu-matrix.module.js';

async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
  const device = await adapter?.requestDevice();
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }

  // Get a WebGPU context from the canvas and configure it
  const canvas = document.querySelector('canvas');
  const context = canvas.getContext('webgpu');
  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
  context.configure({
    device,
    format: presentationFormat,
  });

  const module = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      struct Uniforms {
        matrix: mat4x4f,
      };

      @group(0) @binding(0) var&lt;uniform&gt; uni: Uniforms;
      @group(0) @binding(1) var tex: texture_2d&lt;f32&gt;;
      @group(0) @binding(2) var smp: sampler;

      @vertex fn vs(@builtin(vertex_index) vNdx: u32) -&gt; VSOutput {
        let positions = array(
          vec2f( 0,  0),
          vec2f( 1,  0),
          vec2f( 0,  1),
          vec2f( 0,  1),
          vec2f( 1,  0),
          vec2f( 1,  1),
        );
        let pos = positions[vNdx];
        return VSOutput(
          uni.matrix * vec4f(pos, 0, 1),
          pos,
        );
      }

      @fragment fn fs(fsInput: VSOutput) -&gt; @location(0) vec4f {
        return textureSample(tex, smp, fsInput.texcoord);
      }
    `,
  });

  const pipeline = device.createRenderPipeline({
    label: 'textured unit quad',
    layout: 'auto',
    vertex: {
      module,
    },
    fragment: {
      module,
      targets: [{ format: 'rgba8unorm' }],
    },
  });

  const renderPassDescriptor = {
    label: 'our basic canvas renderPass',
    colorAttachments: [
      {
        // view: &lt;- to be filled out when we render
        clearValue: [0.3, 0.3, 0.3, 1],
        loadOp: 'clear',
        storeOp: 'store',
      },
    ],
  };

  const imageUniformBuffer = device.createBuffer({
    size: 4 * 16,  // mat4x4
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });

  const imageTexture = await createTextureFromImage(
    device,
    'resources/images/david-clode-clown-fish.jpg',
  );

  const imageSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  const imageBindGroup = device.createBindGroup({
    layout: pipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: imageUniformBuffer } },
      { binding: 1, resource: imageTexture.createView() },
      { binding: 2, resource: imageSampler },
    ],
  });

</pre>
<p>The image being loaded is by <a href="https://unsplash.com/@davidclode">David Clode</a> from <a href="https://unsplash.com/photos/orange-and-white-clown-fish-x9yfTxHpj5w">here</a>.</p>
<p>The post processing code is pretty much the same as the first post processing example.
It does nothing but we keep the a superfluous uniform struct just so we don’t have to
remove the uniform buffer setting code and add it back in the next step.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessModule = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32,
      ) -&gt; VSOutput {
        var pos = array(
          vec2f(-1.0, -1.0),
          vec2f(-1.0,  3.0),
          vec2f( 3.0, -1.0),
        );

        var vsOutput: VSOutput;
        let xy = pos[vertexIndex];
        vsOutput.position = vec4f(xy, 0.0, 1.0);
        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
        return vsOutput;
      }

      struct Uniforms {
*        unused: f32,
      };

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

      @fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
*        _ = uni; // so it's included in the bind group
        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
        var rgb = color.rgb;
        return vec4f(rgb, color.a);
      }
    `,
  });

  const postProcessPipeline = device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: postProcessModule },
    fragment: {
      module: postProcessModule,
      targets: [ { format: presentationFormat }],
    },
  });

  const postProcessSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  const postProcessRenderPassDescriptor = {
    label: 'post process render pass',
    colorAttachments: [
      { loadOp: 'clear', storeOp: 'store' },
    ],
  };

  const postProcessUniformBuffer = device.createBuffer({
    size: 16,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });

  let renderTarget;
  let postProcessBindGroup;

  function setupPostProcess(canvasTexture) {
    if (renderTarget?.width === canvasTexture.width &amp;&amp;
        renderTarget?.height === canvasTexture.height) {
      return;
    }

    renderTarget?.destroy();
    renderTarget = device.createTexture({
      size: canvasTexture,
      format: 'rgba8unorm',
      usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
    });
    const renderTargetView = renderTarget.createView();
    renderPassDescriptor.colorAttachments[0].view = renderTargetView;

    postProcessBindGroup = device.createBindGroup({
      layout: postProcessPipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: renderTargetView },
        { binding: 1, resource: postProcessSampler },
        { binding: 2, resource: { buffer: postProcessUniformBuffer } },
      ],
    });
  }

  function postProcess(encoder, srcTexture, dstTexture) {
    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }
</pre>
<p>The rendering switches from a request animation frame loop
to rendering on demand.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const canvasTexture = context.getCurrentTexture();
    setupPostProcess(canvasTexture);

*    // css 'cover'
*    const canvasAspect = canvas.clientWidth / canvas.clientHeight;
*    const imageAspect = imageTexture.width / imageTexture.height;
*    const aspect = canvasAspect / imageAspect;
*    const aspectScale = aspect &gt; 1 ? [1, aspect, 1] : [1 / aspect, 1, 1];
*
*    const matrix = mat4.identity();
*    mat4.scale(matrix, [2, 2, 1], matrix);
*    mat4.scale(matrix, aspectScale, matrix);
*    mat4.translate(matrix, [-0.5, -0.5, 1], matrix);
*
*    // Copy our the uniform values to the GPU
*    device.queue.writeBuffer(imageUniformBuffer, 0, matrix);

    // Draw the image to a texture.
    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass(renderPassDescriptor);
    pass.setPipeline(pipeline);
    pass.setBindGroup(0, imageBindGroup);
    pass.draw(6);
    pass.end();

    postProcess(encoder, renderTarget, canvasTexture);

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
  }

  const observer = new ResizeObserver(entries =&gt; {
    for (const entry of entries) {
      const canvas = entry.target;
      const width = entry.contentBoxSize[0].inlineSize;
      const height = entry.contentBoxSize[0].blockSize;
      canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
      canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));
    }
    render();
  });
  observer.observe(canvas);
</pre>
<p>The code above computes a matrix that produces a CSS style <code class="notranslate" translate="no">cover</code> mode for our image. In other words, it scales the image so the entire canvas is covered.</p>
<p>Let’s add a few tiny embellishments:</p>
<p>Let’s make it so you can drag and drop an image.
We’ll use a helper library.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+import * as dragAndDrop from './resources/js/drag-and-drop.js';

...

-  const imageTexture = await createTextureFromImage(
+  let imageTexture = await createTextureFromImage(
    device,
    'resources/images/david-clode-clown-fish.jpg',
  );

  const imageSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

-  const imageBindGroup = device.createBindGroup({
+  let imageBindGroup;
+  function updateBindGroup() {
+    imageBindGroup = device.createBindGroup({
*      layout: pipeline.getBindGroupLayout(0),
*      entries: [
*        { binding: 0, resource: { buffer: imageUniformBuffer } },
*        { binding: 1, resource: imageTexture.createView() },
*        { binding: 2, resource: imageSampler },
*      ],
*    });
+  }
+  updateBindGroup();

...

+  const gui = new GUI();
+  gui.name('Drag-n-Drop Image');
+  gui.onChange(render);

...

+  async function readImageFile(file) {
+    const newImageTexture = await createTextureFromImage(device, URL.createObjectURL(file));
+    imageTexture.destroy();
+    imageTexture = newImageTexture;
+    updateBindGroup();
+    render();
+  }
+
+  dragAndDrop.setup({msg: 'Drop Image File here'});
+  dragAndDrop.onDropFile(readImageFile);

</pre>
<p>The <code class="notranslate" translate="no">GUI</code> part is not needed but it will tell the user they can drag-and-drop an image.</p>
<p>Then, since most phone’s don’t support drag-and-drop, lets
make it so you can paste in an image. Again we’ll use a helper.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+import onPasteImage from './resources/js/on-paste-image.js';

...

  dragAndDrop.setup({msg: 'Drop Image File here'});
  dragAndDrop.onDropFile(readImageFile);

+  onPasteImage(readImageFile);
</pre>
<p>Now you should be able to select an image on your phone
and paste it into the example. Note, this will only work
if the same has the focus or if you run it in its own page.</p>
<p>Those details were maybe not important but they were small and will let you try your own images.</p>
<p>So here’s that running.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-image-adjustments-noop.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-image-adjustments-noop.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<h2 id="brightness"><a id="a-brightness"></a> Brightness</h2>
<p>Probably the easiest image adjustment is “brightness”.
Here’s another image</p>
<div class="webgpu_center center"><div data-diagram="original" data-labels="{&quot;type&quot;: &quot;original&quot;}"></div></div>
<div class="webgpu_center center"><div>
  <a href="https://unsplash.com/photos/a-happy-corgi-dog-rests-outdoors-with-tongue-out-RQFMEBJcolY">Photo</a> by <a href="https://unsplash.com/@alvannee">Alvan Nee</a>
</div></div>
<p>And here it is with a brightness adjustment</p>
<div class="webgpu_center center"><div data-diagram="brightness" data-labels="{&quot;type&quot;: &quot;brightness&quot;}"></div></div>
<p>The brightness adjustment goes from -1 to 1 where:</p>
<ul>
<li>&nbsp;0 = don’t adjust it.</li>
<li>-1 = remove 100% of the brightness.</li>
<li>+1 = make it as bright as possible <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></li>
</ul>
<p>To do this all we need to do is add the brightness setting to the color in our post processing fragment shader.</p>
<p>Here’s the change to our shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct VSOutput {
  @builtin(position) position: vec4f,
  @location(0) texcoord: vec2f,
};

+fn adjustBrightness(color: vec3f, brightness: f32) -&gt; vec3f {
+  return color + brightness;
+}

@vertex fn vs(
  @builtin(vertex_index) vertexIndex : u32,
) -&gt; VSOutput {
  var pos = array(
    vec2f(-1.0, -1.0),
    vec2f(-1.0,  3.0),
    vec2f( 3.0, -1.0),
  );

  var vsOutput: VSOutput;
  let xy = pos[vertexIndex];
  vsOutput.position = vec4f(xy, 0.0, 1.0);
  vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
  return vsOutput;
}

struct Uniforms {
-  unused: f32,
+  brightness: f32,
};

@group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
@group(0) @binding(1) var postSampler: sampler;
@group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

@fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
-  _ = uni; // so it's included in the bind group
  let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
  var rgb = color.rgb;
+  rgb = adjustBrightness(rgb, uni.brightness);
  return vec4f(rgb, color.a);
}
</pre>
<p>Then we need to set the brightness.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function postProcess(encoder, srcTexture, dstTexture) {
+    device.queue.writeBuffer(
+      postProcessUniformBuffer,
+      0,
+      new Float32Array([
+        settings.brightness,
+      ]),
+    );

    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }

+  const settings = {
+    brightness: 0,
+  };

  const gui = new GUI();
  gui.name('Drag-n-Drop Image');
  gui.onChange(render);
+  gui.add(settings, 'brightness', -1, 1);
</pre>
<p>And with that we can adjust the brightness</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-image-adjustments-brightness.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-image-adjustments-brightness.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<h1 id="contrast"><a id="a-contrast"></a> Contrast</h1>
<p>Another relatively easy one is “contrast”</p>
<div class="webgpu_center center"><div data-diagram="contrast" data-labels="{&quot;type&quot;: &quot;contrast&quot;}"></div></div>
<p>For contrast, have a value from -1 to 10 and for each
color channel, if the value is &lt; 0.5 we push it toward 0. If it’s &gt; 0.5 we push it toward one. This pushes the colors apart.</p>
<p>Here’s the changes to the shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct VSOutput {
  @builtin(position) position: vec4f,
  @location(0) texcoord: vec2f,
};

fn adjustBrightness(color: vec3f, brightness: f32) -&gt; vec3f {
  return color + brightness;
}

+fn adjustContrast(color: vec3f, contrast: f32) -&gt; vec3f {
+  let c = contrast + 1.0;
+  return clamp(0.5 + c * (color - 0.5), vec3f(0), vec3f(1));
+}

@vertex fn vs(
  @builtin(vertex_index) vertexIndex : u32,
) -&gt; VSOutput {
  var pos = array(
    vec2f(-1.0, -1.0),
    vec2f(-1.0,  3.0),
    vec2f( 3.0, -1.0),
  );

  var vsOutput: VSOutput;
  let xy = pos[vertexIndex];
  vsOutput.position = vec4f(xy, 0.0, 1.0);
  vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
  return vsOutput;
}

struct Uniforms {
  brightness: f32,
+  contrast: f32,
};

@group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
@group(0) @binding(1) var postSampler: sampler;
@group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

@fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
  let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
  var rgb = color.rgb;
  rgb = adjustBrightness(rgb, uni.brightness);
+  rgb = adjustContrast(rgb, uni.contrast);
  return vec4f(rgb, color.a);
}
</pre>
<p>You can see above we take the color and subtract 0.5.
This makes the colors that were below 0.5 to be negative
and the colors that were above 0.5 positive. We then
multiple by our contrast setting +1. So a setting of 0
will multiply by 1 (no change). We then add 0.5 back in.
When the contrast setting is below 0.5 this will push
the colors toward 0.5 and at a contrast setting of -1
they’ll all become 0.5 (gray). For contrast settings above 0
the colors will be pushed away from 0.5.</p>
<p>Again we need to make a way to set the new adjustment.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function postProcess(encoder, srcTexture, dstTexture) {
    device.queue.writeBuffer(
      postProcessUniformBuffer,
      0,
      new Float32Array([
        settings.brightness,
+        settings.contrast,
      ]),
    );

    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }

  const settings = {
    brightness: 0,
+    contrast: 0,
  };

  const gui = new GUI();
  gui.name('Drag-n-Drop Image');
  gui.onChange(render);
  gui.add(settings, 'brightness', -1, 1);
+  gui.add(settings, 'contrast', -1, 10);
</pre>
<p>Note that our setting of 10 as the maximum is a little arbitrary. Since we’re
moving the values away from 0.5 by multiplying with our contrast value, if the
color is 0.51 and the contrast is 10 then we’ll end up making the new color 0.60
(0.5 + 10 * 0.01). That’s not all the way to 1. In practice though, if you try
it below, you’ll see that even above 6 not much changes. Maybe you’d have to
pick a very low contrast image to need higher contrast values.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-image-adjustments-contrast.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-image-adjustments-contrast.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>It’s important to note these operations are order dependent. We apply brightness
and then contrast. Since contrast pushes colors away from 0.5 and brightness
adds to the overall color then, as it is, for a given brightness setting we’re
effectively choosing where the 0.5 level is in the image before the contrast is
applied.</p>
<h1 id="hue-saturation-lightness-hsl"><a id="a-hue-saturation-lightness"></a> Hue Saturation Lightness (HSL)</h1>
<p>It’s common to allow a hue, saturation, and lightness adjustment.</p>
<div class="webgpu_center center"><div data-diagram="hsl" data-labels="{&quot;h&quot;: &quot;hue&quot;, &quot;s&quot;: &quot;saturation&quot;, &quot;l&quot;: &quot;lightness&quot;}"></div></div>
<p>These adjustments generally go together which
we’ll see why when we go over how they work.</p>
<p>Recall that our colors are represented by red, green,
and blue channels, each going from 0 to 1. This can
be represented as a cube where red is one dimension,
green another, and blue a 3rd.</p>
<p>HSL takes all of those colors and maps them to a cylinder
where H is the angle around the cylinder, S is the distance
from the center with 0 being at the center (no saturation) and 1 the edge
(maximum saturation). The L is position along the length
of the cylinder were 0 is no lightness (black) and 1 is
maximum lightness (white)</p>
<p>Every color in the RGB space has a corresponding HSL value.</p>
<div class="webgpu_center center">
  <div class="rgb-hsl">
    <div data-diagram="rgbDiagram" style="max-width: 500px;" data-labels="{&quot;r&quot;: &quot;r&quot;, &quot;g&quot;: &quot;g&quot;, &quot;b&quot;: &quot;b&quot;}"></div>
    <div data-diagram="hslDiagram" style="max-width: 500px;" data-labels="{&quot;h&quot;: &quot;hue&quot;, &quot;s&quot;: &quot;saturation&quot;, &quot;l&quot;: &quot;lightness&quot;}"></div>
  </div>
</div>
<p>It’s not too difficult to convert from one space to the other. It’s actually
more difficult to explain the conversion. In any case, here’s a shader function
to convert from RGB to HSL</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct HSL {
  h: f32,
  s: f32,
  l: f32,
};

fn rgbToHsl(rgb: vec3f) -&gt; HSL {
  let cMin = min(min(rgb.r, rgb.b), rgb.g);
  let cMax = max(max(rgb.r, rgb.b), rgb.g);
  let delta = cMax - cMin;

  let l = (cMax + cMin) / 2.0;
  if (delta == 0.0) {
    return HSL(0, 0, l);
  }

  var h = 0.0;
  if (rgb.r == cMax) {
    h = (rgb.g - rgb.b) / delta;
  } else if (rgb.g == cMax) {
    h = 2.0 + (rgb.b - rgb.r) / delta;
  } else {
    h = 4.0 + (rgb.r - rgb.g) / delta;
  }
  h = h / 6.0;
  let s = delta / (1.0 - abs(2.0 * l - 1.0));
  return HSL(h, s, l);
}
</pre>
<p>This function returns a 3 values in the 0 to 1 range. We could have passed
out a <code class="notranslate" translate="no">vec3f</code> for the result but it seemed nicer to declare an <code class="notranslate" translate="no">HSL</code> struct
so the members can be referred to as <code class="notranslate" translate="no">h</code>, <code class="notranslate" translate="no">s</code>, and <code class="notranslate" translate="no">l</code> instead of <code class="notranslate" translate="no">x</code>, <code class="notranslate" translate="no">y</code>, and <code class="notranslate" translate="no">z</code>.</p>
<p>Here’s the opposite function that converts from HSL to RGB.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">fn hslToRgb(hsl: HSL) -&gt; vec3f {
  let c = vec3f(fract(hsl.h), clamp(vec2f(hsl.s, hsl.l), vec2f(0), vec2f(1)));
  let rgb = clamp(abs((c.x * 6.0 + vec3f(0.0, 4.0, 2.0)) % 6.0 - 3.0) - 1.0, vec3f(0), vec3f(1));
  return c.z + c.y * (rgb - 0.5) * (1.0 - abs(2.0 * c.z - 1.0));
}
</pre>
<p>This function clamps saturation and lightness between 0 and 1.
It also uses <code class="notranslate" translate="no">fract(hsl.h)</code> which means it’s safe to pass in any values
[~precision]. For example you could set the saturation to 50, it will
just get clamped to 1. You could set the hue to 75.3, it will be the same as 0.3.</p>
<p>Given those 2 functions we can change our shaders to include an HSL adjustment</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">...

+fn adjustHSL(color: vec3f, adjust: HSL) -&gt; vec3f {
+  let hsl = rgbToHsl(color);
+  let newHSL = HSL(hsl.h + adjust.h, hsl.s + adjust.s, hsl.l + adjust.l);
+  return hslToRgb(newHSL);
+}

...

struct Uniforms {
  brightness: f32,
  contrast: f32,
+  @align(16) hsl: HSL,
};

@group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
@group(0) @binding(1) var postSampler: sampler;
@group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

@fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
  let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
  var rgb = color.rgb;
+  rgb = adjustHSL(rgb, uni.hsl);
  rgb = adjustBrightness(rgb, uni.brightness);
  rgb = adjustContrast(rgb, uni.contrast);
  return vec4f(rgb, color.a);
}
</pre>
<p>One thing that might stick out here is the <code class="notranslate" translate="no">@align(16)</code> we needed when adding
<code class="notranslate" translate="no">HSL</code> to the <code class="notranslate" translate="no">Uniforms</code> struct. The reason we need this is because
<a href="webgpu-memory-layout.html#a-struct-array-size-alignment">structs used in uniforms, by default, must be aligned to 16 byte boundaries</a>.
Further, it means the structure is usable for both uniform and storage buffers.
If you remove the <code class="notranslate" translate="no">@align(16)</code> then it’s only useable for storage buffers. WGSL
doesn’t add this alignment automatically so that in the future the alignment
requirements can be lifted, and so the structures only need one layout. If it
didn’t require the <code class="notranslate" translate="no">@align(16)</code> now, and instead it auto aligned, then later
when restriction was removed, lots of code would break. <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>To use this we still need to update the JavaScript to set the new uniform values.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessUniformBuffer = device.createBuffer({
-    size: 16,
+    size: 32,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });

...

  function postProcess(encoder, srcTexture, dstTexture) {
    device.queue.writeBuffer(
      postProcessUniformBuffer,
      0,
      new Float32Array([
        settings.brightness,
        settings.contrast,
+        0,
+        0,
+        settings.hue,
+        settings.saturation,
+        settings.lightness,
      ]),
    );

    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }

  const settings = {
    brightness: 0,
    contrast: 0,
+    hue: 0,
+    saturation: 0,
+    lightness: 0,
  };

  const gui = new GUI();
  gui.name('Drag-n-Drop Image');
  gui.onChange(render);
  gui.add(settings, 'brightness', -1, 1);
  gui.add(settings, 'contrast', -1, 10);
+  gui.add(settings, 'hue', -0.5, 0.5);
+  gui.add(settings, 'saturation', -1, 1);
+  gui.add(settings, 'lightness', -1, 1);
</pre>
<p>And now you should be able to adjust the hue, saturation, and lightness.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-image-adjustments-hsl.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-image-adjustments-hsl.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>I hope that gave some ideas for image adjustments and post processing.
In the <a href="webgpu-1dlut.html">next article</a> we’ll use a 1d texture for
more flexibility.</p>
<!-- keep this at the bottom of the article -->
<link href="webgpu-image-adjustments.css" rel="stylesheet">
<script type="module" src="webgpu-image-adjustments.js"></script>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Technically, for image adjustments, we don’t need 2 steps. First drawing
the images into a texture, and then applying the adjustments. We could
just apply the adjustments as we draw the image. The advantage of doing
it as a separate process is we can use it in any situation, for example
a game might use post processing based image adjustments to set a tone,
to fade in and out, and for various other effects. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>HDR can go higher than 1. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>removing this restriction is <a href="https://github.com/gpuweb/gpuweb/issues/4973">already in progress</a>, at least for newer devices. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-image-adjustments.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-image-adjustments.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-image-adjustments.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-image-adjustments.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-image-adjustments.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-image-adjustments.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-image-adjustments.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-image-adjustments.html">简体中文
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
  <li>Textures</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-importing-textures.html">Loading Images</a></li>
<li><a href="/webgpu/lessons/webgpu-textures-external-video.html">Using Video</a></li>
<li><a href="/webgpu/lessons/webgpu-cube-maps.html">Cube Maps</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-textures.html">Storage Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-multisampling.html">Multisampling / MSAA</a></li>
        </ul>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-transparency.html">Transparency and Blending</a></li>
<li><a href="/webgpu/lessons/webgpu-bind-group-layouts.html">Bind Group Layouts</a></li>
<li><a href="/webgpu/lessons/webgpu-copying-data.html">Copying Data</a></li>
<li><a href="/webgpu/lessons/webgpu-limits-and-features.html">Optional Features and Limits</a></li>
<li><a href="/webgpu/lessons/webgpu-timing.html">Timing Performance</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
<li><a href="/webgpu/lessons/webgpu-compatibility-mode.html">Compatibility Mode</a></li>
        </ul>
  <li>3D Math</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-translation.html">Translation</a></li>
<li><a href="/webgpu/lessons/webgpu-rotation.html">Rotation</a></li>
<li><a href="/webgpu/lessons/webgpu-scale.html">Scale</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-math.html">Matrix Math</a></li>
<li><a href="/webgpu/lessons/webgpu-orthographic-projection.html">Orthographic Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-perspective-projection.html">Perspective Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-cameras.html">Cameras</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-stacks.html">Matrix Stacks</a></li>
<li><a href="/webgpu/lessons/webgpu-scene-graphs.html">Scene Graphs</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-large-triangle-to-cover-clip-space.html">Large Clip Space Triangle</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-environment-maps.html">Environment maps</a></li>
<li><a href="/webgpu/lessons/webgpu-skybox.html">Skyboxes</a></li>
        </ul>
  <li>Post Processing</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-post-processing.html">Basic CRT Effect</a></li>
<li><a href="/webgpu/lessons/webgpu-image-adjustments.html">Image Adjustments</a></li>
<li><a href="/webgpu/lessons/webgpu-1dlut.html">1D Lookup Table (LUT)</a></li>
<li><a href="/webgpu/lessons/webgpu-3dlut.html">3D Lookup Table (LUT)</a></li>
        </ul>
        </ul>
  <li>Compute Shaders</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-compute-shaders.html">Compute Shader Basics</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram.html">Image Histogram</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram-part-2.html">Image Histogram Part 2</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgpu/lessons/webgpu-multiple-canvases.html">Multiple Canvases</a></li>
<li><a href="/webgpu/lessons/webgpu-points.html">Points</a></li>
<li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-optimization.html">Speed and Optimization</a></li>
<li><a href="/webgpu/lessons/webgpu-debugging.html">Debugging and Errors</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl-function-reference.html">WGSL Function Reference</a></li>
<li><a href="/webgpu/lessons/resources/wgsl-offset-computer.html">WGSL Offset Computer</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/webgpu/webgpufundamentals">github</a></li>
  <li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
  <li><a href="https://webgpureport.org">WebGPUReport.org</a></li>
  <li><a href="https://web3dsurvey.com/webgpu">Web3DSurvey.com</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
<div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
<div>
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
</div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Post Processing - Image Adjustments`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/js/prettify.js"></script>
<script src="/webgpu/lessons/resources/js/lesson.js" type="module"></script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-92BFT5PE4H"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-92BFT5PE4H');
</script>






</body></html>