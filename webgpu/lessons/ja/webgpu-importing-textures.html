<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/ja/webgpu-importing-textures.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="ja"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="画像/キャンバス/ビデオをテクスチャに読み込む方法">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_ja.jpg">

<meta property="og:title" content="WebGPU テクスチャへの画像の読み込み">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_ja.jpg">
<meta property="og:description" content="画像/キャンバス/ビデオをテクスチャに読み込む方法">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU テクスチャへの画像の読み込み">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html">
<meta name="twitter:description" content="画像/キャンバス/ビデオをテクスチャに読み込む方法">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_ja.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-importing-textures_ja.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html",
      "inLanguage":"ja",
      "name":"WebGPU テクスチャへの画像の読み込み",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/ja/webgpu-importing-textures.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU テクスチャへの画像の読み込み</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">

<link rel="stylesheet" href="/webgpu/lessons/lang.css">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-importing-textures.html">English
    </option><option value="/webgpu/lessons/es/webgpu-importing-textures.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-importing-textures.html" selected="">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-importing-textures.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-importing-textures.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-importing-textures.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-importing-textures.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-importing-textures.html">简体中文
</option></select>


    <a href="#toc">目次</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/webgpu/lessons/ja/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub">
  <div>
    <div><a href="https://github.com/webgpu/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div>
  </div>
</div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU テクスチャへの画像の読み込み</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <div class="warn">この記事はGemini Code Assistによって自動翻訳されました。翻訳に問題がある場合は、お手数ですが<a href="https://github.com/webgpu/webgpufundamentals/pulls">こちら</a>からPull Requestを送信してください。</div>
<p><a href="webgpu-textures.html">前の記事</a>でテクスチャの使用に関するいくつかの基本を説明しました。この記事では、画像をテクスチャに読み込むことと、GPUでミップマップを生成することについて説明します。</p>
<p>前の記事では、<code class="notranslate" translate="no">device.createTexture</code>を呼び出してテクスチャを作成し、<code class="notranslate" translate="no">device.queue.writeTexture</code>を呼び出してテクスチャにデータを入れました。<code class="notranslate" translate="no">device.queue</code>には、画像をテクスチャにコピーできる<code class="notranslate" translate="no">device.queue.copyExternalImageToTexture</code>という別の関数があります。</p>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>を受け取ることができるので、<a href="../webgpu-textures.html#a-mag-filter">前の記事のmagFilterの例</a>を取り上げ、いくつかの画像を読み込むように変更しましょう。</p>
<p>まず、画像から<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>を取得するためのコードが必要です。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  async function loadImageBitmap(url) {
    const res = await fetch(url);
    const blob = await res.blob();
    return await createImageBitmap(blob, { colorSpaceConversion: 'none' });
  }
</pre>
<p>上記のコードは、画像のURLで<a href="https://developer.mozilla.org/en-US/docs/Web/API/fetch"><code class="notranslate" translate="no">fetch</code></a>を呼び出します。これにより<a href="https://developer.mozilla.org/en-US/docs/Web/API/Response"><code class="notranslate" translate="no">Response</code></a>が返されます。次に、それを使用して、画像ファイルのデータを不透明に表す<a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob"><code class="notranslate" translate="no">Blob</code></a>を読み込みます。次に、それを<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>を作成するための標準的なブラウザ関数である<a href="https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap"><code class="notranslate" translate="no">createImageBitmap</code></a>に渡します。ブラウザに色空間を適用しないように指示するために<code class="notranslate" translate="no">{ colorSpaceConversion: 'none' }</code>を渡します。ブラウザに色空間を適用するかどうかはあなた次第です。WebGPUでは、法線マップやハイトマップなど、色データではない画像を読み込むことがよくあります。そのような場合、ブラウザが画像内のデータをいじることは絶対に望ましくありません。</p>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>を作成するコードができたので、1つ読み込んで同じサイズのテクスチャを作成しましょう。</p>
<p>この画像を読み込みます。</p>
<div class="webgpu_center"><img src="../../resources/images/f-texture.png"></div>
<p><code class="notranslate" translate="no">F</code>の文字が入ったテクスチャは、その向きをすぐに確認できるため、良いサンプルテクスチャであると一度教わりました。</p>
<div class="webgpu_center"><img src="../resources/f-orientation.svg"></div>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const texture = device.createTexture({
-    label: 'yellow F on red',
-    size: [kTextureWidth, kTextureHeight],
-    format: 'rgba8unorm',
-    usage:
-      GPUTextureUsage.TEXTURE_BINDING |
-      GPUTextureUsage.COPY_DST,
-  });
+  const url = 'resources/images/f-texture.png';
+  const source = await loadImageBitmap(url);
+  const texture = device.createTexture({
+    label: url,
+    format: 'rgba8unorm',
+    size: [source.width, source.height],
+    usage: GPUTextureUsage.TEXTURE_BINDING |
+           GPUTextureUsage.COPY_DST |
+           GPUTextureUsage.RENDER_ATTACHMENT,
+  });
</pre>
<p><code class="notranslate" translate="no">copyExternalImageToTexture</code>では、<code class="notranslate" translate="no">GPUTextureUsage.COPY_DST</code>と<code class="notranslate" translate="no">GPUTextureUsage.RENDER_ATTACHMENT</code>の使用法フラグを含める必要があることに注意してください。</p>
<p>次に、<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>をテクスチャにコピーできます。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  device.queue.writeTexture(
-      { texture },
-      textureData,
-      { bytesPerRow: kTextureWidth * 4 },
-      { width: kTextureWidth, height: kTextureHeight },
-  );
+  device.queue.copyExternalImageToTexture(
+    { source, flipY: true },
+    { texture },
+    { width: source.width, height: source.height },
+  );
</pre>
<p><code class="notranslate" translate="no">copyExternalImageToTexture</code>のパラメータは、ソース、宛先、サイズです。ソースについては、読み込み時にテクスチャを反転させたい場合は<code class="notranslate" translate="no">flipY: true</code>を指定できます。</p>
<p>そして、それは機能します！</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import-no-mips.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import-no-mips.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<h2 id="gpuでミップを生成する"><a id="a-generating-mips-on-the-gpu"></a>GPUでミップを生成する</h2>
<p><a href="../webgpu-textures.html#a-mipmap-filter">前の記事では、ミップマップも生成しました</a>が、その場合、画像データに簡単にアクセスできました。画像を読み込むときに、その画像を2Dキャンバスに描画し、<code class="notranslate" translate="no">getImageData</code>を呼び出してデータを取得し、最後にミップを生成してアップロードすることができました。これはかなり遅くなります。また、キャンバス2Dのレンダリング方法は意図的に実装に依存するため、損失が発生する可能性もあります。</p>
<p>ミップレベルを生成したとき、バイリニア補間を行いました。これは、GPUが<code class="notranslate" translate="no">minFilter: linear</code>で行うこととまったく同じです。この機能を使用して、GPUでミップレベルを生成できます。</p>
<p><a href="../webgpu-textures.html#a-mipmap-filter">前の記事のmipmapFilterの例</a>を変更して、画像を読み込み、GPUを使用してミップを生成するようにしましょう。</p>
<p>まず、テクスチャを作成するコードを変更して、ミップレベルを作成するようにします。作成する数を把握する必要があり、次のように計算できます。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numMipLevels = (...sizes) =&gt; {
    const maxSize = Math.max(...sizes);
    return 1 + Math.log2(maxSize) | 0;
  };
</pre>
<p>これを1つ以上の数値で呼び出すと、必要なミップの数が返されます。たとえば、<code class="notranslate" translate="no">numMipLevels(123, 456)</code>は<code class="notranslate" translate="no">9</code>を返します。</p>
<blockquote>
<ul>
<li>レベル0：123、456</li>
<li>レベル1：61、228</li>
<li>レベル2：30、114</li>
<li>レベル3：15、57</li>
<li>レベル4：7、28</li>
<li>レベル5：3、14</li>
<li>レベル6：1、7</li>
<li>レベル7：1、3</li>
<li>レベル8：1、1</li>
</ul>
<p>9ミップレベル</p>
</blockquote>
<p><code class="notranslate" translate="no">Math.log2</code>は、数値を生成するために必要な2のべき乗を教えてくれます。つまり、<code class="notranslate" translate="no">Math.log2(8) = 3</code>です。なぜなら、2<sup>3</sup> = 8だからです。同じことを別の言い方をすれば、<code class="notranslate" translate="no">Math.log2</code>は、この数値を2で何回割ることができるかを教えてくれます。</p>
<blockquote>
<pre class="prettyprint showlinemods notranslate notranslate" translate="no">Math.log2(8)
          8 / 2 = 4
                  4 / 2 = 2
                          2 / 2 = 1
</pre>
</blockquote>
<p>したがって、8を2で3回割ることができます。これは、作成するミップレベルの数を計算するために必要なものです。<code class="notranslate" translate="no">Math.log2(largestSize) + 1</code>です。1は、元のサイズのミップレベル0用です。</p>
<p>したがって、適切な数のミップレベルを作成できるようになりました。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const texture = device.createTexture({
    label: url,
    format: 'rgba8unorm',
    mipLevelCount: numMipLevels(source.width, source.height),
    size: [source.width, source.height],
    usage: GPUTextureUsage.TEXTURE_BINDING |
           GPUTextureUsage.COPY_DST |
           GPUTextureUsage.RENDER_ATTACHMENT,
  });
  device.queue.copyExternalImageToTexture(
    { source, flipY: true, },
    { texture },
    { width: source.width, height: source.height },
  );
</pre>
<p>次のミップレベルを生成するには、これまで行ってきたように、既存のミップレベルから次のレベルに、<code class="notranslate" translate="no">minFilter: linear</code>でテクスチャ付きクワッドを描画します。</p>
<p>コードは次のとおりです。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const generateMips = (() =&gt; {
    let sampler;
    let module;
    const pipelineByFormat = {};

    return function generateMips(device, texture) {
      if (!module) {
        module = device.createShaderModule({
          label: 'textured quad shaders for mip level generation',
          code: `
            struct VSOutput {
              @builtin(position) position: vec4f,
              @location(0) texcoord: vec2f,
            };

            @vertex fn vs(
              @builtin(vertex_index) vertexIndex : u32
            ) -&gt; VSOutput {
              let pos = array(
                // 1番目の三角形
                vec2f( 0.0,  0.0),  // 中央
                vec2f( 1.0,  0.0),  // 右、中央
                vec2f( 0.0,  1.0),  // 中央、上

                // 2番目の三角形
                vec2f( 0.0,  1.0),  // 中央、上
                vec2f( 1.0,  0.0),  // 右、中央
                vec2f( 1.0,  1.0),  // 右、上
              );

              var vsOutput: VSOutput;
              let xy = pos[vertexIndex];
              vsOutput.position = vec4f(xy * 2.0 - 1.0, 0.0, 1.0);
              vsOutput.texcoord = vec2f(xy.x, 1.0 - xy.y);
              return vsOutput;
            }

            @group(0) @binding(0) var ourSampler: sampler;
            @group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

            @fragment fn fs(fsInput: VSOutput) -&gt; @location(0) vec4f {
              return textureSample(ourTexture, ourSampler, fsInput.texcoord);
            }
          `,
        });

        sampler = device.createSampler({
          minFilter: 'linear',
        });
      }

      if (!pipelineByFormat[texture.format]) {
        pipelineByFormat[texture.format] = device.createRenderPipeline({
          label: 'mip level generator pipeline',
          layout: 'auto',
          vertex: {
            module,
          },
          fragment: {
            module,
            targets: [{ format: texture.format }],
          },
        });
      }
      const pipeline = pipelineByFormat[texture.format];

      const encoder = device.createCommandEncoder({
        label: 'mip gen encoder',
      });

      for (let baseMipLevel = 1; baseMipLevel &lt; texture.mipLevelCount; ++baseMipLevel) {
        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: sampler },
            {
              binding: 1,
              resource: texture.createView({
                baseMipLevel: baseMipLevel - 1,
                mipLevelCount: 1,
              }),
            },
          ],
        });

        const renderPassDescriptor = {
          label: 'our basic canvas renderPass',
          colorAttachments: [
            {
              view: texture.createView({baseMipLevel, mipLevelCount: 1}),
              loadOp: 'clear',
              storeOp: 'store',
            },
          ],
        };

        const pass = encoder.beginRenderPass(renderPassDescriptor);
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);
        pass.draw(6);  // call our vertex shader 6 times
        pass.end();
      }
      const commandBuffer = encoder.finish();
      device.queue.submit([commandBuffer]);
    };
  })();
</pre>
<p>上記のコードは長く見えますが、これまでのテクスチャの例で使用してきたコードとほぼ同じです。変更点</p>
<ul>
<li>
<p>3つの変数を保持するクロージャを作成します。<code class="notranslate" translate="no">module</code>、<code class="notranslate" translate="no">sampler</code>、<code class="notranslate" translate="no">pipelineByFormat</code>です。<code class="notranslate" translate="no">module</code>と<code class="notranslate" translate="no">sampler</code>については、設定されていないかどうかを確認し、設定されていない場合は、将来保持して使用できる<code class="notranslate" translate="no">GPUSShaderModule</code>と<a href="https://developer.mozilla.org/en-US/docs/Web/API/GPUSampler"><code class="notranslate" translate="no">GPUSampler</code></a>を作成します。</p>
</li>
<li>
<p>すべての例とほぼ同じシェーダーのペアがあります。唯一の違いはこの部分です。</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-  vsOutput.position = uni.matrix * vec4f(xy, 0.0, 1.0);
-  vsOutput.texcoord = xy * vec2f(1, 50);
+  vsOutput.position = vec4f(xy * 2.0 - 1.0, 0.0, 1.0);
+  vsOutput.texcoord = vec2f(xy.x, 1.0 - xy.y);
</pre>
<p>シェーダーにあるハードコードされたクワッド位置データは0.0から1.0までなので、そのままでは、例で行ったように、描画しているテクスチャの右上4分の1しかカバーしません。領域全体をカバーする必要があるため、2を掛けて1を引くことで、-1、-1から+1、+1までのクワッドが得られます。</p>
<p>また、Yテクスチャ座標を反転させます。これは、テクスチャに描画するとき、+1、+1が右上にあるためですが、サンプリングしているテクスチャの右上がそこにあるようにしたいからです。サンプリングされたテクスチャの右上は+1、0です。</p>
</li>
<li>
<p><code class="notranslate" translate="no">pipelineByFormat</code>というオブジェクトがあり、これをテクスチャ形式へのパイプラインのマップとして使用します。これは、パイプラインが使用する形式を知る必要があるためです。</p>
</li>
<li>
<p>特定の形式のパイプラインがすでにあるかどうかを確認し、ない場合は作成します。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    if (!pipelineByFormat[texture.format]) {
      pipelineByFormat[texture.format] = device.createRenderPipeline({
        label: 'mip level generator pipeline',
        layout: 'auto',
        vertex: {
          module,
        },
        fragment: {
          module,
+          targets: [{ format: texture.format }],
        },
      });
    }
    const pipeline = pipelineByFormat[texture.format];
</pre>
<p>ここでの唯一の大きな違いは、<code class="notranslate" translate="no">targets</code>がキャンバスにレンダリングするときに使用する<code class="notranslate" translate="no">presentationFormat</code>からではなく、テクスチャの形式から設定されることです。</p>
</li>
<li>
<p>最後に、<code class="notranslate" translate="no">texture.createView</code>にいくつかのパラメータを使用します。</p>
<p>生成する必要のある各ミップレベルをループします。データが含まれている最後のミップのバインドグループを作成し、現在のミップレベルに描画するようにrenderPassDescriptorを設定します。次に、その特定のミップレベルのrenderPassをエンコードします。完了すると、すべてのミップが入力されます。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    for (let baseMipLevel = 1; baseMipLevel &lt; texture.mipLevelCount; ++baseMipLevel) {
      const bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: sampler },
+          {
+            binding: 1,
+            resource: texture.createView({
+              baseMipLevel: baseMipLevel - 1,
+              mipLevelCount: 1,
+            }),
+          },
        ],
      });

      const renderPassDescriptor = {
        label: 'our basic canvas renderPass',
        colorAttachments: [
          {
+            view: texture.createView({baseMipLevel, mipLevelCount: 1}),
            loadOp: 'clear',
            storeOp: 'store',
          },
        ],
      };

      const pass = encoder.beginRenderPass(renderPassDescriptor);
      pass.setPipeline(pipeline);
      pass.setBindGroup(0, bindGroup);
      pass.draw(6);  // call our vertex shader 6 times
      pass.end();
    }

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
</pre>
</li>
</ul>
<blockquote>
<p>注：この関数は2Dテクスチャのみを処理します。<a href="../webgpu-cube-maps.html#a-texture-helpers">キューブマップに関する記事</a>では、この関数を拡張して2D配列テクスチャとキューブマップを処理する方法について説明しています。</p>
</blockquote>
<h2 id="単純な画像読み込み関数"><a id="a-texture-helpers"></a>単純な画像読み込み関数</h2>
<p>画像をテクスチャに読み込み、ミップを生成するのを簡単にするためのサポート関数をいくつか作成しましょう。</p>
<p>これは、最初のミップレベルを更新し、オプションで画像を反転させる関数です。画像にミップレベルがある場合は、それらを生成します。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function copySourceToTexture(device, texture, source, {flipY} = {}) {
    device.queue.copyExternalImageToTexture(
      { source, flipY, },
      { texture },
      { width: source.width, height: source.height },
    );

    if (texture.mipLevelCount &gt; 1) {
      generateMips(device, texture);
    }
  }
</pre>
<p><a id="a-create-texture-from-source"></a>これは、ソース（この場合は<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>）が与えられた場合に、一致するサイズのテクスチャを作成し、前の関数を呼び出してデータで埋める関数です。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function createTextureFromSource(device, source, options = {}) {
    const texture = device.createTexture({
      format: 'rgba8unorm',
*      mipLevelCount: options.mips ? numMipLevels(source.width, source.height) : 1,
      size: [source.width, source.height],
      usage: GPUTextureUsage.TEXTURE_BINDING |
             GPUTextureUsage.COPY_DST |
             GPUTextureUsage.RENDER_ATTACHMENT,
    });
    copySourceToTexture(device, texture, source, options);
    return texture;
  }
</pre>
<p>そして、これはURLが与えられた場合に、URLを<a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>として読み込み、前の関数を呼び出してテクスチャを作成し、画像の内容で埋める関数です。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  async function createTextureFromImage(device, url, options) {
    const imgBitmap = await loadImageBitmap(url);
    return createTextureFromSource(device, imgBitmap, options);
  }
</pre>
<p>これらの設定で、<a href="../webgpu-textures.html#a-mipmap-filter">mipmapFilterサンプル</a>への唯一の大きな変更はこれです。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const textures = [
-    createTextureWithMips(createBlendedMipmap(), 'blended'),
-    createTextureWithMips(createCheckedMipmap(), 'checker'),
-  ];
+  const textures = await Promise.all([
+    await createTextureFromImage(device,
+        'resources/images/f-texture.png', {mips: true, flipY: false}),
+    await createTextureFromImage(device,
+        'resources/images/coins.jpg', {mips: true}),
+    await createTextureFromImage(device,
+        'resources/images/Granite_paving_tileable_512x512.jpeg', {mips: true}),
+  ]);
</pre>
<p>上記のコードは、上記のFテクスチャと、これらの2つのタイリングテクスチャを読み込みます。</p>
<div class="webgpu_center side-by-side">
  <div class="separate">
    <img src="../../resources/images/coins.jpg">
    <div class="copyright">
      <a href="https://renderman.pixar.com/pixar-one-thirty">CC-BY: Pixar</a>
    </div>
  </div>
  <div class="separate">
    <img src="../../resources/images/Granite_paving_tileable_512x512.jpeg">
    <div class="copyright">
       <a href="https://commons.wikimedia.org/wiki/File:Granite_paving_tileable_2048x2048.jpg">CC-BY-SA: Coyau</a>
    </div>
  </div>
</div>
<p>そして、これがそれです。</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<h2 id="キャンバスの読み込み"><a id="a-loading-canvas"></a>キャンバスの読み込み</h2>
<p><code class="notranslate" translate="no">copyExternalImageToTexture</code>は、他の<em>ソース</em>を受け取ります。もう1つは<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement"><code class="notranslate" translate="no">HTMLCanvasElement</code></a>です。これを使用して2Dキャンバスにものを描画し、その結果をWebGPUのテクスチャで取得できます。もちろん、WebGPUを使用してテクスチャに描画し、描画したばかりのテクスチャをレンダリングする他のもので使用できます。実際、ミップレベルにレンダリングし、そのミップレベルをテクスチャアタッチメントとして使用して次のミップレベルにレンダリングしたばかりです。</p>
<p>しかし、2Dキャンバスを使用すると、特定のことが簡単になる場合があります。2Dキャンバスには、比較的高レベルのAPIがあります。</p>
<p>では、まず何らかのキャンバスアニメーションを作成しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">const size = 256;
const half = size / 2;

const ctx = document.createElement('canvas').getContext('2d');
ctx.canvas.width = size;
ctx.canvas.height = size;

const hsl = (h, s, l) =&gt; `hsl(${h * 360 | 0}, ${s * 100}%, ${l * 100 | 0}%)`;

function update2DCanvas(time) {
  time *= 0.0001;
  ctx.clearRect(0, 0, size, size);
  ctx.save();
  ctx.translate(half, half);
  const num = 20;
  for (let i = 0; i &lt; num; ++i) {
    ctx.fillStyle = hsl(i / num * 0.2 + time * 0.1, 1, i % 2 * 0.5);
    ctx.fillRect(-half, -half, size, size);
    ctx.rotate(time * 0.5);
    ctx.scale(0.85, 0.85);
    ctx.translate(size / 16, 0);
  }
  ctx.restore();
}

function render(time) {
  update2DCanvas(time);
  requestAnimationFrame(render);
}
requestAnimationFrame(render);
</pre>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fcanvas-2d-animation.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../canvas-2d-animation.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<p>そのキャンバスをWebGPUに読み込むには、前の例にいくつかの変更を加えるだけで済みます。</p>
<p>適切なサイズのテクスチャを作成する必要があります。最も簡単な方法は、上記で記述したのと同じコードを使用することです。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const texture = createTextureFromSource(device, ctx.canvas, {mips: true});

  const textures = await Promise.all([
-    await createTextureFromImage(device,
-        'resources/images/f-texture.png', {mips: true, flipY: false}),
-    await createTextureFromImage(device,
-        'resources/images/coins.jpg', {mips: true}),
-    await createTextureFromImage(device,
-        'resources/images/Granite_paving_tileable_512x512.jpeg', {mips: true}),
+    texture,
  ]);
</pre>
<p>次に、<code class="notranslate" translate="no">requestAnimationFrame</code>ループに切り替え、2Dキャンバスを更新し、WebGPUにアップロードする必要があります。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  function render() {
+  function render(time) {
+    update2DCanvas(time);
+    copySourceToTexture(device, texture, ctx.canvas);

     ...


    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);

  const observer = new ResizeObserver(entries =&gt; {
    for (const entry of entries) {
      const canvas = entry.target;
      const width = entry.contentBoxSize[0].inlineSize;
      const height = entry.contentBoxSize[0].blockSize;
      canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
      canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));
-      render();
    }
  });
  observer.observe(canvas);

  canvas.addEventListener('click', () =&gt; {
    texNdx = (texNdx + 1) % textures.length;
-    render();
  });
</pre>
<p>これで、キャンバスをアップロードし、そのためのミップレベルを生成できます。</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import-canvas.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import-canvas.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<h2 id="ビデオの読み込み"><a id="a-loading-video"></a>ビデオの読み込み</h2>
<p>この方法でビデオを読み込むことは、何ら変わりありません。<code class="notranslate" translate="no">&lt;video&gt;</code>要素を作成し、前の例でキャンバスに渡したのと同じ関数に渡すことができ、マイナーな調整で機能するはずです。</p>
<p>これがビデオです。</p>
<div class="webgpu_center">
  <div>
     <video muted="" controls="" src="../../resources/videos/Golden_retriever_swimming_the_doggy_paddle-360-no-audio.webm" style="width: 720px" ;=""></video>
     <div class="copyright"><a href="https://commons.wikimedia.org/wiki/File:Golden_retriever_swimming_the_doggy_paddle.webm">CC-BY: Golden Woofs</a></div>
  </div>
</div>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a>と<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement"><code class="notranslate" translate="no">HTMLCanvasElement</code></a>の幅と高さは<code class="notranslate" translate="no">width</code>と<code class="notranslate" translate="no">height</code>プロパティですが、<a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement"><code class="notranslate" translate="no">HTMLVideoElement</code></a>の幅と高さは<code class="notranslate" translate="no">videoWidth</code>と<code class="notranslate" translate="no">videoHeight</code>にあります。したがって、その違いを処理するようにコードを更新しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  function getSourceSize(source) {
+    return [
+      source.videoWidth || source.width,
+      source.videoHeight || source.height,
+    ];
+  }

  function copySourceToTexture(device, texture, source, {flipY} = {}) {
    device.queue.copyExternalImageToTexture(
      { source, flipY, },
      { texture },
-      { width: source.width, height: source.height },
+      getSourceSize(source),
    );

    if (texture.mipLevelCount &gt; 1) {
      generateMips(device, texture);
    }
  }

  function createTextureFromSource(device, source, options = {}) {
+    const size = getSourceSize(source);
    const texture = device.createTexture({
      format: 'rgba8unorm',
-      mipLevelCount: options.mips ? numMipLevels(source.width, source.height) : 1,
-      size: [source.width, source.height],
+      mipLevelCount: options.mips ? numMipLevels(...size) : 1,
+      size,
      usage: GPUTextureUsage.TEXTURE_BINDING |
             GPUTextureUsage.COPY_DST |
             GPUTextureUsage.RENDER_ATTACHMENT,
    });
    copySourceToTexture(device, texture, source, options);
    return texture;
  }
</pre>
<p>では、ビデオ要素を設定しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const video = document.createElement('video');
  video.muted = true;
  video.loop = true;
  video.preload = 'auto';
  video.src = 'resources/videos/Golden_retriever_swimming_the_doggy_paddle-360-no-audio.webm';

  const texture = createTextureFromSource(device, video, {mips: true});
</pre>
<p>そして、レンダリング時に更新します。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  function render(time) {
-    update2DCanvas(time);
-    copySourceToTexture(device, texture, ctx.canvas);
+  function render() {
+    copySourceToTexture(device, texture, video);
</pre>
<p>ビデオの複雑な点の1つは、WebGPUに渡す前に再生が開始されるのを待つ必要があることです。最新のブラウザでは、<code class="notranslate" translate="no">video.requestVideoFrameCallback</code>を呼び出すことでこれを行うことができます。新しいフレームが利用可能になるたびに呼び出されるため、少なくとも1つのフレームが利用可能になったことを知るために使用できます。</p>
<p>フォールバックとして、時間が進むのを待って祈ることができます🙏。残念ながら、古いブラウザでは、ビデオを使用するのが安全な時期を知るのが難しいためです😅。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  function startPlayingAndWaitForVideo(video) {
+    return new Promise((resolve, reject) =&gt; {
+      video.addEventListener('error', reject);
+      if ('requestVideoFrameCallback' in video) {
+        video.requestVideoFrameCallback(resolve);
+      } else {
+        const timeWatcher = () =&gt; {
+          if (video.currentTime &gt; 0) {
+            resolve();
+          } else {
+            requestAnimationFrame(timeWatcher);
+          }
+        };
+        timeWatcher();
+      }
+      video.play().catch(reject);
+    });
+  }

  const video = document.createElement('video');
  video.muted = true;
  video.loop = true;
  video.preload = 'auto';
  video.src = 'resources/videos/Golden_retriever_swimming_the_doggy_paddle-360-no-audio.webm';
+  await startPlayingAndWaitForVideo(video);

  const texture = createTextureFromSource(device, video, {mips: true});
</pre>
<p>もう1つの複雑な点は、ビデオを開始する前にユーザーがページと対話するのを待つ必要があることです<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。再生ボタン付きのHTMLを追加しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-html" translate="no">  &lt;body&gt;
    &lt;canvas&gt;&lt;/canvas&gt;
+    &lt;div id="start"&gt;
+      &lt;div&gt;▶️&lt;/div&gt;
+    &lt;/div&gt;
  &lt;/body&gt;
</pre>
<p>そして、それを中央に配置するためのCSSです。</p>
<pre class="prettyprint showlinemods notranslate lang-css" translate="no">#start {
  position: fixed;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  display: flex;
  justify-content: center;
  align-items: center;
}
#start&gt;div {
  font-size: 200px;
  cursor: pointer;
}
</pre>
<p>次に、クリックされるのを待って非表示にする関数を記述しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  function waitForClick() {
+    return new Promise(resolve =&gt; {
+      window.addEventListener(
+        'click',
+        () =&gt; {
+          document.querySelector('#start').style.display = 'none';
+          resolve();
+        },
+        { once: true });
+    });
+  }

  const video = document.createElement('video');
  video.muted = true;
  video.loop = true;
  video.preload = 'auto';
  video.src = 'resources/videos/Golden_retriever_swimming_the_doggy_paddle-360-no-audio.webm';
+  await waitForClick();
  await startPlayingAndWaitForVideo(video);

  const texture = createTextureFromSource(device, video, {mips: true});
</pre>
<p>ビデオを一時停止する待機も追加しましょう。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const video = document.createElement('video');
  video.muted = true;
  video.loop = true;
  video.preload = 'auto';
  video.src = 'resources/videos/pexels-anna-bondarenko-5534310 (540p).mp4'; /* webgpufundamentals: url */
  await waitForClick();
  await startPlayingAndWaitForVideo(video);

+  canvas.addEventListener('click', () =&gt; {
+    if (video.paused) {
+      video.play();
+    } else {
+      video.pause();
+    }
+  });
</pre>
<p>そして、それでビデオをテクスチャで取得できるはずです。</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-simple-textured-quad-import-video.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-simple-textured-quad-import-video.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<p>1つの最適化として、ビデオが変更された場合にのみテクスチャを更新することができます。</p>
<p>例：</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const video = document.createElement('video');
  video.muted = true;
  video.loop = true;
  video.preload = 'auto';
  video.src = 'resources/videos/Golden_retriever_swimming_the_doggy_paddle-360-no-audio.webm';
  await waitForClick();
  await startPlayingAndWaitForVideo(video);

+  let alwaysUpdateVideo = !('requestVideoFrameCallback' in video);
+  let haveNewVideoFrame = false;
+  if (!alwaysUpdateVideo) {
+    function recordHaveNewFrame() {
+      haveNewVideoFrame = true;
+      video.requestVideoFrameCallback(recordHaveNewFrame);
+    }
+    video.requestVideoFrameCallback(recordHaveNewFrame);
+  }

  ...

  function render() {
+    if (alwaysUpdateVideo || haveNewVideoFrame) {
+      haveNewVideoFrame = false;
      copySourceToTexture(device, texture, video);
+    }

    ...
</pre>
<p>この変更により、新しいフレームごとにビデオのみを更新します。したがって、たとえば、表示レートが120フレーム/秒のデバイスでは、120フレーム/秒で描画するため、アニメーション、カメラの動きなどはスムーズになります。しかし、ビデオテクスチャ自体は、独自のフレームレート（たとえば30fps）でのみ更新されます。</p>
<p><strong>しかし！WebGPUには、ビデオを効率的に使用するための特別なサポートがあります。</strong></p>
<p>これについては、<a href="webgpu-textures-external-video.html">別の記事</a>で説明します。上記の方法では、<code class="notranslate" translate="no">device.query.copyExternalImageToTexture</code>を使用すると、実際には<strong>コピー</strong>が作成されます。コピーには時間がかかります。たとえば、4Kビデオの解像度は通常3840×2160であり、<code class="notranslate" translate="no">rgba8unorm</code>の場合、<strong>フレームごとに</strong>31メガバイトのデータをコピーする必要があります。<a href="webgpu-textures-external-video.html">外部テクスチャ</a>を使用すると、ビデオのデータを直接使用できます（コピーなし）が、異なるメソッドが必要であり、いくつかの制限があります。</p>
<h2 id="テクスチャアトラス"><a id="a-texture-atlases"></a>テクスチャアトラス</h2>
<p>上記の例から、テクスチャで何かを描画するには、テクスチャを作成し、データを入れ、サンプラーでバインドグループにバインドし、シェーダーから参照する必要があることがわかります。では、オブジェクトに複数の異なるテクスチャを描画したい場合はどうすればよいでしょうか？脚と背もたれが木でできていて、クッションが布でできている椅子があったとします。</p>
<div class="webgpu_center">
  <div class="center">
    <model-viewer src="../resources/models/gltf/cc0_chair.glb" camera-controls="" touch-action="pan-y" camera-orbit="45deg 70deg 2.5m" interaction-prompt="none" disable-zoom="" disable-pan="" style="width: 400px; height: 400px;"></model-viewer>
  </div>
  <div>
    <a href="https://skfb.ly/opnwY"></a>"[CC0] Chair" by adadadad5252341 <a href="http://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>
  </div>
</div>
<p>または、タイヤがゴムで、ボディが塗装で、バンパーとハブキャップがクロムの車です。</p>
<div class="webgpu_center">
  <div class="center">
    <model-viewer src="../resources/models/gltf/classic_muscle_car.glb" camera-controls="" touch-action="pan-y" camera-orbit="45deg 70deg 20m" interaction-prompt="none" disable-zoom="" disable-pan="" style="width: 700px; height: 400px;"></model-viewer>
  </div>
  <div>
    <a href="https://skfb.ly/6Usqo"></a>"Classic Muscle car" by Lexyc16 <a href="http://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>
  </div>
</div>
<p>他に何もしなければ、椅子には2回描画する必要があると思うかもしれません。1回は木製のテクスチャで木材を描画し、もう1回は布製のテクスチャでクッションを描画します。車の場合は、タイヤ、ボディ、バンパーなど、いくつかの描画が必要になります。</p>
<p>すべてのオブジェクトに複数の描画呼び出しが必要になるため、これは遅くなります。シェーダーにさらに多くの入力（2、3、4つのテクスチャ）とそれぞれのテクスチャ座標を追加することで、これを修正しようとすることができますが、これはあまり柔軟ではなく、4つのテクスチャすべてを読み取り、それらの間で選択するコードを追加する必要があるため、遅くなります。</p>
<p>このケースをカバーする最も一般的な方法は、<a href="https://www.google.com/search?q=texture+atlas">テクスチャアトラス</a>と呼ばれるものを使用することです。テクスチャアトラスは、複数の画像を含むテクスチャの派手な名前です。次に、テクスチャ座標を使用して、どの部分がどこに行くかを選択します。</p>
<p>これらの6つの画像でキューブをラップしましょう。</p>
<div class="webgpu_table_div_center">
  <style>
    table.webgpu_table_center {
      border-spacing: 0.5em;
      border-collapse: separate;
    }
    table.webgpu_table_center img {
      display:block;
    }
  </style>
  <table class="webgpu_table_center">
    <tbody><tr><td><img src="../resources/noodles-01.jpg"></td><td><img src="../resources/noodles-02.jpg"></td></tr>
    <tr><td><img src="../resources/noodles-03.jpg"></td><td><img src="../resources/noodles-04.jpg"></td></tr>
    <tr><td><img src="../resources/noodles-05.jpg"></td><td><img src="../resources/noodles-06.jpg"></td></tr>
  </tbody></table>
</div>
<p>Photoshopや<a href="https://photopea.com">Photopea</a>などの画像編集ソフトウェアを使用して、6つの画像をすべて1つの画像に入れることができます。</p>
<img class="webgpu_center" src="../../resources/images/noodles.jpg">
<p>次に、キューブを作成し、画像の各部分をキューブの特定の面に選択するテクスチャ座標を提供します。簡単にするために、上記のテクスチャの6つの画像をすべて4x2の正方形に入れました。したがって、各正方形のテクスチャ座標を計算するのは非常に簡単なはずです。</p>
<div class="webgpu_center center diagram">
  <div>
    <div data-diagram="texture-atlas" style="display: inline-block; width: 600px;"></div>
  </div>
</div>
<blockquote>
<p>上の図は、テクスチャ座標の0,0が左下隅であることがよく示唆されているため、紛らわしいかもしれません。しかし、実際には「下」はありません。テクスチャ座標0,0がテクスチャのデータの最初のピクセルを参照するという考え方だけです。テクスチャのデータの最初のピクセルは、画像の左上隅です。0,0 = 左下という考え方に従うと、テクスチャ座標は次のようになります。<strong>それらはまだ同じ座標です</strong>。</p>
</blockquote>
<div class="webgpu_center center diagram">
  <div>
    <div data-diagram="texture-atlas-bottom-left" style="display: inline-block; width: 600px;"></div>
    <div class="center">左下に0,0</div>
  </div>
</div>
<p>これは、キューブの位置頂点と、それらに付随するテクスチャ座標です。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function createCubeVertices() {
  const vertexData = new Float32Array([
     //  位置   |  テクスチャ座標
     //-------------+----------------------
     // 前面     左上の画像を選択
    -1,  1,  1,        0   , 0  ,
    -1, -1,  1,        0   , 0.5,
     1,  1,  1,        0.25, 0  ,
     1, -1,  1,        0.25, 0.5,
     // 右面     中央上の画像を選択
     1,  1, -1,        0.25, 0  ,
     1,  1,  1,        0.5 , 0  ,
     1, -1, -1,        0.25, 0.5,
     1, -1,  1,        0.5 , 0.5,
     // 背面      右上の画像を選択
     1,  1, -1,        0.5 , 0  ,
     1, -1, -1,        0.5 , 0.5,
    -1,  1, -1,        0.75, 0  ,
    -1, -1, -1,        0.75, 0.5,
    // 左面       左下の画像を選択
    -1,  1,  1,        0   , 0.5,
    -1,  1, -1,        0.25, 0.5,
    -1, -1,  1,        0   , 1  ,
    -1, -1, -1,        0.25, 1  ,
    // 底面     中央下の画像を選択
     1, -1,  1,        0.25, 0.5,
    -1, -1,  1,        0.5 , 0.5,
     1, -1, -1,        0.25, 1  ,
    -1, -1, -1,        0.5 , 1  ,
    // 上面        右下の画像を選択
    -1,  1,  1,        0.5 , 0.5,
     1,  1,  1,        0.75, 0.5,
    -1,  1, -1,        0.5 , 1  ,
     1,  1, -1,        0.75, 1  ,

  ]);

  const indexData = new Uint16Array([
     0,  1,  2,  2,  1,  3,  // 前
     4,  5,  6,  6,  5,  7,  // 右
     8,  9, 10, 10,  9, 11,  // 後
    12, 13, 14, 14, 13, 15,  // 左
    16, 17, 18, 18, 17, 19,  // 下
    20, 21, 22, 22, 21, 23,  // 上
  ]);

  return {
    vertexData,
    indexData,
    numVertices: indexData.length,
  };
}
</pre>
<p>この例を作成するには、<a href="webgpu-cameras.html">カメラに関する記事</a>の例から始める必要があります。まだ記事を読んでいない場合は、それを読んで、それが一部であるシリーズを読んで3Dを行う方法を学ぶことができます。今のところ、重要な部分は、上記で行ったように、頂点シェーダーから位置とテクスチャ座標を出力し、それらを使用してフラグメントシェーダーのテクスチャから値を検索することです。したがって、カメラの例のシェーダーに必要な変更を次に示します。上記を適用します。</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct Uniforms {
  matrix: mat4x4f,
};

struct Vertex {
  @location(0) position: vec4f,
-  @location(1) color: vec4f,
+  @location(1) texcoord: vec2f,
};

struct VSOutput {
  @builtin(position) position: vec4f,
-  @location(0) color: vec4f,
+  @location(0) texcoord: vec2f,
};

@group(0) @binding(0) var&lt;uniform&gt; uni: Uniforms;
+@group(0) @binding(1) var ourSampler: sampler;
+@group(0) @binding(2) var ourTexture: texture_2d&lt;f32&gt;;

@vertex fn vs(vert: Vertex) -&gt; VSOutput {
  var vsOut: VSOutput;
  vsOut.position = uni.matrix * vert.position;
-  vsOut.color = vert.color;
+  vsOut.texcoord = vert.texcoord;
  return vsOut;
}

@fragment fn fs(vsOut: VSOutput) -&gt; @location(0) vec4f {
-  return vsOut.color;
+  return textureSample(ourTexture, ourSampler, vsOut.texcoord);
}
</pre>
<p>行ったのは、頂点ごとの色から頂点ごとのテクスチャ座標に切り替え、そのテクスチャ座標をフラグメントシェーダーに渡すことだけです。上記で行ったようにです。次に、上記で行ったように、フラグメントシェーダーでそれを使用します。</p>
<p>JavaScriptでは、その例のパイプラインを、色を受け取るものからテクスチャ座標を受け取るものに変更する必要があります。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const pipeline = device.createRenderPipeline({
    label: '2 attributes',
    layout: 'auto',
    vertex: {
      module,
      buffers: [
        {
-          arrayStride: (4) * 4, // (3) floats 4 bytes each + one 4 byte color
+          arrayStride: (3 + 2) * 4, // (3+2) floats 4 bytes each
          attributes: [
            {shaderLocation: 0, offset: 0, format: 'float32x3'},  // position
-            {shaderLocation: 1, offset: 12, format: 'unorm8x4'},  // color
+            {shaderLocation: 1, offset: 12, format: 'float32x2'},  // texcoord
          ],
        },
      ],
    },
    fragment: {
      module,
      targets: [{ format: presentationFormat }],
    },
    primitive: {
      cullMode: 'back',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'less',
      format: 'depth24plus',
    },
  });
</pre>
<p>データを小さく保つために、<a href="webgpu-vertex-buffers.html">頂点バッファに関する記事</a>で説明したようにインデックスを使用します。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const { vertexData, numVertices } = createFVertices();
+  const { vertexData, indexData, numVertices } = createCubeVertices();
  const vertexBuffer = device.createBuffer({
    label: 'vertex buffer vertices',
    size: vertexData.byteLength,
    usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
  });
  device.queue.writeBuffer(vertexBuffer, 0, vertexData);

+  const indexBuffer = device.createBuffer({
+    label: 'index buffer',
+    size: vertexData.byteLength,
+    usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST,
+  });
+  device.queue.writeBuffer(indexBuffer, 0, indexData);
</pre>
<p>この例にテクスチャの読み込みとミップ生成のすべてのコードをコピーし、それを使用してテクスチャアトラス画像を読み込む必要があります。また、サンプラーを作成し、それらをバインドグループに追加する必要があります。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const texture = await createTextureFromImage(device,
+      'resources/images/noodles.jpg', {mips: true, flipY: false});
+
+  const sampler = device.createSampler({
+    magFilter: 'linear',
+    minFilter: 'linear',
+    mipmapFilter: 'linear',
+  });

  const bindGroup = device.createBindGroup({
    label: 'bind group for object',
    layout: pipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: uniformBuffer }},
+      { binding: 1, resource: sampler },
+      { binding: 2, resource: texture.createView() },
    ],
  });
</pre>
<p>3Dで描画するための行列を設定するために、いくつかの3D数学を行う必要があります。（繰り返しになりますが、3D数学の詳細については、<a href="webgpu-cameras.html">カメラに関する記事</a>を参照してください。）</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const degToRad = d =&gt; d * Math.PI / 180;

  const settings = {
    rotation: [degToRad(20), degToRad(25), degToRad(0)],
  };

  const radToDegOptions = { min: -360, max: 360, step: 1, converters: GUI.converters.radToDeg };

  const gui = new GUI();
  gui.onChange(render);
  gui.add(settings.rotation, '0', radToDegOptions).name('rotation.x');
  gui.add(settings.rotation, '1', radToDegOptions).name('rotation.y');
  gui.add(settings.rotation, '2', radToDegOptions).name('rotation.z');

  ...

  function render() {

    ...

    const aspect = canvas.clientWidth / canvas.clientHeight;
    mat4.perspective(
        60 * Math.PI / 180,
        aspect,
        0.1,      // zNear
        10,      // zFar
        matrixValue,
    );
    const view = mat4.lookAt(
      [0, 1, 5],  // camera position
      [0, 0, 0],  // target
      [0, 1, 0],  // up
    );
    mat4.multiply(matrixValue, view, matrixValue);
    mat4.rotateX(matrixValue, settings.rotation[0], matrixValue);
    mat4.rotateY(matrixValue, settings.rotation[1], matrixValue);
    mat4.rotateZ(matrixValue, settings.rotation[2], matrixValue);

    // upload the uniform values to the uniform buffer
    device.queue.writeBuffer(uniformBuffer, 0, uniformValues);
</pre>
<p>そして、レンダリング時にインデックスで描画する必要があります。</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass(renderPassDescriptor);
    pass.setPipeline(pipeline);
    pass.setVertexBuffer(0, vertexBuffer);
+    pass.setIndexBuffer(indexBuffer, 'uint16');

    ...

    pass.setBindGroup(0, bindGroup);
-    pass.draw(numVertices);
+    pass.drawIndexed(numVertices);

    pass.end();
</pre>
<p>そして、単一のテクスチャを使用して、各面に異なる画像を持つキューブが得られます。</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-texture-atlas.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-texture-atlas.html" target="_blank">クリックして別のウインドウを開く</a>
</div>

<p></p>
<p>テクスチャアトラスを使用すると、読み込むテクスチャが1つだけで、シェーダーは1つのテクスチャを参照するだけで済むため、単純なままであり、画像を別々に保持する場合のようにテクスチャごとに1回の描画呼び出しではなく、形状を描画するために1回の描画呼び出ししか必要としないため、優れています。</p>
<!-- この記事の最後にこれを保持してください -->
<script type="module" src="/3rdparty/model-viewer.3.3.0.min.js"></script>
<script type="module" src="../webgpu-importing-textures.js"></script>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>通常は音声なしで、ユーザーがページと対話するのを待たずにビデオを自動再生させるさまざまな方法があります。それらは時間とともに変化するようなので、ここでは解決策については説明しません。 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-importing-textures.html">English
    </option><option value="/webgpu/lessons/es/webgpu-importing-textures.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-importing-textures.html" selected="">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-importing-textures.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-importing-textures.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-importing-textures.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-importing-textures.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-importing-textures.html">简体中文
</option></select>


        <div id="toc">
          <ul>  <li>基本</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-fundamentals.html">基本</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-inter-stage-variables.html">inter-stage変数</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-uniforms.html">ユニフォーム</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-storage-buffers.html">ストレージバッファ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-vertex-buffers.html">頂点バッファ</a></li>
  <li>テクスチャ</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-textures.html">テクスチャ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-importing-textures.html">画像の読み込み</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-textures-external-video.html">ビデオの使用</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-cube-maps.html">キューブマップ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-storage-textures.html">ストレージテクスチャ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-multisampling.html">マルチサンプリング / MSAA</a></li>
        </ul>
<li><a href="/webgpu/lessons/ja/webgpu-constants.html">定数</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-memory-layout.html">構造体とメモリレイアウト</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-transparency.html">透明度とブレンディング</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-bind-group-layouts.html">バインドグループレイアウト</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-copying-data.html">データのコピー</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-limits-and-features.html">オプション機能と制限</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-timing.html">タイミングパフォーマンス</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-how-it-works.html">仕組み</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-compatibility-mode.html">互換モード</a></li>
        </ul>
  <li>3Dの数学</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-translation.html">平行移動</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-rotation.html">回転</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-scale.html">スケール</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-matrix-math.html">行列演算</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-orthographic-projection.html">正射影</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-perspective-projection.html">透視投影</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-cameras.html">カメラ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-matrix-stacks.html">行列スタック</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-scene-graphs.html">シーングラフ</a></li>
        </ul>
  <li>ライト</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-lighting-directional.html">指向性ライティング</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-lighting-point.html">点光源</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-lighting-spot.html">スポットライト</a></li>
        </ul>
  <li>テクニック</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-large-triangle-to-cover-clip-space.html">大きなクリップ空間の三角形</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-environment-maps.html">環境マップ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-skybox.html">スカイボックス</a></li>
        </ul>
  <li>ポストプロセッシング</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-post-processing.html">基本的なCRTエフェクト</a></li>
        </ul>
        </ul>
  <li>コンピュートシェーダ</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-compute-shaders.html">コンピュートシェーダーの基本</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-compute-shaders-histogram.html">画像ヒストグラム</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-compute-shaders-histogram-part-2.html">画像ヒストグラム パート2</a></li>
        </ul>
  <li>その他のトピック</li>
        <ul>
          <li><a href="/webgpu/lessons/ja/webgpu-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-multiple-canvases.html">複数のキャンバス</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-points.html">ポイント</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-from-webgl.html">WebGLからWebGPUへ</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-optimization.html">速度と最適化</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-debugging.html">デバッグとエラー</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-resources.html">リソース / 参考文献</a></li>
<li><a href="/webgpu/lessons/ja/webgpu-wgsl-function-reference.html">WGSL 関数リファレンス</a></li>
<li><a href="/webgpu/lessons/resources/wgsl-offset-computer.html">WGSL オフセット計算機</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/webgpu/webgpufundamentals">github</a></li>
  <li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
  <li><a href="https://webgpureport.org">WebGPUReport.org</a></li>
  <li><a href="https://web3dsurvey.com/webgpu">Web3DSurvey.com</a></li>
</ul>
        </div>
    </div>
    <div class="lesson-comments">
        <div>問題点/バグ? <a href="https://github.com/webgpu/webgpufundamentals/issues">githubでissueを作成</a>.</div>

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU テクスチャへの画像の読み込み`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js" type="module"></script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-92BFT5PE4H"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-92BFT5PE4H');
</script>






</body></html>