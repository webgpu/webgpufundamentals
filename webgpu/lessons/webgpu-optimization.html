<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-optimization.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to go faster in WebGPU">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-optimization_en.jpg">

<meta property="og:title" content="WebGPU Speed and Optimization">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-optimization_en.jpg">
<meta property="og:description" content="How to go faster in WebGPU">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Speed and Optimization">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html">
<meta name="twitter:description" content="How to go faster in WebGPU">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-optimization_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-optimization_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html",
      "inLanguage":"en",
      "name":"WebGPU Speed and Optimization",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-optimization.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Speed and Optimization</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">

<link rel="stylesheet" href="/webgpu/lessons/lang.css">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-optimization.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-optimization.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-optimization.html">Êó•Êú¨Ë™û
    </option><option value="/webgpu/lessons/ko/webgpu-optimization.html">ÌïúÍµ≠Ïñ¥
    </option><option value="/webgpu/lessons/ru/webgpu-optimization.html">–†—É—Å—Å–∫–∏–π
    </option><option value="/webgpu/lessons/uk/webgpu-optimization.html">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
    </option><option value="/webgpu/lessons/zh_cn/webgpu-optimization.html">ÁÆÄ‰Ωì‰∏≠Êñá
</option></select>


    <a href="#toc">Table of Contents</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub">
  <div>
    <div><a href="https://github.com/webgpu/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div>
  </div>
</div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Speed and Optimization</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>Most of the examples on this site are written to be as understandable as
possible. That means they work, and they‚Äôre correct, but they don‚Äôt necessarily
show the most efficient way to do something in WebGPU. Further, depending on
what you need to do, there are a myriad of possible optimizations.</p>
<p>In this article will cover some of the most basic optimizations and discuss a
few others. To be clear, IMO, <strong>you don‚Äôt usually need to go this far. Most of
the examples around the net using WebGPU draw a couple of hundred things and so
really wouldn‚Äôt benefit from these optimizations</strong>. Still, it‚Äôs always good to
know how to make things go faster.</p>
<p>The basics: <strong>The less work you do, and the less work you ask WebGPU to do the
faster things will go.</strong></p>
<p>In pretty much all of the examples to date, if we draw multiple shapes we‚Äôve
done the following steps</p>
<ul>
<li>
<p>At Init time:</p>
<ul>
<li>for each thing we want to draw
<ul>
<li>create a uniform buffer</li>
<li>create a bindGroup that references that buffer</li>
</ul>
</li>
</ul>
</li>
<li>
<p>At Render time:</p>
<ul>
<li>start an encoder and render pass</li>
<li>for each thing we want to draw
<ul>
<li>update a typed array with our uniform values for this object</li>
<li>copy the typed array to the uniform buffer for this object</li>
<li>set any pipeline, vertex and index buffers if needed</li>
<li>encode a command(s) to bind the bindGroup(s) for this object</li>
<li>encode a command to draw</li>
</ul>
</li>
<li>end the render pass, finish the encoder, submit the command buffer</li>
</ul>
</li>
</ul>
<p>Let‚Äôs make an example we can optimize that follows the steps above so we can
then optimize it.</p>
<p>Note, this a fake example. We are only going to draw a bunch of cubes and as
such we could certainly optimize things by using <em>instancing</em> which we covered
in the articles on <a href="webgpu-storage-buffers.html#a-instancing">storage buffers</a>
and <a href="webgpu-vertex-buffers.html#a-instancing">vertex buffers</a>. I didn‚Äôt want to
clutter the code by handling tons of different kinds of objects. Instancing is
certainly a great way to optimize if your project uses lots of the same model.
Plants, trees, rocks, trash, etc are often optimized by using instancing. For
other models, it‚Äôs arguably less common.</p>
<p>For example a table might have 4, 6 or 8 chairs around it and it would probably
be faster to use instancing to draw those chairs, except in a list of 500+
things to draw, if the chairs are the only exceptions, then it‚Äôs probably not
worth the effort to figure out some optimal data organization that some how
organizes the chairs to use instancing but finds no other situations to use
instancing.</p>
<p>The point of the paragraph above is, use instancing when it‚Äôs appropriate. If
you are going to draw hundreds or more of the same thing than instancing is
probably appropriate. If you are going to only draw a few of the same thing then
it‚Äôs probably not worth the effort to special case those few things.</p>
<p>In any case, here‚Äôs our code. We‚Äôve got the initialization code we‚Äôve been using
in general.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const adapter = await navigator.gpu?.requestAdapter({
    powerPreference: 'high-performance',
  });
  const device = await adapter?.requestDevice();
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }

  // Get a WebGPU context from the canvas and configure it
  const canvas = document.querySelector('canvas');
  const context = canvas.getContext('webgpu');
  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
  context.configure({
    device,
    format: presentationFormat,
  });
</pre>
<p>Then let‚Äôs make a shader module.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const module = device.createShaderModule({
    code: `
      struct Uniforms {
        normalMatrix: mat3x3f,
        viewProjection: mat4x4f,
        world: mat4x4f,
        color: vec4f,
        lightWorldPosition: vec3f,
        viewWorldPosition: vec3f,
        shininess: f32,
      };

      struct Vertex {
        @location(0) position: vec4f,
        @location(1) normal: vec3f,
        @location(2) texcoord: vec2f,
      };

      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) normal: vec3f,
        @location(1) surfaceToLight: vec3f,
        @location(2) surfaceToView: vec3f,
        @location(3) texcoord: vec2f,
      };

      @group(0) @binding(0) var diffuseTexture: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var diffuseSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

      @vertex fn vs(vert: Vertex) -&gt; VSOutput {
        var vsOut: VSOutput;
        vsOut.position = uni.viewProjection * uni.world * vert.position;

        // Orient the normals and pass to the fragment shader
        vsOut.normal = uni.normalMatrix * vert.normal;

        // Compute the world position of the surface
        let surfaceWorldPosition = (uni.world * vert.position).xyz;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
        vsOut.surfaceToLight = uni.lightWorldPosition - surfaceWorldPosition;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
        vsOut.surfaceToView = uni.viewWorldPosition - surfaceWorldPosition;

        // Pass the texture coord on to the fragment shader
        vsOut.texcoord = vert.texcoord;

        return vsOut;
      }

      @fragment fn fs(vsOut: VSOutput) -&gt; @location(0) vec4f {
        // Because vsOut.normal is an inter-stage variable 
        // it's interpolated so it will not be a unit vector.
        // Normalizing it will make it a unit vector again
        let normal = normalize(vsOut.normal);

        let surfaceToLightDirection = normalize(vsOut.surfaceToLight);
        let surfaceToViewDirection = normalize(vsOut.surfaceToView);
        let halfVector = normalize(
          surfaceToLightDirection + surfaceToViewDirection);

        // Compute the light by taking the dot product
        // of the normal with the direction to the light
        let light = dot(normal, surfaceToLightDirection);

        var specular = dot(normal, halfVector);
        specular = select(
            0.0,                           // value if condition is false
            pow(specular, uni.shininess),  // value if condition is true
            specular &gt; 0.0);               // condition

        let diffuse = uni.color * textureSample(diffuseTexture, diffuseSampler, vsOut.texcoord);
        // Lets multiply just the color portion (not the alpha)
        // by the light
        let color = diffuse.rgb * light + specular;
        return vec4f(color, diffuse.a);
      }
    `,
  });
</pre>
<p>This shader module is uses lighting similar to
<a href="webgpu-lighting-point.html#a-specular">the point light with specular highlights covered else where</a>.
It uses a texture because most 3d models use textures so I thought it best to include one.
It multiplies the texture by a color so we can adjust the colors of each cube.
And it has all of the uniform values we need to do the lighting and
<a href="webgpu-perspective-projection.html">project the cube in 3d</a>.</p>
<p>We need data for a cube and to put that data in buffers.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function createBufferWithData(device, data, usage) {
    const buffer = device.createBuffer({
      size: data.byteLength,
      usage: usage | GPUBufferUsage.COPY_DST,
    });
    device.queue.writeBuffer(buffer, 0, data);
    return buffer;
  }

  const positions = new Float32Array([1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]);
  const normals   = new Float32Array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1]);
  const texcoords = new Float32Array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]);
  const indices   = new Uint16Array([0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23]);

  const positionBuffer = createBufferWithData(device, positions, GPUBufferUsage.VERTEX);
  const normalBuffer = createBufferWithData(device, normals, GPUBufferUsage.VERTEX);
  const texcoordBuffer = createBufferWithData(device, texcoords, GPUBufferUsage.VERTEX);
  const indicesBuffer = createBufferWithData(device, indices, GPUBufferUsage.INDEX);
  const numVertices = indices.length;
</pre>
<p>We need a render pipeline</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const pipeline = device.createRenderPipeline({
    label: 'textured model with point light w/specular highlight',
    layout: 'auto',
    vertex: {
      module,
      buffers: [
        // position
        {
          arrayStride: 3 * 4, // 3 floats
          attributes: [
            {shaderLocation: 0, offset: 0, format: 'float32x3'},
          ],
        },
        // normal
        {
          arrayStride: 3 * 4, // 3 floats
          attributes: [
            {shaderLocation: 1, offset: 0, format: 'float32x3'},
          ],
        },
        // uvs
        {
          arrayStride: 2 * 4, // 2 floats
          attributes: [
            {shaderLocation: 2, offset: 0, format: 'float32x2'},
          ],
        },
      ],
    },
    fragment: {
      module,
      targets: [{ format: presentationFormat }],
    },
    primitive: {
      cullMode: 'back',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'less',
      format: 'depth24plus',
    },
  });
</pre>
<p>The pipeline above uses 1 buffer per attribute. One for position data, one for
normal data, and one for texture coordinates (UVs). It culls back facing
triangles, and it expects a depth texture for depth testing. All things we‚Äôve
covered in other articles.</p>
<p>Let‚Äôs insert a few utilities for making colors and random numbers.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">/** Given a css color string, return an array of 4 values from 0 to 255 */
const cssColorToRGBA8 = (() =&gt; {
  const canvas = new OffscreenCanvas(1, 1);
  const ctx = canvas.getContext('2d', {willReadFrequently: true});
  return cssColor =&gt; {
    ctx.clearRect(0, 0, 1, 1);
    ctx.fillStyle = cssColor;
    ctx.fillRect(0, 0, 1, 1);
    return Array.from(ctx.getImageData(0, 0, 1, 1).data);
  };
})();

/** Given a css color string, return an array of 4 values from 0 to 1 */
const cssColorToRGBA = cssColor =&gt; cssColorToRGBA8(cssColor).map(v =&gt; v / 255);

/**
 * Given hue, saturation, and luminance values in the range of 0 to 1
 * return the corresponding CSS hsl string
 */
const hsl = (h, s, l) =&gt; `hsl(${h * 360 | 0}, ${s * 100}%, ${l * 100 | 0}%)`;

/**
 * Given hue, saturation, and luminance values in the range of 0 to 1
 * returns an array of 4 values from 0 to 1
 */
const hslToRGBA = (h, s, l) =&gt; cssColorToRGBA(hsl(h, s, l));

/**
 * Returns a random number between min and max.
 * If min and max are not specified, returns 0 to 1
 * If max is not specified, return 0 to min.
 */
function rand(min, max) {
  if (min === undefined) {
    max = 1;
    min = 0;
  } else if (max === undefined) {
    max = min;
    min = 0;
  }
  return Math.random() * (max - min) + min;
}

/** Selects a random array element */
const randomArrayElement = arr =&gt; arr[Math.random() * arr.length | 0];
</pre>
<p>Hopefully they are all pretty straight forward.</p>
<p>Now let‚Äôs make some textures and a sampler. We‚Äôll use
a canvas, draw an emoji on it, and then use our function
<code class="notranslate" translate="no">createTextureFromSource</code> that we wrote in
<a href="webgpu-importing-textures.html">the article on importing textures</a>
to create a texture from it.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const textures = [
    'üòÇ', 'üëæ', 'üëç', 'üëÄ', 'üåû', 'üõü',
  ].map(s =&gt; {
    const size = 128;
    const ctx = new OffscreenCanvas(size, size).getContext('2d');
    ctx.fillStyle = '#fff';
    ctx.fillRect(0, 0, size, size);
    ctx.font = `${size * 0.9}px sans-serif`;
    ctx.textAlign = 'center';
    ctx.textBaseline = 'middle';
    ctx.fillText(s, size / 2, size / 2);
    return createTextureFromSource(device, ctx.canvas, {mips: true});
  });

  const sampler = device.createSampler({
    magFilter: 'linear',
    minFilter: 'linear',
    mipmapFilter: 'nearest',
  });
</pre>
<p>Let‚Äôs create a set of material info. We haven‚Äôt done this anywhere else but it‚Äôs
a common setup. Unity, Unreal, Blender, Three.js, Babylon,js all have a concept
of a <em>material</em>. Generally, a material holds things like the color of the
material, how shiny it is, as well as which texture to use, etc‚Ä¶</p>
<p>We‚Äôll make 20 ‚Äúmaterials‚Äù and then pick a material at random for each cube.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numMaterials = 20;
  const materials = [];
  for (let i = 0; i &lt; numMaterials; ++i) {
    const color = hslToRGBA(rand(), rand(0.5, 0.8), rand(0.5, 0.7));
    const shininess = rand(10, 120);
    materials.push({
      color,
      shininess,
      texture: randomArrayElement(textures),
      sampler,
    });
  }
</pre>
<p>Now let‚Äôs make data for each thing (cube) we want to draw. We‚Äôll support a
maximum of 30000. Like we have in the past, we‚Äôll make a uniform buffer for each
object as well as a typed array we can update with uniform values. We‚Äôll also
make a bind group for each object. And we‚Äôll pick some random values we can use
to position and animate each object.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const maxObjects = 30000;
  const objectInfos = [];

  for (let i = 0; i &lt; maxObjects; ++i) {
    const uniformBufferSize = (12 + 16 + 16 + 4 + 4 + 4) * 4;
    const uniformBuffer = device.createBuffer({
      label: 'uniforms',
      size: uniformBufferSize,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });

    const uniformValues = new Float32Array(uniformBufferSize / 4);

    // offsets to the various uniform values in float32 indices
    const kNormalMatrixOffset = 0;
    const kViewProjectionOffset = 12;
    const kWorldOffset = 28;
    const kColorOffset = 44;
    const kLightWorldPositionOffset = 48;
    const kViewWorldPositionOffset = 52;
    const kShininessOffset = 55;

    const normalMatrixValue = uniformValues.subarray(
        kNormalMatrixOffset, kNormalMatrixOffset + 12);
    const viewProjectionValue = uniformValues.subarray(
        kViewProjectionOffset, kViewProjectionOffset + 16);
    const worldValue = uniformValues.subarray(
        kWorldOffset, kWorldOffset + 16);
    const colorValue = uniformValues.subarray(kColorOffset, kColorOffset + 4);
    const lightWorldPositionValue = uniformValues.subarray(
        kLightWorldPositionOffset, kLightWorldPositionOffset + 3);
    const viewWorldPositionValue = uniformValues.subarray(
        kViewWorldPositionOffset, kViewWorldPositionOffset + 3);
    const shininessValue = uniformValues.subarray(
        kShininessOffset, kShininessOffset + 1);

    const material = randomArrayElement(materials);

    const bindGroup = device.createBindGroup({
      label: 'bind group for object',
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: material.texture.createView() },
        { binding: 1, resource: material.sampler },
        { binding: 2, resource: { buffer: uniformBuffer }},
      ],
    });

    const axis = vec3.normalize([rand(-1, 1), rand(-1, 1), rand(-1, 1)]);
    const radius = rand(10, 100);
    const speed = rand(0.1, 0.4);
    const rotationSpeed = rand(-1, 1);
    const scale = rand(2, 10);

    objectInfos.push({
      bindGroup,

      uniformBuffer,
      uniformValues,

      normalMatrixValue,
      worldValue,
      viewProjectionValue,
      colorValue,
      lightWorldPositionValue,
      viewWorldPositionValue,
      shininessValue,

      axis,
      material,
      radius,
      speed,
      rotationSpeed,
      scale,
    });
  }
</pre>
<p>We pre-create a render pass descriptor which we‚Äôll update to begin a render pass
at render time.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const renderPassDescriptor = {
    label: 'our basic canvas renderPass',
    colorAttachments: [
      {
        // view: &lt;- to be filled out when we render
        clearValue: [0.3, 0.3, 0.3, 1],
        loadOp: 'clear',
        storeOp: 'store',
      },
    ],
    depthStencilAttachment: {
      // view: &lt;- to be filled out when we render
      depthClearValue: 1.0,
      depthLoadOp: 'clear',
      depthStoreOp: 'store',
    },
  };
</pre>
<p>We need a simple UI so we can adjust how many things we‚Äôre drawing.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
    numObjects: 1000,
  };

  const gui = new GUI();
  gui.add(settings, 'numObjects', { min: 0, max: maxObjects, step: 1});
</pre>
<p>Now we can write our render loop.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  let depthTexture;
  let then = 0;

  function render(time) {
    time *= 0.001;  // convert to seconds
    const deltaTime = time - then;
    then = time;


    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>Inside the render loop we‚Äôll update our render pass descriptor. we‚Äôll also
create a depth texture if one doesn‚Äôt exist or if the one
we have has a different size then our canvas texture. We did this in
<a href="webgpu-orthographic-projection.html#a-depth-textures">the article on 3d</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    // Get the current texture from the canvas context and
    // set it as the texture to render to.
    const canvasTexture = context.getCurrentTexture();
    renderPassDescriptor.colorAttachments[0].view = canvasTexture.createView();

    // If we don't have a depth texture OR if its size is different
    // from the canvasTexture when make a new depth texture
    if (!depthTexture ||
        depthTexture.width !== canvasTexture.width ||
        depthTexture.height !== canvasTexture.height) {
      if (depthTexture) {
        depthTexture.destroy();
      }
      depthTexture = device.createTexture({
        size: [canvasTexture.width, canvasTexture.height],
        format: 'depth24plus',
        usage: GPUTextureUsage.RENDER_ATTACHMENT,
      });
    }
    renderPassDescriptor.depthStencilAttachment.view = depthTexture.createView();
</pre>
<p>We‚Äôll start a command buffer and a render pass and set our vertex and index buffers.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass(renderPassDescriptor);
    pass.setPipeline(pipeline);
    pass.setVertexBuffer(0, positionBuffer);
    pass.setVertexBuffer(1, normalBuffer);
    pass.setVertexBuffer(2, texcoordBuffer);
    pass.setIndexBuffer(indicesBuffer, 'uint16');
</pre>
<p>Then we‚Äôll compute a viewProjection matrix like we covered in
<a href="webgpu-perspective-projection.html">the article on perspective projection</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const degToRad = d =&gt; d * Math.PI / 180;

  function render(time) {
    ...

+    const aspect = canvas.clientWidth / canvas.clientHeight;
+    const projection = mat4.perspective(
+        degToRad(60),
+        aspect,
+        1,      // zNear
+        2000,   // zFar
+    );
+
+    const eye = [100, 150, 200];
+    const target = [0, 0, 0];
+    const up = [0, 1, 0];
+
+    // Compute a view matrix
+    const viewMatrix = mat4.lookAt(eye, target, up);
+
+    // Combine the view and projection matrixes
+    const viewProjectionMatrix = mat4.multiply(projection, viewMatrix);
</pre>
<p>Now we can loop over all the objects and draw them, for each one we need
to update all of its uniform values, copy the uniform values to its uniform buffer,
bind the bind group for this object, and draw.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
        uniformBuffer,
        uniformValues,
        normalMatrixValue,
        worldValue,
        viewProjectionValue,
        colorValue,
        lightWorldPositionValue,
        viewWorldPositionValue,
        shininessValue,

        axis,
        material,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];

      // Copy the viewProjectionMatrix into the uniform values for this object
      viewProjectionValue.set(viewProjectionMatrix);

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

      const {color, shininess} = material;

      // copy the materials values.
      colorValue.set(color);
      lightWorldPositionValue.set([-10, 30, 300]);
      viewWorldPositionValue.set(eye);
      shininessValue[0] = shininess;

      // upload the uniform values to the uniform buffer
      device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }
</pre>
<blockquote>
<p>Note that the portion of the code labeled ‚ÄúCompute a world matrix‚Äù is not so common. It would
be more common to have a <a href="webgpu-scene-graphs.html">scene graph</a> but that would have cluttered
the example even more. We needed something showing animation I threw something together.</p>
</blockquote>
<p>Then we can end the pass, finish the command buffer, and submit it.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+    pass.end();
+
+    const commandBuffer = encoder.finish();
+    device.queue.submit([commandBuffer]);

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>A few more things left to do. Let‚Äôs add in resizing</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const canvasToSizeMap = new WeakMap();

  function render(time) {
    time *= 0.001;  // convert to seconds
    const deltaTime = time - then;
    then = time;

+    const {width, height} = canvasToSizeMap.get(canvas) ?? canvas;
+
+    // Don't set the canvas size if it's already that size as it may be slow.
+    if (canvas.width !== width || canvas.height !== height) {
+      canvas.width = width;
+      canvas.height = height;
+    }

    // Get the current texture from the canvas context and
    // set it as the texture to render to.
    const canvasTexture = context.getCurrentTexture();
    renderPassDescriptor.colorAttachments[0].view = canvasTexture.createView();

    ...

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);

  +const observer = new ResizeObserver(entries =&gt; {
  +  entries.forEach(entry =&gt; {
  +    canvasToSizeMap.set(entry.target, {
  +      width: Math.max(1, Math.min(entry.contentBoxSize[0].inlineSize, device.limits.maxTextureDimension2D)),
  +      height: Math.max(1, Math.min(entry.contentBoxSize[0].blockSize, device.limits.maxTextureDimension2D)),
  +    });
  +  });
  +});
  +observer.observe(canvas);
</pre>
<p>Let‚Äôs also add in some timing. We‚Äôll use the <code class="notranslate" translate="no">NonNegativeRollingAverage</code> and <code class="notranslate" translate="no">TimingHelper</code> classes
we made in <a href="webgpu-timing.html">the article on timing</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">// see https://webgpufundamentals.org/webgpu/lessons/webgpu-timing.html
import TimingHelper from './resources/js/timing-helper.js';
// see https://webgpufundamentals.org/webgpu/lessons/webgpu-timing.html
import NonNegativeRollingAverage from './resources/js/non-negative-rolling-average.js';

const fpsAverage = new NonNegativeRollingAverage();
const jsAverage = new NonNegativeRollingAverage();
const gpuAverage = new NonNegativeRollingAverage();
const mathAverage = new NonNegativeRollingAverage();
</pre>
<p>Then we‚Äôll time our JavaScript from the beginning to the end of our rendering code</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function render(time) {
    ...

+    const startTimeMs = performance.now();

    ...

+    const elapsedTimeMs = performance.now() - startTimeMs;
+    jsAverage.addSample(elapsedTimeMs);

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>We‚Äôll time the part of the JavaScript that does the 3D math</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function render(time) {
    ...

+    let mathElapsedTimeMs = 0;

    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
        uniformBuffer,
        uniformValues,
        normalMatrixValue,
        worldValue,
        viewProjectionValue,
        colorValue,
        lightWorldPositionValue,
        viewWorldPositionValue,
        shininessValue,

        axis,
        material,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];
+      const mathTimeStartMs = performance.now();

      // Copy the viewProjectionMatrix into the uniform values for this object
      viewProjectionValue.set(viewProjectionMatrix);

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

      const {color, shininess} = material;

      colorValue.set(color);
      lightWorldPositionValue.set([-10, 30, 300]);
      viewWorldPositionValue.set(eye);
      shininessValue[0] = shininess;

+      mathElapsedTimeMs += performance.now() - mathTimeStartMs;

      // upload the uniform values to the uniform buffer
      device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }

    ...

    const elapsedTimeMs = performance.now() - startTimeMs;
    jsAverage.addSample(elapsedTimeMs);
+    mathAverage.addSample(mathElapsedTimeMs);


    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>We‚Äôll time the time between <code class="notranslate" translate="no">requestAnimationFrame</code> callbacks.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  let depthTexture;
  let then = 0;

  function render(time) {
    time *= 0.001;  // convert to seconds
    const deltaTime = time - then;
    then = time;

    ...

    const elapsedTimeMs = performance.now() - startTimeMs;
+    fpsAverage.addSample(1 / deltaTime);
    jsAverage.addSample(elapsedTimeMs);
    mathAverage.addSample(mathElapsedTimeMs);


    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>And we‚Äôll time our render pass</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const adapter = await navigator.gpu?.requestAdapter({
    powerPreference: 'high-performance',
  });
-  const device = await adapter?.requestDevice();
+  const canTimestamp = adapter.features.has('timestamp-query');
+  const device = await adapter?.requestDevice({
+    requiredFeatures: [
+      ...(canTimestamp ? ['timestamp-query'] : []),
+     ],
+  });
  if (!device) {
    fail('could not init WebGPU');
  }

+  const timingHelper = new TimingHelper(device);

  ...

  function render(time) {
    ...

-    const pass = encoder.beginRenderPass(renderPassEncoder);
+    const pass = timingHelper.beginRenderPass(encoder, renderPassDescriptor);

    ...

    pass.end();

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);

+    timingHelper.getResult().then(gpuTime =&gt; {
+      gpuAverage.addSample(gpuTime / 1000);
+    });

    ...

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>And we need to show the timing</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  ...

  const timingHelper = new TimingHelper(device);
+  const infoElem = document.querySelector('#info');

  ...

  function render(time) {
    ...

    timingHelper.getResult().then(gpuTime =&gt; {
      gpuAverage.addSample(gpuTime / 1000);
    });

    const elapsedTimeMs = performance.now() - startTimeMs;
    fpsAverage.addSample(1 / deltaTime);
    jsAverage.addSample(elapsedTimeMs);
    mathAverage.addSample(mathElapsedTimeMs);

+    infoElem.textContent = `\
+js  : ${jsAverage.get().toFixed(1)}ms
+math: ${mathAverage.get().toFixed(1)}ms
+fps : ${fpsAverage.get().toFixed(0)}
+gpu : ${canTimestamp ? `${(gpuAverage.get() / 1000).toFixed(1)}ms` : 'N/A'}
+`;

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>One more thing, just to help with better comparisons. An issue we have now is,
every visible cube has every pixel rendered or at least checked if it needs to
be rendered. Since we‚Äôre not optimizing the rendering of pixels but rather
optimizing the usage of WebGPU itself, it can be useful to be able to draw to a
1x1 pixel canvas. This effectively removes nearly all of the time spent
rasterizing triangles and instead leaves only the part of our code that is doing
math and communicating with WebGPU.</p>
<p>So let‚Äôs add an option to do that</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
    numObjects: 1000,
+    render: true,
  };

  const gui = new GUI();
  gui.add(settings, 'numObjects', { min: 0, max: maxObjects, step: 1});
+  gui.add(settings, 'render');

  let depthTexture;
  let then = 0;
  let frameCount = 0;

  function render(time) {
    time *= 0.001;  // convert to seconds
    const deltaTime = time - then;
    then = time;
    ++frameCount;

    const startTimeMs = performance.now();

-    const {width, height} = canvasToSizeMap.get(canvas) ?? canvas;
+    const {width, height} = settings.render
+       ? canvasToSizeMap.get(canvas) ?? canvas
+       : { width: 1, height: 1 };
</pre>
<p>Now, if we uncheck ‚Äòrender‚Äô, we‚Äôll remove almost all of the um, ahh ‚Ä¶, rendering.</p>
<p>And with that, we have our first ‚Äúun-optimized‚Äù example. It‚Äôs following the
steps listed near the top of the article, and it works.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-optimization-none.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-optimization-none.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Increase the number of objects and see when the framerate drops for you. For me,
on my 75hz monitor on an M1 Mac I got ~8000 cubes before the framerate dropped.</p>
<h1 id="optimization-mapped-on-creation"><a id="a-mapped-on-creation"></a> Optimization: Mapped On Creation</h1>
<p>In the example above, and in most of the examples on this site, we‚Äôve used
<code class="notranslate" translate="no">writeBuffer</code> to copy data into a vertex or index buffer. As a very minor
optimization, for this particular case, when you create a buffer you can pass in
<code class="notranslate" translate="no">mappedAtCreation: true</code>. This has 2 benefits.</p>
<ol>
<li>
<p>It‚Äôs slightly faster to put the data into the new buffer</p>
</li>
<li>
<p>You don‚Äôt have to add <code class="notranslate" translate="no">GPUBufferUsage.COPY_DST</code> to the buffer‚Äôs usage.</p>
<p>This assumes you‚Äôre not going to change the data later via <code class="notranslate" translate="no">writeBuffer</code> nor
one of the copy to buffer functions.</p>
</li>
</ol>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function createBufferWithData(device, data, usage) {
    const buffer = device.createBuffer({
      size: data.byteLength,
-      usage: usage | GPUBufferUsage.COPY_DST,
+      usage: usage,
+      mappedAtCreation: true,
    });
-    device.queue.writeBuffer(buffer, 0, data);
+    const dst = new Uint8Array(buffer.getMappedRange());
+    dst.set(new Uint8Array(data.buffer));
+    buffer.unmap();
    return buffer;
  }
</pre>
<p>Note that this optimization only helps at creation time so it will not affect
our performance at render time.</p>
<h1 id="optimization-pack-and-interleave-your-vertices"><a id="a-pack-verts"></a> Optimization: Pack and interleave your vertices</h1>
<p>In the example above we have 3 attributes, one for position, one for normals,
and one for texture coordinates. It‚Äôs common to have 4 to 6 attributes where
we‚Äôd have <a href="webgpu-normal-mapping.html">tangents for normal mapping</a> and, if
we had <a href="webgpu-skinning.html">a skinned model</a>, we‚Äôd add in weights and joints.</p>
<p>In the example above, each attribute is using its own buffer. This is slower both
on the CPU and GPU. It‚Äôs slower on the CPU in JavaScript because we need to call
<code class="notranslate" translate="no">setVertexBuffer</code> once for each buffer for each model we want to draw.</p>
<p>Imagine instead of just a cube we had 100s of models. Each time we switched
which model to draw we‚Äôd have to call <code class="notranslate" translate="no">setVertexBuffer</code> up to 6 times. 100 * 6
calls per model = 600 calls.</p>
<p>Following the rule ‚Äúless work = go faster‚Äù, if we merged the data for the
attributes into a single buffer then we‚Äôd only need one call to
<code class="notranslate" translate="no">setVertexBuffer</code> once per model. 100 calls. That‚Äôs like 600% faster!</p>
<p>On the GPU, loading things that are together in memory is usually faster than
loading from different places in memory so on top of just putting the vertex
data for a single model into a single buffer, it‚Äôs better to interleave the
data.</p>
<p>Let‚Äôs make that change.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const positions = new Float32Array([1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]);
-  const normals   = new Float32Array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1]);
-  const texcoords = new Float32Array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]);
+  const vertexData = new Float32Array([
+  // position       normal        texcoord
+     1,  1, -1,     1,  0,  0,    1, 0,
+     1,  1,  1,     1,  0,  0,    0, 0,
+     1, -1,  1,     1,  0,  0,    0, 1,
+     1, -1, -1,     1,  0,  0,    1, 1,
+    -1,  1,  1,    -1,  0,  0,    1, 0,
+    -1,  1, -1,    -1,  0,  0,    0, 0,
+    -1, -1, -1,    -1,  0,  0,    0, 1,
+    -1, -1,  1,    -1,  0,  0,    1, 1,
+    -1,  1,  1,     0,  1,  0,    1, 0,
+     1,  1,  1,     0,  1,  0,    0, 0,
+     1,  1, -1,     0,  1,  0,    0, 1,
+    -1,  1, -1,     0,  1,  0,    1, 1,
+    -1, -1, -1,     0, -1,  0,    1, 0,
+     1, -1, -1,     0, -1,  0,    0, 0,
+     1, -1,  1,     0, -1,  0,    0, 1,
+    -1, -1,  1,     0, -1,  0,    1, 1,
+     1,  1,  1,     0,  0,  1,    1, 0,
+    -1,  1,  1,     0,  0,  1,    0, 0,
+    -1, -1,  1,     0,  0,  1,    0, 1,
+     1, -1,  1,     0,  0,  1,    1, 1,
+    -1,  1, -1,     0,  0, -1,    1, 0,
+     1,  1, -1,     0,  0, -1,    0, 0,
+     1, -1, -1,     0,  0, -1,    0, 1,
+    -1, -1, -1,     0,  0, -1,    1, 1,
+  ]);
  const indices   = new Uint16Array([0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23]);

-  const positionBuffer = createBufferWithData(device, positions, GPUBufferUsage.VERTEX);
-  const normalBuffer = createBufferWithData(device, normals, GPUBufferUsage.VERTEX);
-  const texcoordBuffer = createBufferWithData(device, texcoords, GPUBufferUsage.VERTEX);
+  const vertexBuffer = createBufferWithData(device, vertexData, GPUBufferUsage.VERTEX);
  const indicesBuffer = createBufferWithData(device, indices, GPUBufferUsage.INDEX);
  const numVertices = indices.length;

  const pipeline = device.createRenderPipeline({
    label: 'textured model with point light w/specular highlight',
    layout: 'auto',
    vertex: {
      module,
      buffers: [
-        // position
-        {
-          arrayStride: 3 * 4, // 3 floats
-          attributes: [
-            {shaderLocation: 0, offset: 0, format: 'float32x3'},
-          ],
-        },
-        // normal
-        {
-          arrayStride: 3 * 4, // 3 floats
-          attributes: [
-            {shaderLocation: 1, offset: 0, format: 'float32x3'},
-          ],
-        },
-        // uvs
-        {
-          arrayStride: 2 * 4, // 2 floats
-          attributes: [
-            {shaderLocation: 2, offset: 0, format: 'float32x2'},
-          ],
-        },
+        {
+          arrayStride: (3 + 3 + 2) * 4, // 8 floats
+          attributes: [
+            {shaderLocation: 0, offset: 0 * 4, format: 'float32x3'}, // position
+            {shaderLocation: 1, offset: 3 * 4, format: 'float32x3'}, // normal
+            {shaderLocation: 2, offset: 6 * 4, format: 'float32x2'}, // texcoord
+          ],
+        },
      ],
    },
    fragment: {
      module,
      targets: [{ format: presentationFormat }],
    },
    primitive: {
      cullMode: 'back',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'less',
      format: 'depth24plus',
    },
  });

  ...
-    pass.setVertexBuffer(0, positionBuffer);
-    pass.setVertexBuffer(1, normalBuffer);
-    pass.setVertexBuffer(2, texcoordBuffer);
+    pass.setVertexBuffer(0, vertexBuffer);
</pre>
<p>Above we put the data for all 3 attributes into a single buffer and then changed
our render pass so it expects the data interleaved into a single buffer.</p>
<p>Note: if you‚Äôre loading gLTF files, it‚Äôs arguably good to either pre-process
them so their vertex data is interleaved into a single buffer (best) or else
interleave the data at load time.</p>
<h1 id="optimization-split-uniform-buffers-shared-material-per-model">Optimization: Split uniform buffers (shared, material, per model)</h1>
<p>Our example right now has one uniform buffer per object.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct Uniforms {
  normalMatrix: mat3x3f,
  viewProjection: mat4x4f,
  world: mat4x4f,
  color: vec4f,
  lightWorldPosition: vec3f,
  viewWorldPosition: vec3f,
  shininess: f32,
};
</pre>
<p>Some of those uniform values like <code class="notranslate" translate="no">viewProjection</code>, <code class="notranslate" translate="no">lightWorldPosition</code>
and <code class="notranslate" translate="no">viewWorldPosition</code> can be shared.</p>
<p>We can split these in the shader to use 2 uniform buffers. One for the shared
values and one for <em>per object values</em>.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">struct GlobalUniforms {
  viewProjection: mat4x4f,
  lightWorldPosition: vec3f,
  viewWorldPosition: vec3f,
};
struct PerObjectUniforms {
  normalMatrix: mat3x3f,
  world: mat4x4f,
  color: vec4f,
  shininess: f32,
};
</pre>
<p>With this change, we‚Äôll save having to copy the
<code class="notranslate" translate="no">viewProjection</code>, <code class="notranslate" translate="no">lightWorldPosition</code> and <code class="notranslate" translate="no">viewWorldPosition</code>
to every uniform buffer. We‚Äôll also copy less data per object
with <code class="notranslate" translate="no">device.queue.writeBuffer</code></p>
<p>Here‚Äôs the new shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const module = device.createShaderModule({
    code: `
-      struct Uniforms {
-        normalMatrix: mat3x3f,
-        viewProjection: mat4x4f,
-        world: mat4x4f,
-        color: vec4f,
-        lightWorldPosition: vec3f,
-        viewWorldPosition: vec3f,
-        shininess: f32,
-      };

+      struct GlobalUniforms {
+        viewProjection: mat4x4f,
+        lightWorldPosition: vec3f,
+        viewWorldPosition: vec3f,
+      };
+      struct PerObjectUniforms {
+        normalMatrix: mat3x3f,
+        world: mat4x4f,
+        color: vec4f,
+        shininess: f32,
+      };

      struct Vertex {
        @location(0) position: vec4f,
        @location(1) normal: vec3f,
        @location(2) texcoord: vec2f,
      };

      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) normal: vec3f,
        @location(1) surfaceToLight: vec3f,
        @location(2) surfaceToView: vec3f,
        @location(3) texcoord: vec2f,
      };

      @group(0) @binding(0) var diffuseTexture: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var diffuseSampler: sampler;
-      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;
+      @group(0) @binding(2) var&lt;uniform&gt; obj: PerObjectUniforms;
+      @group(0) @binding(3) var&lt;uniform&gt; glb: GlobalUniforms;

      @vertex fn vs(vert: Vertex) -&gt; VSOutput {
        var vsOut: VSOutput;
-        vsOut.position = uni.viewProjection * uni.world * vert.position;
+        vsOut.position = glb.viewProjection * obj.world * vert.position;

        // Orient the normals and pass to the fragment shader
-        vsOut.normal = uni.normalMatrix * vert.normal;
+        vsOut.normal = obj.normalMatrix * vert.normal;

        // Compute the world position of the surface
-        let surfaceWorldPosition = (uni.world * vert.position).xyz;
+        let surfaceWorldPosition = (obj.world * vert.position).xyz;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
-        vsOut.surfaceToLight = uni.lightWorldPosition - surfaceWorldPosition;
+        vsOut.surfaceToLight = glb.lightWorldPosition - surfaceWorldPosition;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
-        vsOut.surfaceToView = uni.viewWorldPosition - surfaceWorldPosition;
+        vsOut.surfaceToView = glb.viewWorldPosition - surfaceWorldPosition;

        // Pass the texture coord on to the fragment shader
        vsOut.texcoord = vert.texcoord;

        return vsOut;
      }

      @fragment fn fs(vsOut: VSOutput) -&gt; @location(0) vec4f {
        // Because vsOut.normal is an inter-stage variable 
        // it's interpolated so it will not be a unit vector.
        // Normalizing it will make it a unit vector again
        let normal = normalize(vsOut.normal);

        let surfaceToLightDirection = normalize(vsOut.surfaceToLight);
        let surfaceToViewDirection = normalize(vsOut.surfaceToView);
        let halfVector = normalize(
          surfaceToLightDirection + surfaceToViewDirection);

        // Compute the light by taking the dot product
        // of the normal with the direction to the light
        let light = dot(normal, surfaceToLightDirection);

        var specular = dot(normal, halfVector);
        specular = select(
            0.0,                           // value if condition is false
-            pow(specular, uni.shininess),  // value if condition is true
+            pow(specular, obj.shininess),  // value if condition is true
            specular &gt; 0.0);               // condition

-        let diffuse = uni.color * textureSample(diffuseTexture, diffuseSampler, vsOut.texcoord);
+        let diffuse = obj.color * textureSample(diffuseTexture, diffuseSampler, vsOut.texcoord);
        // Lets multiply just the color portion (not the alpha)
        // by the light
        let color = diffuse.rgb * light + specular;
        return vec4f(color, diffuse.a);
      }
    `,
  });
</pre>
<p>We need to create one global uniform buffer for the global uniforms.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const globalUniformBufferSize = (16 + 4 + 4) * 4;
  const globalUniformBuffer = device.createBuffer({
    label: 'global uniforms',
    size: globalUniformBufferSize,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });

  const globalUniformValues = new Float32Array(globalUniformBufferSize / 4);

  const kViewProjectionOffset = 0;
  const kLightWorldPositionOffset = 16;
  const kViewWorldPositionOffset = 20;

  const viewProjectionValue = globalUniformValues.subarray(
      kViewProjectionOffset, kViewProjectionOffset + 16);
  const lightWorldPositionValue = globalUniformValues.subarray(
      kLightWorldPositionOffset, kLightWorldPositionOffset + 3);
  const viewWorldPositionValue = globalUniformValues.subarray(
      kViewWorldPositionOffset, kViewWorldPositionOffset + 3);
</pre>
<p>Then we can remove these uniforms from our perObject uniform buffer and add the
global uniform buffer to each object‚Äôs bind group.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const maxObjects = 30000;
  const objectInfos = [];

  for (let i = 0; i &lt; maxObjects; ++i) {
-    const uniformBufferSize = (12 + 16 + 16 + 4 + 4 + 4) * 4;
+    const uniformBufferSize = (12 + 16 + 4 + 4) * 4;
    const uniformBuffer = device.createBuffer({
      label: 'uniforms',
      size: uniformBufferSize,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });

    const uniformValues = new Float32Array(uniformBufferSize / 4);

    // offsets to the various uniform values in float32 indices
    const kNormalMatrixOffset = 0;
-    const kViewProjectionOffset = 12;
-    const kWorldOffset = 28;
-    const kColorOffset = 44;
-    const kLightWorldPositionOffset = 48;
-    const kViewWorldPositionOffset = 52;
-    const kShininessOffset = 55;
+    const kWorldOffset = 12;
+    const kColorOffset = 28;
+    const kShininessOffset = 32;

    const normalMatrixValue = uniformValues.subarray(
        kNormalMatrixOffset, kNormalMatrixOffset + 12);
-    const viewProjectionValue = uniformValues.subarray(
-        kViewProjectionOffset, kViewProjectionOffset + 16);
    const worldValue = uniformValues.subarray(
        kWorldOffset, kWorldOffset + 16);
    const colorValue = uniformValues.subarray(kColorOffset, kColorOffset + 4);
-    const lightWorldPositionValue = uniformValues.subarray(
-        kLightWorldPositionOffset, kLightWorldPositionOffset + 3);
-    const viewWorldPositionValue = uniformValues.subarray(
-        kViewWorldPositionOffset, kViewWorldPositionOffset + 3);
    const shininessValue = uniformValues.subarray(
        kShininessOffset, kShininessOffset + 1);

    const material = randomArrayElement(materials);

    const bindGroup = device.createBindGroup({
      label: 'bind group for object',
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: material.texture.createView() },
        { binding: 1, resource: material.sampler },
        { binding: 2, resource: { buffer: uniformBuffer }},
+        { binding: 3, resource: { buffer: globalUniformBuffer }},
      ],
    });

    const axis = vec3.normalize([rand(-1, 1), rand(-1, 1), rand(-1, 1)]);
    const radius = rand(10, 100);
    const speed = rand(0.1, 0.4);
    const rotationSpeed = rand(-1, 1);
    const scale = rand(2, 10);

    objectInfos.push({
      bindGroup,

      uniformBuffer,
      uniformValues,

      normalMatrixValue,
      worldValue,
-      viewProjectionValue,
      colorValue,
-      lightWorldPositionValue,
-      viewWorldPositionValue,
      shininessValue,
      material,

      axis,
      radius,
      speed,
      rotationSpeed,
      scale,
    });
  }
</pre>
<p>Then, at render time, we update the global uniform buffer just once, outside the
loop of rendering our objects.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const aspect = canvas.clientWidth / canvas.clientHeight;
    const projection = mat4.perspective(
        degToRad(60),
        aspect,
        1,      // zNear
        2000,   // zFar
    );

    const eye = [100, 150, 200];
    const target = [0, 0, 0];
    const up = [0, 1, 0];

    // Compute a view matrix
    const viewMatrix = mat4.lookAt(eye, target, up);

    // Combine the view and projection matrixes
-    const viewProjectionMatrix = mat4.multiply(projection, viewMatrix);
+    mat4.multiply(projection, viewMatrix, viewProjectionValue);
+
+    lightWorldPositionValue.set([-10, 30, 300]);
+    viewWorldPositionValue.set(eye);
+
+    device.queue.writeBuffer(globalUniformBuffer, 0, globalUniformValues);

    let mathElapsedTimeMs = 0;

    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
        uniformBuffer,
        uniformValues,
        normalMatrixValue,
        worldValue,
-        viewProjectionValue,
        colorValue,
-        lightWorldPositionValue,
-        viewWorldPositionValue,
        shininessValue,

        axis,
        material,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];
      const mathTimeStartMs = performance.now();

-      // Copy the viewProjectionMatrix into the uniform values for this object
-      viewProjectionValue.set(viewProjectionMatrix);

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

      const {color, shininess} = material;
      colorValue.set(color);
-      lightWorldPositionValue.set([-10, 30, 300]);
-      viewWorldPositionValue.set(eye);
      shininessValue[0] = shininess;

      mathElapsedTimeMs += performance.now() - mathTimeStartMs;

      // upload the uniform values to the uniform buffer
      device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }

    pass.end();
</pre>
<p>That didn‚Äôt change the number of calls into WebGPU, in fact it added 1. But, it
reduced a bunch of the work we were doing per model.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-optimization-step3-global-vs-per-object-uniforms.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-optimization-step3-global-vs-per-object-uniforms.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>On my machine, with that change, our math portion dropped ~16%</p>
<h1 id="optimization-separate-more-uniforms">Optimization: Separate more uniforms</h1>
<p>A common organization in a 3D library is to have ‚Äúmodels‚Äù (the vertex data),
‚Äúmaterials‚Äù (the colors, shininess, and textures), ‚Äúlights‚Äù (which lights to
use), ‚ÄúviewInfo‚Äù (the view and projection matrix). In particular, in our
example, <code class="notranslate" translate="no">color</code> and <code class="notranslate" translate="no">shininess</code> never change so it‚Äôs a waste to keep copying
them to the uniform buffer every frame.</p>
<p>Let‚Äôs make a uniform buffer per material. We‚Äôll copy the material settings into
them at init time and then just add them to our bind group.</p>
<p>First let‚Äôs change the shaders to use another uniform buffer.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const module = device.createShaderModule({
    code: `
      struct GlobalUniforms {
        viewProjection: mat4x4f,
        lightWorldPosition: vec3f,
        viewWorldPosition: vec3f,
      };

+      struct MaterialUniforms {
+        color: vec4f,
+        shininess: f32,
+      };

      struct PerObjectUniforms {
        normalMatrix: mat3x3f,
        world: mat4x4f,
-        color: vec4f,
-        shininess: f32,
      };

      struct Vertex {
        @location(0) position: vec4f,
        @location(1) normal: vec3f,
        @location(2) texcoord: vec2f,
      };

      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) normal: vec3f,
        @location(1) surfaceToLight: vec3f,
        @location(2) surfaceToView: vec3f,
        @location(3) texcoord: vec2f,
      };

      @group(0) @binding(0) var diffuseTexture: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var diffuseSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; obj: PerObjectUniforms;
      @group(0) @binding(3) var&lt;uniform&gt; glb: GlobalUniforms;
+      @group(0) @binding(4) var&lt;uniform&gt; material: MaterialUniforms;

      @vertex fn vs(vert: Vertex) -&gt; VSOutput {
        var vsOut: VSOutput;
        vsOut.position = glb.viewProjection * obj.world * vert.position;

        // Orient the normals and pass to the fragment shader
        vsOut.normal = obj.normalMatrix * vert.normal;

        // Compute the world position of the surface
        let surfaceWorldPosition = (obj.world * vert.position).xyz;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
        vsOut.surfaceToLight = glb.lightWorldPosition - surfaceWorldPosition;

        // Compute the vector of the surface to the light
        // and pass it to the fragment shader
        vsOut.surfaceToView = glb.viewWorldPosition - surfaceWorldPosition;

        // Pass the texture coord on to the fragment shader
        vsOut.texcoord = vert.texcoord;

        return vsOut;
      }

      @fragment fn fs(vsOut: VSOutput) -&gt; @location(0) vec4f {
        // Because vsOut.normal is an inter-stage variable 
        // it's interpolated so it will not be a unit vector.
        // Normalizing it will make it a unit vector again
        let normal = normalize(vsOut.normal);

        let surfaceToLightDirection = normalize(vsOut.surfaceToLight);
        let surfaceToViewDirection = normalize(vsOut.surfaceToView);
        let halfVector = normalize(
          surfaceToLightDirection + surfaceToViewDirection);

        // Compute the light by taking the dot product
        // of the normal with the direction to the light
        let light = dot(normal, surfaceToLightDirection);

        var specular = dot(normal, halfVector);
        specular = select(
            0.0,                           // value if condition is false
-            pow(specular, obj.shininess),  // value if condition is true
+            pow(specular, material.shininess),  // value if condition is true
            specular &gt; 0.0);               // condition

-        let diffuse = obj.color * textureSample(diffuseTexture, diffuseSampler, vsOut.texcoord);
+        let diffuse = material.color * textureSample(diffuseTexture, diffuseSampler, vsOut.texcoord);
        // Lets multiply just the color portion (not the alpha)
        // by the light
        let color = diffuse.rgb * light + specular;
        return vec4f(color, diffuse.a);
      }
    `,
  });
</pre>
<p>Then we‚Äôll make a uniform buffer for each material.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numMaterials = 20;
  const materials = [];
  for (let i = 0; i &lt; numMaterials; ++i) {
    const color = hslToRGBA(rand(), rand(0.5, 0.8), rand(0.5, 0.7));
    const shininess = rand(10, 120);

+    const materialValues = new Float32Array([
+      ...color,
+      shininess,
+      0, 0, 0,  // padding
+    ]);
+    const materialUniformBuffer = createBufferWithData(
+      device,
+      materialValues,
+      GPUBufferUsage.UNIFORM,
+    );

    materials.push({
-      color,
-      shininess,
+      materialUniformBuffer,
      texture: randomArrayElement(textures),
      sampler,
    });
  }
</pre>
<p>When we setup the per object info we no longer need to pass on the material
settings. Instead we just need to add the material‚Äôs uniform buffer to the
object‚Äôs bind group.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const maxObjects = 30000;
  const objectInfos = [];

  for (let i = 0; i &lt; maxObjects; ++i) {
-    const uniformBufferSize = (12 + 16 + 4 + 4) * 4;
+    const uniformBufferSize = (12 + 16) * 4;
    const uniformBuffer = device.createBuffer({
      label: 'uniforms',
      size: uniformBufferSize,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });

    const uniformValues = new Float32Array(uniformBufferSize / 4);

    // offsets to the various uniform values in float32 indices
    const kNormalMatrixOffset = 0;
    const kWorldOffset = 12;
-    const kColorOffset = 28;
-    const kShininessOffset = 32;

    const normalMatrixValue = uniformValues.subarray(
        kNormalMatrixOffset, kNormalMatrixOffset + 12);
    const worldValue = uniformValues.subarray(
        kWorldOffset, kWorldOffset + 16);
-    const colorValue = uniformValues.subarray(kColorOffset, kColorOffset + 4);
-    const shininessValue = uniformValues.subarray(
-        kShininessOffset, kShininessOffset + 1);

    const material = randomArrayElement(materials);

    const bindGroup = device.createBindGroup({
      label: 'bind group for object',
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: material.texture.createView() },
        { binding: 1, resource: material.sampler },
        { binding: 2, resource: { buffer: uniformBuffer }},
        { binding: 3, resource: { buffer: globalUniformBuffer }},
+        { binding: 4, resource: { buffer: material.materialUniformBuffer }},
      ],
    });

    const axis = vec3.normalize([rand(-1, 1), rand(-1, 1), rand(-1, 1)]);
    const radius = rand(10, 100);
    const speed = rand(0.1, 0.4);
    const rotationSpeed = rand(-1, 1);
    const scale = rand(2, 10);

    objectInfos.push({
      bindGroup,

      uniformBuffer,
      uniformValues,

      normalMatrixValue,
      worldValue,
-      colorValue,
-      shininessValue,

      axis,
-      material,
      radius,
      speed,
      rotationSpeed,
      scale,
    });
  }
</pre>
<p>We also no longer need to deal with this stuff at render time.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
        uniformBuffer,
        uniformValues,
        normalMatrixValue,
        worldValue,
-        colorValue,
-        shininessValue,

        axis,
-        material,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];
      const mathTimeStartMs = performance.now();

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

-      const {color, shininess} = material;
-      colorValue.set(color);
-      shininessValue[0] = shininess;

      mathElapsedTimeMs += performance.now() - mathTimeStartMs;

      // upload the uniform values to the uniform buffer
      device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }
</pre>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-optimization-step4-material-uniforms.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-optimization-step4-material-uniforms.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<h1 id="optimization-use-one-large-uniform-buffer-with-buffer-offsets">Optimization: Use One large Uniform Buffer with buffer offsets</h1>
<p>Right now, each object has it‚Äôs own uniform buffer. At render time, for each
object, we update a typed array with the uniform values for that object and then
call <code class="notranslate" translate="no">device.queue.writeBuffer</code> to update that single uniform buffer‚Äôs values.
If we‚Äôre rendering 8000 objects that‚Äôs 8000 calls to <code class="notranslate" translate="no">device.queue.writeBuffer</code>.</p>
<p>Instead, we could make one larger uniform buffer. We can then setup the bind
group for each object to use it‚Äôs own portion of the larger buffer. At render
time, we can update all the values for all of the objects in one large typed
array and make just one call to <code class="notranslate" translate="no">device.queue.writeBuffer</code> which should be
faster.</p>
<p>First let‚Äôs allocate a large uniform buffer and large typed array. Uniform
buffer offsets have a minimum alignment which defaults to 256 bytes so we‚Äôll
round up the size we need per object to 256 bytes.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+/** Rounds up v to a multiple of alignment */
+const roundUp = (v, alignment) =&gt; Math.ceil(v / alignment) * alignment;

  ...

+  const uniformBufferSize = (12 + 16) * 4;
+  const uniformBufferSpace = roundUp(uniformBufferSize, device.limits.minUniformBufferOffsetAlignment);
+  const uniformBuffer = device.createBuffer({
+    label: 'uniforms',
+    size: uniformBufferSpace * maxObjects,
+    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
+  });
+  const uniformValues = new Float32Array(uniformBuffer.size / 4);
</pre>
<p>Now we can change the per object views to view into that large typedarray. We
can also set the bind group to use the correct portion of the large uniform
buffer.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  for (let i = 0; i &lt; maxObjects; ++i) {
+    const uniformBufferOffset = i * uniformBufferSpace;
+    const f32Offset = uniformBufferOffset / 4;

    // offsets to the various uniform values in float32 indices
    const kNormalMatrixOffset = 0;
    const kWorldOffset = 12;

-    const normalMatrixValue = uniformValues.subarray(
-        kNormalMatrixOffset, kNormalMatrixOffset + 12);
-    const worldValue = uniformValues.subarray(
-        kWorldOffset, kWorldOffset + 16);
+    const normalMatrixValue = uniformValues.subarray(
+        f32Offset + kNormalMatrixOffset, f32Offset + kNormalMatrixOffset + 12);
+    const worldValue = uniformValues.subarray(
+        f32Offset + kWorldOffset, f32Offset + kWorldOffset + 16);

    const material = randomArrayElement(materials);

    const bindGroup = device.createBindGroup({
      label: 'bind group for object',
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: material.texture.createView() },
        { binding: 1, resource: material.sampler },
-        { binding: 2, resource: { buffer: uniformBuffer }},
+        {
+          binding: 2,
+          resource: {
+            buffer: uniformBuffer,
+            offset: uniformBufferOffset,
+            size: uniformBufferSize,
+          },
+        },
        { binding: 3, resource: { buffer: globalUniformBuffer }},
        { binding: 4, resource: { buffer: material.materialUniformBuffer }},
      ],
    });

    const axis = vec3.normalize([rand(-1, 1), rand(-1, 1), rand(-1, 1)]);
    const radius = rand(10, 100);
    const speed = rand(0.1, 0.4);
    const rotationSpeed = rand(-1, 1);
    const scale = rand(2, 10);

    objectInfos.push({
      bindGroup,

-      uniformBuffer,
-      uniformValues,

      normalMatrixValue,
      worldValue,

      axis,
      radius,
      speed,
      rotationSpeed,
      scale,
    });
  }
</pre>
<p>At render time we update all the objects values and then make
just one call to <code class="notranslate" translate="no">device.queue.writeBuffer</code>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
-        uniformBuffer,
-        uniformValues,
        normalMatrixValue,
        worldValue,

        axis,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];
      const mathTimeStartMs = performance.now();

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

      mathElapsedTimeMs += performance.now() - mathTimeStartMs;

-      // upload the uniform values to the uniform buffer
-      device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }

+    // upload all uniform values to the uniform buffer
+    if (settings.numObjects) {
+      const size = (settings.numObjects - 1) * uniformBufferSpace + uniformBufferSize;
+      device.queue.writeBuffer( uniformBuffer, 0, uniformValues, 0, size / uniformValues.BYTES_PER_ELEMENT);
+    }

    pass.end();
</pre>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-optimization-step5-use-buffer-offsets.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-optimization-step5-use-buffer-offsets.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>On my machine that shaved off 40% of the JavaScript time!</p>
<h1 id="optimization-use-mapped-buffers">Optimization: Use Mapped Buffers</h1>
<p>When we call <code class="notranslate" translate="no">device.queue.writeBuffer</code>, what happens is, WebGPU makes a copy of
the data in the typed array. It copies that data to the GPU process (a separate
process that talks to the GPU for security). In the GPU process that data is
then copied to the GPU Buffer.</p>
<p>We can skip one of those copies by using mapped buffers instead. We‚Äôll map a
buffer, update the uniform values directly into that mapped buffer. Then we‚Äôll
unmap the buffer and issue a <code class="notranslate" translate="no">copyBufferToBuffer</code> command to copy to the uniform
buffer. This will save a copy.</p>
<p>WebGPU mapping happens asynchronously so rather then map a buffer and wait for
it to be ready, we‚Äôll keep an array of already mapped buffers. Each frame, we
either get an already mapped buffer or create a new one that is already mapped.
After we render, we‚Äôll setup a callback to map the buffer when it‚Äôs available
and put it back on the list of already mapped buffers. This way, we‚Äôll never
have to wait for a mapped buffer.</p>
<p>First we‚Äôll make an array of mapped buffers and a function to either get a
pre-mapped buffer or make a new one.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const mappedTransferBuffers = [];
  const getMappedTransferBuffer = () =&gt; {
    return mappedTransferBuffers.pop() || device.createBuffer({
      label: 'transfer buffer',
      size: uniformBufferSpace * maxObjects,
      usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC,
      mappedAtCreation: true,
    });
  };
</pre>
<p>We can‚Äôt pre-create typedarray views anymore because mapping
a buffer gives us a new <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer"><code class="notranslate" translate="no">ArrayBuffer</code></a>. So, we‚Äôll have to
make new typedarray views after mapping.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  // offsets to the various uniform values in float32 indices
+  const kNormalMatrixOffset = 0;
+  const kWorldOffset = 12;

  for (let i = 0; i &lt; maxObjects; ++i) {
    const uniformBufferOffset = i * uniformBufferSpace;
-    const f32Offset = uniformBufferOffset / 4;
-
-    // offsets to the various uniform values in float32 indices
-    const kNormalMatrixOffset = 0;
-    const kWorldOffset = 12;
-
-    const normalMatrixValue = uniformValues.subarray(
-        f32Offset + kNormalMatrixOffset, f32Offset + kNormalMatrixOffset + 12);
-    const worldValue = uniformValues.subarray(
-        f32Offset + kWorldOffset, f32Offset + kWorldOffset + 16);
-    const material = randomArrayElement(materials);

    const bindGroup = device.createBindGroup({
      label: 'bind group for object',
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: material.texture.createView() },
        { binding: 1, resource: material.sampler },
        { binding: 2, resource: { buffer: uniformBuffer, offset: uniformBufferOffset, size: uniformBufferSize }},
        { binding: 3, resource: { buffer: globalUniformBuffer }},
        { binding: 4, resource: { buffer: material.materialUniformBuffer }},
      ],
    });

    const axis = vec3.normalize([rand(-1, 1), rand(-1, 1), rand(-1, 1)]);
    const radius = rand(10, 100);
    const speed = rand(0.1, 0.4);
    const rotationSpeed = rand(-1, 1);
    const scale = rand(2, 10);

    objectInfos.push({
      bindGroup,

-      normalMatrixValue,
-      worldValue,

      axis,
      radius,
      speed,
      rotationSpeed,
      scale,
    });
  }
</pre>
<p>At render time we encode a command to copy the transfer buffer
to the uniform buffer <em>before</em> we start looping through the
objects. This is because the <code class="notranslate" translate="no">copyBufferToBuffer</code> command is
a command on the <a href="https://developer.mozilla.org/en-US/docs/Web/API/GPUCommandEncoder"><code class="notranslate" translate="no">GPUCommandEncoder</code></a>. We need it to run before
the objects are rendered but, as we loop over the object‚Äôs we‚Äôre
encoding render pass commands to render them. Before, we called
<code class="notranslate" translate="no">device.queue.writeBuffer</code> after updating the typed arrays, which
of course, executes first because we have no called <code class="notranslate" translate="no">submit</code> yet
on our commands. In this case though, our copy actually is a command
so we have to encode it before the draw commands. This is fine because
remember, it‚Äôs just a command, it will not be executed until we
submit the command buffer which means we can still update the transfer
buffer as the copy has not yet happened.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const encoder = device.createCommandEncoder();
-    const pass = timingHelper.beginRenderPass(encoder, renderPassDescriptor);
-    pass.setPipeline(pipeline);
-    pass.setVertexBuffer(0, vertexBuffer);
-    pass.setIndexBuffer(indicesBuffer, 'uint16');

    ...

    let mathElapsedTimeMs = 0;

+    const transferBuffer = getMappedTransferBuffer();
+    const uniformValues = new Float32Array(transferBuffer.getMappedRange());

+    // copy the uniform values from the transfer buffer to the uniform buffer
+    if (settings.numObjects) {
+      // Remember, this is just encoding a command that will happen later.
+      const size = (settings.numObjects - 1) * uniformBufferSpace + uniformBufferSize;
+      encoder.copyBufferToBuffer(transferBuffer, 0, uniformBuffer, 0, size);
+    }

+    const pass = timingHelper.beginRenderPass(encoder, renderPassDescriptor);
+    pass.setPipeline(pipeline);
+    pass.setVertexBuffer(0, vertexBuffer);
+    pass.setIndexBuffer(indicesBuffer, 'uint16');

    for (let i = 0; i &lt; settings.numObjects; ++i) {
      const {
        bindGroup,
-        normalMatrixValue,
-        worldValue,
        axis,
        radius,
        speed,
        rotationSpeed,
        scale,
      } = objectInfos[i];
      const mathTimeStartMs = performance.now();

+      // Make views into the mapped buffer.
+      const uniformBufferOffset = i * uniformBufferSpace;
+      const f32Offset = uniformBufferOffset / 4;
+      const normalMatrixValue = uniformValues.subarray(
+          f32Offset + kNormalMatrixOffset, f32Offset + kNormalMatrixOffset + 12);
+      const worldValue = uniformValues.subarray(
+          f32Offset + kWorldOffset, f32Offset + kWorldOffset + 16);

      // Compute a world matrix
      mat4.identity(worldValue);
      mat4.axisRotate(worldValue, axis, i + time * speed, worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 3.721 + time * speed) * radius], worldValue);
      mat4.translate(worldValue, [0, 0, Math.sin(i * 9.721 + time * 0.1) * radius], worldValue);
      mat4.rotateX(worldValue, time * rotationSpeed + i, worldValue);
      mat4.scale(worldValue, [scale, scale, scale], worldValue);

      // Inverse and transpose it into the normalMatrix value
      mat3.fromMat4(mat4.transpose(mat4.inverse(worldValue)), normalMatrixValue);

      mathElapsedTimeMs += performance.now() - mathTimeStartMs;

      pass.setBindGroup(0, bindGroup);
      pass.drawIndexed(numVertices);
    }
+    transferBuffer.unmap();

-    // upload all uniform values to the uniform buffer
-    if (settings.numObjects) {
-      const size = (settings.numObjects - 1) * uniformBufferSpace + uniformBufferSize;
-      device.queue.writeBuffer( uniformBuffer, 0, uniformValues, 0, size / uniformValues.BYTES_PER_ELEMENT);
-    }

    pass.end();

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
</pre>
<p>Finally, as soon as we‚Äôve submitted the command buffer we map the buffer again.
Mapping is asynchronous so when it‚Äôs finally ready we‚Äôll add it back to the list
of already mapped buffers.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    pass.end();

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);

+    transferBuffer.mapAsync(GPUMapMode.WRITE).then(() =&gt; {
+      mappedTransferBuffers.push(transferBuffer);
+    });
</pre>
<p>On my machine, this version draws around 15000 objects at 75fps. which is about
87% more than we started with.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-optimization-step6-use-mapped-buffers.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-optimization-step6-use-mapped-buffers.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>With rendering unchecked, the difference is even bigger. For me I get 9000 at
75fps with the original non-optimized example and 18000 at 75fps in this last
version. That‚Äôs a 2x speed up!</p>
<p>Other things that <em>might</em> help</p>
<ul>
<li>
<p><strong>Double buffer the large uniform buffer</strong></p>
<p>This comes up as a possible optimization because WebGPU can not update a
buffer that is currently in use.</p>
<p>So, imagine you start rendering (you call <code class="notranslate" translate="no">device.queue.submit</code>). The GPU
starts rendering using our large uniform buffer. You immediately try to update
that buffer. In this case, WebGPU would have to pause and wait for the GPU to
finish using the buffer for rendering.</p>
<p>This is unlikely to happen in our example above. We don‚Äôt directly update the
uniform buffer. Instead we update a transfer buffer and then later, ask the
GPU to copy it to the uniform buffer.</p>
<p>This issue would be more likely to come up if we update a buffer directly on
the GPU using a compute shader.</p>
</li>
<li>
<p><strong>Compute matrix math with offsets</strong></p>
<p>The math library we created in <a href="webgpu-matrix-math.html">the series on matrix math</a>
Generates <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code class="notranslate" translate="no">Float32Array</code></a>s as outputs and takes in <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code class="notranslate" translate="no">Float32Array</code></a>s as inputs.
It can modify a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code class="notranslate" translate="no">Float32Array</code></a> in place. But, what it can‚Äôt do is update a
<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code class="notranslate" translate="no">Float32Array</code></a> at some offset.</p>
<p>This is why, in our loop where we update our per object uniform values, for
each object we have to create 2 <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code class="notranslate" translate="no">Float32Array</code></a> views into our mapped buffer.
For 20000 objects that‚Äôs creating 40000 of these temporary views.</p>
<p>Adding offsets to every input would make them burdensome to use in my opinion
but, just as a test, I wrote a modified version of the math functions that
take an offset. In other words.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    mat4.multiply(a, b, dst);
</pre>
<p>becomes</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">   mat4.multiply(a, aOffset, b, bOffset, dst, dstOffset);
</pre>
<p><a href="../webgpu-optimization-step6-use-mapped-buffers-math-w-offsets.html">It appears to be about 7% faster to use the offsets</a>.</p>
<p>It‚Äôs up to you if you feel that‚Äôs worth it. For me personally, like I
mentioned at the top of the article, I‚Äôd prefer to keep it simple to use. I‚Äôm
rarely trying to draw 10000 things. But, it‚Äôs good to know, if I wanted to
squeeze out more performance, this is one place I might find some. More likely
I‚Äôd look into WebAssembly if I needed to go that far.</p>
</li>
<li>
<p><strong>Directly map the uniform buffer</strong></p>
<p>In our example above we map a transfer buffer, a buffer that only has
<code class="notranslate" translate="no">COPY_SRC</code> and <code class="notranslate" translate="no">MAP_WRITE</code> usage flags. We then have to call
<code class="notranslate" translate="no">encoder.copyBufferToBuffer</code> to copy the contents of that buffer into the
actual uniform buffer.</p>
<p>It would be much nicer if we could directly map the uniform buffer and avoid
the copy. Unfortunately, that ability is not available in WebGPU version 1 but
it is being considered as an optional feature sometime in the future,
especially for <em>uniform memory architectures</em> like some ARM based devices.</p>
</li>
<li>
<p><strong>Indirect Drawing</strong></p>
<p>Indirect drawing refers to draw commands that take their parameters from a GPU buffer.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">pass.draw(vertexCount, instanceCount, firstVertex, firstInstance);  // direct
pass.drawIndirect(someBuffer, offsetIntoSomeBuffer);                // indirect
</pre>
<p>In the indirect case above, <code class="notranslate" translate="no">someBuffer</code> is a 16 byte portion of a GPU buffer that holds
<code class="notranslate" translate="no">[vertexCount, instanceCount, firstVertex, firstInstance]</code>.</p>
<p>The advantage to indirect draw is that you can have the GPU itself fill out the values.
You can even have the GPU set <code class="notranslate" translate="no">vertexCount</code> and/or <code class="notranslate" translate="no">instanceCount</code> to zero when you
don‚Äôt want that thing to be drawn.</p>
<p>Using indirect drawing, you could do things like, for example, passing all of the
objects‚Äô bounding boxes or bounding spheres to the GPU and then have the GPU do
frustum culling and if the object is inside the frustum it would update that
object‚Äôs indirect drawing parameters to be drawn, otherwise it would update them
to not be drawn. ‚Äúfrustum culling‚Äù is a fancy way to say "check if the object
is possibly inside the frustum of the camera. We talked about frustums in
<a href="webgpu-persective-projection.html">the article on perspective projection</a>.</p>
</li>
<li>
<p><strong>Render Bundles</strong></p>
<p>Render bundles let you pre-record a bunch of command buffer commands and then
request them to be executed later. This can be useful, especially if your
scene is relatively static, meaning you don‚Äôt need to add or remove objects
later.</p>
<p>There‚Äôs a great article <a href="https://toji.dev/webgpu-best-practices/render-bundles">here</a>
that combines render bundles, indirect draws, GPU frustum culling, to show
some ideas for getting more speed in specialized situations.</p>
</li>
</ul>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-optimization.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-optimization.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-optimization.html">Êó•Êú¨Ë™û
    </option><option value="/webgpu/lessons/ko/webgpu-optimization.html">ÌïúÍµ≠Ïñ¥
    </option><option value="/webgpu/lessons/ru/webgpu-optimization.html">–†—É—Å—Å–∫–∏–π
    </option><option value="/webgpu/lessons/uk/webgpu-optimization.html">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
    </option><option value="/webgpu/lessons/zh_cn/webgpu-optimization.html">ÁÆÄ‰Ωì‰∏≠Êñá
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
  <li>Textures</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-importing-textures.html">Loading Images</a></li>
<li><a href="/webgpu/lessons/webgpu-textures-external-video.html">Using Video</a></li>
<li><a href="/webgpu/lessons/webgpu-cube-maps.html">Cube Maps</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-textures.html">Storage Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-multisampling.html">Multisampling / MSAA</a></li>
        </ul>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-transparency.html">Transparency and Blending</a></li>
<li><a href="/webgpu/lessons/webgpu-bind-group-layouts.html">Bind Group Layouts</a></li>
<li><a href="/webgpu/lessons/webgpu-copying-data.html">Copying Data</a></li>
<li><a href="/webgpu/lessons/webgpu-limits-and-features.html">Optional Features and Limits</a></li>
<li><a href="/webgpu/lessons/webgpu-timing.html">Timing Performance</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
        </ul>
  <li>3D Math</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-translation.html">Translation</a></li>
<li><a href="/webgpu/lessons/webgpu-rotation.html">Rotation</a></li>
<li><a href="/webgpu/lessons/webgpu-scale.html">Scale</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-math.html">Matrix Math</a></li>
<li><a href="/webgpu/lessons/webgpu-orthographic-projection.html">Orthographic Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-perspective-projection.html">Perspective Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-cameras.html">Cameras</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-stacks.html">Matrix Stacks</a></li>
<li><a href="/webgpu/lessons/webgpu-scene-graphs.html">Scene Graphs</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-large-triangle-to-cover-clip-space.html">Large Clip Space Triangle</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-environment-maps.html">Environment maps</a></li>
<li><a href="/webgpu/lessons/webgpu-skybox.html">Skyboxes</a></li>
        </ul>
        </ul>
  <li>Compute Shaders</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-compute-shaders.html">Compute Shader Basics</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram.html">Image Histogram</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram-part-2.html">Image Histogram Part 2</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgpu/lessons/webgpu-multiple-canvases.html">Multiple Canvases</a></li>
<li><a href="/webgpu/lessons/webgpu-points.html">Points</a></li>
<li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-optimization.html">Speed and Optimization</a></li>
<li><a href="/webgpu/lessons/webgpu-debugging.html">Debugging and Errors</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl-function-reference.html">WGSL Function Reference</a></li>
<li><a href="/webgpu/lessons/resources/wgsl-offset-computer.html">WGSL Offset Computer</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/webgpu/webgpufundamentals">github</a></li>
  <li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
  <li><a href="https://webgpureport.org">WebGPUReport.org</a></li>
  <li><a href="https://web3dsurvey.com/webgpu">Web3DSurvey.com</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
<div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
<div>
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
</div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Speed and Optimization`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js" type="module"></script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-92BFT5PE4H"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-92BFT5PE4H');
</script>






</body></html>