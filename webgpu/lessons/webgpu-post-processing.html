<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-post-processing.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Post Processing">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-post-processing_en.jpg">

<meta property="og:title" content="WebGPU Post Processing - Basic CRT Effect">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-post-processing_en.jpg">
<meta property="og:description" content="Post Processing">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Post Processing - Basic CRT Effect">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html">
<meta name="twitter:description" content="Post Processing">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-post-processing_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-post-processing_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html",
      "inLanguage":"en",
      "name":"WebGPU Post Processing - Basic CRT Effect",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-post-processing.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Post Processing - Basic CRT Effect</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">

<link rel="stylesheet" href="/webgpu/lessons/lang.css">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-post-processing.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-post-processing.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-post-processing.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-post-processing.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-post-processing.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-post-processing.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-post-processing.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-post-processing.html">简体中文
</option></select>


    <a href="#toc">Table of Contents</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub">
  <div>
    <div><a href="https://github.com/webgpu/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div>
  </div>
</div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Post Processing - Basic CRT Effect</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>Post Processing just means to do some processing after you’ve created the “original” image.
Post processing can apply to a photo, a video, a 2d scene, a 3d scene. It just generally
means you have an image and you apply some effects to that image, like choosing a filter
in Instagram.</p>
<p>In almost every example on this site we render to the canvas texture. To do post processing
we instead render to a different texture. Then render that texture to the canvas while
applying some image processing effects.</p>
<p>As a simple example, let’s try to post process an image to make it kind of look like a 1980s TV
with scanlines and CRT RGB elements.</p>
<div class="webgpu_center"><img class="nobg" src="resources/gemini-generated-1980s-tv-1024.png" style="width: 700px"></div>
<p>To do that, lets take the animated example from the top of <a href="webgpu-timing.html">the article on timing</a>.
The first thing we’ll do is make it render to a separate texture and then render that texture
to the canvas.</p>
<p>Here’s a shader that draws a <a href="webgpu-large-triangle-to-cover-clip-space.html">large clip space triangle</a>.
and passes the correct UV coordinates to let as draw a texture that covers the portion of the triangle
that fits in clip space.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessModule = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32,
      ) -&gt; VSOutput {
        var pos = array(
          vec2f(-1.0, -1.0),
          vec2f(-1.0,  3.0),
          vec2f( 3.0, -1.0),
        );

        var vsOutput: VSOutput;
        let xy = pos[vertexIndex];
        vsOutput.position = vec4f(xy, 0.0, 1.0);
        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
        return vsOutput;
      }

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;

      @fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
        return vec4f(color);
      }
    `,
  })
</pre>
<p>It’s pretty straight forward and is similar to the shader we used to generate mipmaps
in <a href="webgpu-importing-textures.html">the article on using images with textures</a>. The
only major difference is the original shader uses 2 triangles to cover clip space,
this one uses <a href="webgpu-large-triangle-to-cover-clip-space.html">1 large triangle</a>.</p>
<p>Then, to use these shaders we need a pipeline</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessPipeline = device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: postProcessModule },
    fragment: {
      module: postProcessModule,
      targets: [ { format: presentationFormat }],
    },
  });
</pre>
<p>This pipeline will be rendering to the canvas so we need to
set the target format as the <code class="notranslate" translate="no">presentationFormat</code> we looked up before.</p>
<p>We’ll need a sampler, and a renderPassDescriptor.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  const postProcessRenderPassDescriptor = {
    label: 'post process render pass',
    colorAttachments: [
      { loadOp: 'clear', storeOp: 'store' },
    ],
  };
</pre>
<p>Then, instead of having our original renderPass render
to the canvas, we need it to render to a separate texture.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  let renderTarget;
+
+  function setupPostProcess(canvasTexture) {
+    if (renderTarget?.width === canvasTexture.width &amp;&amp;
+        renderTarget?.height === canvasTexture.height) {
+      return;
+    }
+
+    renderTarget?.destroy();
+    renderTarget = device.createTexture({
+      size: canvasTexture,
+      format: 'rgba8unorm',
+      usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
+    });
+    const renderTargetView = renderTarget.createView();
+    renderPassDescriptor.colorAttachments[0].view = renderTargetView;
+  }

  let then = 0;
  function render(now) {
    now *= 0.001;  // convert to seconds
    const deltaTime = now - then;
    then = now;

-    // Get the current texture from the canvas context and
-    // set it as the texture to render to.
-    renderPassDescriptor.colorAttachments[0].view =
-        context.getCurrentTexture().createView();
+    const canvasTexture = context.getCurrentTexture();
+    setupPostProcess(canvasTexture);

    ...
</pre>
<p>Above, we pass the current <code class="notranslate" translate="no">canvasTexture</code> into <code class="notranslate" translate="no">setupPostProcess</code>.
It checks if the size of our “renderTarget” texture is the same size
as the canvas. If not, it creates a new texture the same size.</p>
<p>It then sets our original <code class="notranslate" translate="no">renderPassDescriptor</code>’s color attachment
to this renderTarget texture.</p>
<p>Since our old pipeline will render to this texture we need to update
it for the format of this texture</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const pipeline = device.createRenderPipeline({
    label: 'per vertex color',
    layout: 'auto',
    vertex: {
      module,
      buffers: [
        ...
      ],
    },
    fragment: {
      module,
-      targets: [{ format: presentationFormat }],
+      targets: [{ format: 'rgba8unorm' }],
    },
  });
</pre>
<p>These change alone would make it start rendering the original scene to this
render target texture but we still need to draw something to the canvas
or we won’t see anything so lets do that.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function postProcess(encoder, srcTexture, dstTexture) {
    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }

  ...


  let then = 0;
  function render(now) {
    now *= 0.001;  // convert to seconds
    const deltaTime = now - then;
    then = now;

    const canvasTexture = context.getCurrentTexture();
    setupPostProcess(canvasTexture);

    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass(renderPassDescriptor);

    ...

    pass.draw(numVertices, settings.numObjects);

    pass.end();

+    postProcess(encoder, renderTarget, canvasTexture);

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);

    requestAnimationFrame(render);
  }
  requestAnimationFrame(render);
</pre>
<p>The only other tweak let’s make. Let’s get rid of the object count setting
since it’s not relevant to post processing.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
-    numObjects: 100,
+    numObjects: 200,
  };

  const gui = new GUI();
-  gui.add(settings, 'numObjects', 0, kNumObjects, 1);
</pre>
<p>We could have gotten rid of <code class="notranslate" translate="no">settings.numObjects</code> completely but it requires
edits in several different places and so let’s leave it for now. We’ll set the
number to 200 just to fill the image.</p>
<p>If we run this there’s not visible difference from our original.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-step-01.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-step-01.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>The difference is we’re rendering to the renderTarget texture
and then rendering that texture to the canvas so now we can start
applying some effects.</p>
<p>The most obvious effect of an old CRT is old CRTs have visible scanlines.
This is because the way the image was projected was by using magnets
to direct a beam across the screen in a pattern of horizontal lines.</p>
<p>We can get a similar effect just by generating a pattern of light
and dark using a sine wave and taking the absolute value.</p>
<div class="webgpu_center">
  <div style="width: 100%;"><img class="ddnobg" src="resources/sinewave-40.svg"></div>
  <div lass="caption">sin(x)</div>
</div>
<div class="webgpu_center">
   <div style="width: 100%;"><img class="ddnobg" src="resources/abs-sinewave-40.svg"></div>
   <div class="caption">abs(sin(x))</div>
</div>
<div class="webgpu_center">
   <div style="width: 100%;"><div data-diagram="sine" style="aspect-ratio: 981 / 50; width: 100%;"></div></div>
   <div class="caption">abs(sin(x)) as gray scale color</div>
</div>
<p>Let’s add that to the code. First let’s edit the shader to apply this sine wave.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessModule = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32,
      ) -&gt; VSOutput {
        var pos = array(
          vec2f(-1.0, -1.0),
          vec2f(-1.0,  3.0),
          vec2f( 3.0, -1.0),
        );

        var vsOutput: VSOutput;
        let xy = pos[vertexIndex];
        vsOutput.position = vec4f(xy, 0.0, 1.0);
        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
        return vsOutput;
      }

+      struct Uniforms {
+        effectAmount: f32,
+        bandMult: f32,
+      };

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;
+      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

      @fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
+        let banding = abs(sin(fsInput.position.y * uni.bandMult));
+        let effect = mix(1.0, banding, uni.effectAmount);

        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
-        return vec4f(color);
+        return vec4f(color.rgb * effect, color.a);
      }
    `,
  });
</pre>
<p>Our sine wave is based on <code class="notranslate" translate="no">fsInput.position.y</code> which is the y coordinate of the pixel being
written to. In other words, for each scanline starting at 0 it will go 0.5, 1.5, 2.5, 3.5, etc…
<code class="notranslate" translate="no">bendMult</code> will let us adjust the size of the bands and <code class="notranslate" translate="no">effectAmount</code> will let us turn
the effect on and off so we can compare effect to no effect.</p>
<p>To use the new shader we need up a uniform buffer.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessUniformBuffer = device.createBuffer({
    size: 8,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
</pre>
<p>We need to add it to our bind group</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    postProcessBindGroup = device.createBindGroup({
      layout: postProcessPipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: renderTargetView },
        { binding: 1, resource: postProcessSampler },
+        { binding: 2, resource: postProcessUniformBuffer },
      ],
    });
</pre>
<p>And, we need to add some settings</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
    numObjects: 200,
+    affectAmount: 1,
+    bandMult: 1,
  };

  const gui = new GUI();
+  gui.add(settings, 'affectAmount', 0, 1);
+  gui.add(settings, 'bandMult', 0.01, 2.0);
</pre>
<p>and we need to upload those settings to the uniform buffer</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function postProcess(encoder, srcTexture, dstTexture) {
+    device.queue.writeBuffer(
+      postProcessUniformBuffer,
+      0,
+      new Float32Array([
+        settings.affectAmount,
+        settings.bandMult,
+      ]),
+    );

    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }
</pre>
<p>And that gives us a CRT like scanline effect.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-step-02.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-step-02.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>CRTs, like LCDs, split the image into red, green, and blue areas.
On CRTs those areas were generally larger than most LCDs today so
sometimes this stuck out. Let’s add something to approximate that effect.</p>
<p>First let’s change the shader</p>
<pre class="prettyprint showlinemods notranslate notranslate" translate="no">  const postProcessModule = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32,
      ) -&gt; VSOutput {
        var pos = array(
          vec2f(-1.0, -1.0),
          vec2f(-1.0,  3.0),
          vec2f( 3.0, -1.0),
        );

        var vsOutput: VSOutput;
        let xy = pos[vertexIndex];
        vsOutput.position = vec4f(xy, 0.0, 1.0);
        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
        return vsOutput;
      }

      struct Uniforms {
        effectAmount: f32,
        bandMult: f32,
+        cellMult: f32,
+        cellBright: f32,
      };

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;

      @fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
        let banding = abs(sin(fsInput.position.y * uni.bandMult));

+        let cellNdx = u32(fsInput.position.x * uni.cellMult) % 3;
+        var cellColor = vec3f(0);
+        cellColor[cellNdx] = 1;
+        let cMult = cellColors[cellNdx] + uni.cellBright;

-        let effect = mix(1.0, banding, uni.effectAmount);
+        let effect = mix(vec3f(1), banding * cMult, uni.effectAmount);
        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
        return vec4f(color.rgb * effect, 1);
      }
    `,
  });
</pre>
<p>Above we’re using <code class="notranslate" translate="no">fsInput.position.x</code> which is the x coordinate of the
pixel being written to. By multiplying by <code class="notranslate" translate="no">cellMult</code> we can choose a cell
size. We convert to an integer and modulo 3. This gives us a number, 0, 1, or 2
which we use to set the red, green, or blue channel of <code class="notranslate" translate="no">cellColor</code> to 1.</p>
<p>We add in <code class="notranslate" translate="no">cellBright</code> as an adjustment and then multiply both the old banding
and the new effect together. <code class="notranslate" translate="no">effect</code> changed from an <code class="notranslate" translate="no">f32</code> to a <code class="notranslate" translate="no">vec3f</code> so it
can affect each channel independently.</p>
<p>Back in JavaScript we need to adjust the size of the uniform buffer</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessUniformBuffer = device.createBuffer({
-    size: 8,
+    size: 16,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
</pre>
<p>And add some settings to the GUI</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const settings = {
    numObjects: 200,
    affectAmount: 1,
    bandMult: 1,
+    cellMult: 0.5,
+    cellBright: 1,
  };

  const gui = new GUI();
  gui.add(settings, 'affectAmount', 0, 1);
  gui.add(settings, 'bandMult', 0.01, 2.0);
+  gui.add(settings, 'cellMult', 0, 1);
+  gui.add(settings, 'cellBright', 0, 2);
</pre>
<p>and upload the new settings</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  function postProcess(encoder, srcTexture, dstTexture) {
    device.queue.writeBuffer(
      postProcessUniformBuffer,
      0,
      new Float32Array([
        settings.affectAmount,
        settings.bandMult,
+        settings.cellMult,
+        settings.cellBright,
      ]),
    );

    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }
</pre>
<p>And now we have a CRT color element <em>like</em> effect.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-step-03.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-step-03.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>The effects above are not meant to be perfect representations of how a CRT works.
Rather they were just meant to hint at looking like a CRT and be hopefully easy to
to understand. You can find fancier techniques all over the web.</p>
<h2 id="using-a-compute-shader"><a id="compute"></a> Using a Compute Shader</h2>
<p>The topic comes up, could we use a compute shader for this, and, maybe
more importantly, should we? Let’s cover “can we first”.</p>
<p>We covered using a compute shader to render to a texture in
<a href="webgpu-storage-textures.html">the article on storage textures</a>.</p>
<p>To convert our code to use a compute shader we need to add
the <code class="notranslate" translate="no">STORAGE_BINDING</code> usage to the canvas texture which, from
<a href="webgpu-storage-textures.html">the afore mentioned article</a> requires
checking we can and choosing a texture format that supports it.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
+  const hasBGRA8UnormStorage = adapter?.features.has('bgra8unorm-storage');
-  const device = await adapter?.requestDevice();
+  const device = await adapter?.requestDevice({
+    requiredFeatures: [
+      ...(hasBGRA8UnormStorage ? ['bgra8unorm-storage'] : []),
+    ],
+  });
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }

  // Get a WebGPU context from the canvas and configure it
  const canvas = document.querySelector('canvas');
  const context = canvas.getContext('webgpu');
-  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
+  const presentationFormat = hasBGRA8UnormStorage
+    ? navigator.gpu.getPreferredCanvasFormat()
+    : 'rgab8unorm';
  context.configure({
    device,
    format: presentationFormat,
+    usage: GPUTextureUsage.RENDER_ATTACHMENT |
+           GPUTextureUsage.TEXTURE_BINDING |
+           GPUTextureUsage.STORAGE_BINDING,
  });
</pre>
<p>We need to switch our shader to write to a storage texture</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessModule = device.createShaderModule({
    code: `
-      struct VSOutput {
-        @builtin(position) position: vec4f,
-        @location(0) texcoord: vec2f,
-      };
-
-      @vertex fn vs(
-        @builtin(vertex_index) vertexIndex : u32,
-      ) -&gt; VSOutput {
-        var pos = array(
-          vec2f(-1.0, -1.0),
-          vec2f(-1.0,  3.0),
-          vec2f( 3.0, -1.0),
-        );
-
-        var vsOutput: VSOutput;
-        let xy = pos[vertexIndex];
-        vsOutput.position = vec4f(xy, 0.0, 1.0);
-        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
-        return vsOutput;
-      }

      struct Uniforms {
        effectAmount: f32,
        bandMult: f32,
        cellMult: f32,
        cellBright: f32,
      };

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;
+      @group(1) @binding(0) var outTexture: texture_storage_2d&lt;${presentationFormat}, write&gt;;

-      @fragment fn fs2d(fsInput: VSOutput) -&gt; @location(0) vec4f {
-        let banding = abs(sin(fsInput.position.y * uni.bandMult));
-
-        let cellNdx = u32(fsInput.position.x * uni.cellMult) % 3;
+      @compute @workgroup_size(1) fn cs(@builtin(global_invocation_id) gid: vec3u) {
+        let outSize = textureDimensions(outTexture);
+        let banding = abs(sin(f32(gid.y) * uni.bandMult));
+
+        let cellNdx = u32(f32(gid.x) * uni.cellMult) % 3;
        var cellColor = vec3f(0);
        cellColor[cellNdx] = 1.0;
        let cMult = cellColor + uni.cellBright;

        let effect = mix(vec3f(1), banding * cMult, uni.effectAmount);
-        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
-        return vec4f(color.rgb * effect, color.a);
+        let uv = (vec2f(gid.xy) + 0.5) / vec2f(outSize);
+        let color = textureSampleLevel(postTexture2d, postSampler, uv, 0);
+        textureStore(outTexture, gid.xy, vec4f(color.rgb * effect, color.a));
      }
    `,
  });
</pre>
<p>Above we got rid of the vertex shader and related parts. We also no longer have <code class="notranslate" translate="no">fsInput.position</code>
which was the coordinate of the pixel being written to. Instead we have <code class="notranslate" translate="no">gid</code> which is
the <code class="notranslate" translate="no">global_invocation_id</code> of an individual invocation of our compute shader. We’ll use this
as our texture coordinate. It’s a <code class="notranslate" translate="no">vec3u</code> so we need to cast here and there. We also
no longer have <code class="notranslate" translate="no">fsInput.texcoord</code> but we can get the equivalent with
<code class="notranslate" translate="no">(vec2f(gid.xy) + 0.5) / vec2f(outSize)</code>.</p>
<p>We need to stop using a render pass and instead use a compute pass for our post processing.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const postProcessPipeline = device.createRenderPipeline({
    layout: 'auto',
-    vertex: { module: postProcessModule },
-    fragment: {
-      module: postProcessModule,
-      targets: [ { format: presentationFormat }],
-    },
+    compute: { module: postProcessModule },
  });

  function postProcess(encoder, srcTexture, dstTexture) {
    device.queue.writeBuffer(
      postProcessUniformBuffer,
      0,
      new Float32Array([
        settings.affectAmount,
        settings.bandMult,
        settings.cellMult,
        settings.cellBright,
      ]),
    );

+    const outBindGroup = device.createBindGroup({
+      layout: postProcessPipeline.getBindGroupLayout(1),
+      entries: [
+        { binding: 0, resource: dstTexture.createView() },
+      ],
+    });

-    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
-    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
+    const pass = encoder.beginComputePass();
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
-    pass.draw(3);
+    pass.dispatchWorkgroups(dstTexture.width, dstTexture.height);
    pass.end();
  }
</pre>
<p>That works</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-step-03-compute.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-step-03-compute.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Unfortunately, depending on the GPU, it’s slow! We covered some of why in
<a href="webgpu-compute-shaders-historgram.html">the article on optimizing compute shaders</a>.
Using a workgroup size of 1 makes things easy but it’s slow.</p>
<p>We can update to use a larger workgroup size. This requires us to skip writing
to the texture when we’re out of bounds.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const workgroupSize = [16, 16];
  const postProcessModule = device.createShaderModule({
    code: `
      struct Uniforms {
        effectAmount: f32,
        bandMult: f32,
        cellMult: f32,
        cellBright: f32,
      };

      @group(0) @binding(0) var postTexture2d: texture_2d&lt;f32&gt;;
      @group(0) @binding(1) var postSampler: sampler;
      @group(0) @binding(2) var&lt;uniform&gt; uni: Uniforms;
      @group(1) @binding(0) var outTexture: texture_storage_2d&lt;${presentationFormat}, write&gt;;

-      @compute @workgroup_size(1) fn cs(@builtin(global_invocation_id) gid: vec3u) {
+      @compute @workgroup_size(${workgroupSize}) fn cs(@builtin(global_invocation_id) gid: vec3u) {
        let outSize = textureDimensions(outTexture);
+        if (gid.x &gt;= outSize.x || gid.y &gt;= outSize.y) {
+          return;
+        }
        let banding = abs(sin(f32(gid.y) * uni.bandMult));

        let cellNdx = u32(f32(gid.x) * uni.cellMult) % 3;
        var cellColor = vec3f(0);
        cellColor[cellNdx] = 1.0;
        let cMult = cellColor + uni.cellBright;

        let effect = mix(vec3f(1), banding * cMult, uni.effectAmount);
        let uv = (vec2f(gid.xy) + 0.5) / vec2f(outSize);
        let color = textureSampleLevel(postTexture2d, postSampler, uv, 0);
        textureStore(outTexture, gid.xy, vec4f(color.rgb * effect, color.a));
      }
    `,
  });
</pre>
<p>And then we need to dispatch less workgroups</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">    const pass = encoder.beginComputePass();
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.setBindGroup(1, outBindGroup);
-    pass.dispatchWorkgroups(dstTexture.width, dstTexture.height);
+    pass.dispatchWorkgroups(
+      Math.ceil(dstTexture.width / workgroupSize[0]),
+      Math.ceil(dstTexture.height / workgroupSize[1]),
+    );
    pass.end();
</pre>
<p>This works</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-post-processing-step-03-compute-workgroups.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-post-processing-step-03-compute-workgroups.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>This is much faster! But, unfortunately, on some GPUs it is still slower than using a render pass.</p>
<div class="webgpu_center data-table">
  <table>
    <thead>
      <tr><th>GPU</th><th>Compute pass time vs<br>Render pass time<br>(higher is worse)</th></tr>
    </thead>
    <tbody>
      <tr><td>M1 Mac                 </td><td>1x</td></tr>
      <tr><td>AMD Radeon Pro 5300M   </td><td>1x</td></tr>
      <tr><td>AMD Radeon Pro WX 32000</td><td>1.3x</td></tr>
      <tr><td>Intel UHD Graphics 630 </td><td>1.7x</td></tr>
      <tr><td>NVidia 2070 Super      </td><td>2x</td></tr>
    </tbody>
  </table>
</div>
<p>Going into how to make it faster is too big of a topic for this particular article.
Referencing <a href="webgpu-compute-shaders-historgram.html">the article on optimizing compute shaders</a>,
the same rules apply. Unfortunately none of them are really relevant to this example.
If the post processing you’re trying to do could benefit from shared workgroup memory
then maybe using a compute shader would be beneficial. Access patterns might be relevant
too to try to make sure the GPU isn’t getting lots of cache misses. Yet another might
be taking advantage of <a href="webgpu-subgroups.html">subgroups</a>.</p>
<p>For now, it’s recommended you try different techniques and checking their timing.
Or, stick with render passes unless the algorithm you’re implementing could truly
benefit from the shared data of workgroups and or subgroups. GPUs have been rendering
to textures for much longer than they’ve been running compute shaders so many things
about that process are highly optimized.</p>
<!-- keep this at the bottom of the article -->
<link href="webgpu-post-processing.css" rel="stylesheet">
<script type="module" src="webgpu-post-processing.js"></script>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-post-processing.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-post-processing.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-post-processing.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-post-processing.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-post-processing.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-post-processing.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-post-processing.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-post-processing.html">简体中文
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
  <li>Textures</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-importing-textures.html">Loading Images</a></li>
<li><a href="/webgpu/lessons/webgpu-textures-external-video.html">Using Video</a></li>
<li><a href="/webgpu/lessons/webgpu-cube-maps.html">Cube Maps</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-textures.html">Storage Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-multisampling.html">Multisampling / MSAA</a></li>
        </ul>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-transparency.html">Transparency and Blending</a></li>
<li><a href="/webgpu/lessons/webgpu-bind-group-layouts.html">Bind Group Layouts</a></li>
<li><a href="/webgpu/lessons/webgpu-copying-data.html">Copying Data</a></li>
<li><a href="/webgpu/lessons/webgpu-limits-and-features.html">Optional Features and Limits</a></li>
<li><a href="/webgpu/lessons/webgpu-timing.html">Timing Performance</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
<li><a href="/webgpu/lessons/webgpu-compatibility-mode.html">Compatibility Mode</a></li>
        </ul>
  <li>3D Math</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-translation.html">Translation</a></li>
<li><a href="/webgpu/lessons/webgpu-rotation.html">Rotation</a></li>
<li><a href="/webgpu/lessons/webgpu-scale.html">Scale</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-math.html">Matrix Math</a></li>
<li><a href="/webgpu/lessons/webgpu-orthographic-projection.html">Orthographic Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-perspective-projection.html">Perspective Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-cameras.html">Cameras</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-stacks.html">Matrix Stacks</a></li>
<li><a href="/webgpu/lessons/webgpu-scene-graphs.html">Scene Graphs</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-large-triangle-to-cover-clip-space.html">Large Clip Space Triangle</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-environment-maps.html">Environment maps</a></li>
<li><a href="/webgpu/lessons/webgpu-skybox.html">Skyboxes</a></li>
        </ul>
  <li>Post Processing</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-post-processing.html">Basic CRT Effect</a></li>
        </ul>
        </ul>
  <li>Compute Shaders</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-compute-shaders.html">Compute Shader Basics</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram.html">Image Histogram</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram-part-2.html">Image Histogram Part 2</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgpu/lessons/webgpu-multiple-canvases.html">Multiple Canvases</a></li>
<li><a href="/webgpu/lessons/webgpu-points.html">Points</a></li>
<li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-optimization.html">Speed and Optimization</a></li>
<li><a href="/webgpu/lessons/webgpu-debugging.html">Debugging and Errors</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl-function-reference.html">WGSL Function Reference</a></li>
<li><a href="/webgpu/lessons/resources/wgsl-offset-computer.html">WGSL Offset Computer</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/webgpu/webgpufundamentals">github</a></li>
  <li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
  <li><a href="https://webgpureport.org">WebGPUReport.org</a></li>
  <li><a href="https://web3dsurvey.com/webgpu">Web3DSurvey.com</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
<div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
<div>
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
</div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Post Processing - Basic CRT Effect`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js" type="module"></script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-92BFT5PE4H"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-92BFT5PE4H');
</script>






</body></html>