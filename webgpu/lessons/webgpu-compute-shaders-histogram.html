<!DOCTYPE html><!-- this file is auto-generated from webgpu/lessons/webgpu-compute-shaders-histogram.md. Do not edited directly --><!--
Copyright 2023, GfxFundamentals Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer
  in the documentation and/or other materials provided with the
  distribution.

* Neither the name of GfxFundamentals nor the names of the
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


--><html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Efficiently compute an image histogram.">
<meta name="keywords" content="webgpu graphics">
<meta name="thumbnail" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-compute-shaders-histogram_en.jpg">

<meta property="og:title" content="WebGPU Compute Shaders - Image Histogram">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-compute-shaders-histogram_en.jpg">
<meta property="og:description" content="Efficiently compute an image histogram.">
<meta property="og:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgpufundamentals.org">
<meta name="twitter:title" content="WebGPU Compute Shaders - Image Histogram">
<meta name="twitter:url" content="https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html">
<meta name="twitter:description" content="Efficiently compute an image histogram.">
<meta name="twitter:image:src" content="https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-compute-shaders-histogram_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgpufundamentals.org/#website",
      "url":"https://webgpufundamentals.org/",
      "name":"webgpufundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html#primaryimage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/screenshots/webgpu-compute-shaders-histogram_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html#webpage",
      "url":"https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html",
      "inLanguage":"en",
      "name":"WebGPU Compute Shaders - Image Histogram",
      "keywords":"webgpu graphics programming",
      "isPartOf":{
        "@id":"https://webgpufundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgpufundamentals.org/webgpu/lessons/webgpu-compute-shaders-histogram.html#primaryimage"
      }
    }
  ]
}
</script>

<title>WebGPU Compute Shaders - Image Histogram</title>
<link href="/webgpu/lessons/resources/webgpufundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="apple-touch-icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">
<link rel="icon" href="/webgpu/lessons/resources/webgpufundamentals-icon.png">

<link rel="stylesheet" href="/webgpu/lessons/lang.css">
<link rel="stylesheet" href="/webgpu/lessons/resources/lesson.css">
</head>
<body>
<div class="webgpu_navbar">
  <div>
    <select class="language">
    <option value="/webgpu/lessons/webgpu-compute-shaders-histogram.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-compute-shaders-histogram.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-compute-shaders-histogram.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-compute-shaders-histogram.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-compute-shaders-histogram.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-compute-shaders-histogram.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-compute-shaders-histogram.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-compute-shaders-histogram.html">简体中文
</option></select>


    <a href="#toc">Table of Contents</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgpu_header">
  <h1><a href="/">webgpufundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(160px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub">
  <div>
    <div><a href="https://github.com/webgpu/webgpufundamentals">Fix, Fork, Contribute <!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"></path>
    </g>
</svg>
</a></div>
  </div>
</div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGPU Compute Shaders - Image Histogram</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>This article continues from <a href="webgpu-compute-shaders.html">the article on compute shader basics</a>.</p>
<p>This is going to be a long 2 part article and we’re going to take many steps to
optimize things. This optimization will make things faster but the output will
unfortunately not change the result so each step will look the same as the
previous step.</p>
<p>Further, we’re going to mention speed and timing but the articles
and examples would get even longer if we added the code to do the timing so
we’ll leave timing to <a href="webgpu-timing.html">another article</a> and in these
articles I’ll just mention my own timing and provide some run-able examples.
Hopefully this article will provide one example of making a compute shader.</p>
<p>An image histogram is where you sum up all the pixels in an image by their values or
by some measure of their values.</p>
<p>For example, this 6x7 image</p>
<div class="webgpu_center">
  <div>
    <div data-diagram="image" style="display: inline-block; width: 240px; max-width: 100%;"></div>
    <div style="text-align: center;">6x7</div>
  </div>
</div>
<p>It has these colors.</p>
<div class="webgpu_center">
  <div>
    <div data-diagram="colors" style="display: inline-block; width: 240px; max-width: 100%;"></div>
  </div>
</div>
<p>For each color we can compute a luminance level, (how bright it is). Looking online I found this
formula</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">// Returns a value from 0 to 1 for luminance.
// where r, g, b each go from 0 to 1.
function srgbLuminance(r, g, b) {
  // from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
  return r * 0.2126 +
         g * 0.7152 +
         b * 0.0722;
}
</pre>
<p>Using that we can convert each value to a luminance level</p>
<div class="webgpu_center">
  <div>
    <div data-diagram="luminance" style="display: inline-block; width: 240px; max-width: 100%;"></div>
  </div>
</div>
<p>We can decide on a number “bins”. Let’s decide on 3 bins.
We can then quantize those luminance values so they select a “bin”
and add up the number of pixels that fit in each bin.</p>
<div class="webgpu_center">
  <div>
    <div data-diagram="imageHistogram" style="display: inline-block; width: 40px; max-width: 100%;"></div>
  </div>
</div>
<p>Finally we can graph the values in those bins</p>
<div class="webgpu_center">
  <div>
    <div data-diagram="imageHistogramGraph" style="display: inline-block; width: 96px; max-width: 100%;"></div>
  </div>
</div>
<p>The graph shows that there are more dark pixels (🟦 18) than medium brightness pixels (🟥 16) and
even fewer bright pixels (🟨 8). That’s not so interesting with just 3 bins. But, if we take a picture like this</p>
<div class="webgpu_center">
  <div>
    <div><img src="../resources/images/pexels-francesco-ungaro-96938-mid.jpg" style="width: 700px;"></div>
    <div style="text-align: center;"><a href="https://www.pexels.com/photo/cute-kitten-hiding-behind-a-pillow-96938/">Photo by Francesco Ungaro</a></div>
  </div>
</div>
<p>and we count up the pixel luminance values, separate them into say 256 bins, and graph them, we get something like this</p>
<div class="webgpu_center center">
  <div>
    <div><img src="resources/histogram-luminosity-photoshop.png" style="width: 237px;" class="nobg"></div>
  </div>
</div>
<p>Computing an image histogram is pretty simple. Let’s first do it in JavaScript</p>
<p>Let’s make a function that given an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageData"><code class="notranslate" translate="no">ImageData</code></a> object, generates
a histogram.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function computeHistogram(numBins, imgData) {
  const {width, height, data} = imgData;
  const bins = new Array(numBins).fill(0);
  for (let y = 0; y &lt; height; ++y) {
    for (let x = 0; x &lt; width; ++x) {
      const offset = (y * width + x) * 4;

      const r = data[offset + 0] / 255;
      const g = data[offset + 1] / 255;
      const b = data[offset + 2] / 255;
      const v = srgbLuminance(r, g, b);

      const bin = Math.min(numBins - 1, v * numBins) | 0;
      ++bins[bin];
    }
  }
  return histogram;
}
</pre>
<p>As you can see above, we walk through each pixel. We extract r, g, and b from
the image. We compute a luminance value. We convert that to a bin index and
increment that bin’s count.</p>
<p>Once we have that data we can graph it. The main graph function just
draws a line for each bin multiplied by some scale and the height of
the canvas.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  ctx.fillStyle = '#fff';

  for (let x = 0; x &lt; numBins; ++x) {
    const v = histogram[x] * scale * height;
    ctx.fillRect(x, height - v, 1, v);
  }
</pre>
<p>Deciding on a scale appears to be just a personal choice. If you know of a good
formula for choosing a scale leave a comment. 😅 Based on looking around the net
I came up with this formula for scale.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numBins = histogram.length;
  const max = Math.max(...histogram);
  const scale = Math.max(1 / max, 0.2 * numBins / numEntries);
</pre>
<p>Where <code class="notranslate" translate="no">numEntries</code> is the total number of pixels in the image (ie, width * height),
and basically we’re trying to scale so the bin with the most values touches the
top of the graph but, if that bin is too large then we have some ratio that appears
to produce a pleasant graph.</p>
<p>Putting it all together we create a 2D canvas and draw</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function drawHistogram(histogram, numEntries, height = 100) {
  const numBins = histogram.length;
  const max = Math.max(...histogram);
  const scale = Math.max(1 / max, 0.2 * numBins / numEntries);

  const canvas = document.createElement('canvas');
  canvas.width = numBins;
  canvas.height = height;
  document.body.appendChild(canvas);
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#fff';

  for (let x = 0; x &lt; numBins; ++x) {
    const v = histogram[x] * scale * height;
    ctx.fillRect(x, height - v, 1, v);
  }
}
</pre>
<p>Now we need to load an image. We’ll use the code we
wrote in <a href="webgpu-importing-textures.html">the article on loading images</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const imgBitmap = await loadImageBitmap('resources/images/pexels-francesco-ungaro-96938-mid.jpg');
</pre>
<p>We need get the data from an image. To do that we can draw the image
to a 2d canvas and then use <code class="notranslate" translate="no">getImageData</code>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function getImageData(img) {
  const canvas = document.createElement('canvas');

  // make the canvas the same size as the image
  canvas.width = img.naturalWidth;
  canvas.height = img.naturalHeight;

  const ctx = canvas.getContext('2d');
  ctx.drawImage(img, 0, 0);
  return ctx.getImageData(0, 0, canvas.width, canvas.height);
}
</pre>
<p>We’ll also write a function to display an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap"><code class="notranslate" translate="no">ImageBitmap</code></a></p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function showImageBitmap(imageBitmap) {
  const canvas = document.createElement('canvas');
  canvas.width = imageBitmap.width;
  canvas.height = imageBitmap.height;

  const bm = canvas.getContext('bitmaprenderer');
  bm.transferFromImageBitmap(imageBitmap);
  document.body.appendChild(canvas);
}
</pre>
<p>Let’s add some CSS so our image is not displayed too big and
give it a background color so we don’t have to draw one.</p>
<pre class="prettyprint showlinemods notranslate lang-css" translate="no">canvas {
  display: block;
  max-width: 256px;
  border: 1px solid #888;
  background-color: #333;
}
</pre>
<p>And then we just need call the functions we wrote above.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const imgBitmap = await loadImageBitmap('resources/images/pexels-francesco-ungaro-96938-mid.jpg');

  const imgData = getImageData(imgBitmap);
  const numBins = 256;
  const histogram = computeHistogram(numBins, imgData);

  showImageBitmap(imgBitmap);

  const numEntries = imgData.width * imgData.height;
  drawHistogram(histogram, numEntries);
}
</pre>
<p>And here’s the image histogram.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-javascript.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-javascript.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Hopefully it was easy to follow what the JavaScript code is doing.
Let’s convert it to WebGPU!</p>
<h1 id="computing-a-histogram-on-the-gpu"><a id="a-comptuing-a-histogram"></a>Computing a histogram on the GPU</h1>
<p>Let’s start with the most obvious solution. We’ll directly
convert the JavaScript <code class="notranslate" translate="no">computeHistogram</code> function to WGSL.</p>
<p>The luminance function is pretty straight forward. Here the
JavaScript again</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">// Returns a value from 0 to 1 for luminance.
// where r, g, b each go from 0 to 1.
function srgbLuminance(r, g, b) {
  // from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
  return r * 0.2126 +
         g * 0.7152 +
         b * 0.0722;
}
</pre>
<p>and here’s the corresponding WGSL</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">// from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}
</pre>
<p>The <code class="notranslate" translate="no">dot</code> function, which is short for “dot product”, multiplies every element
of one vector with the corresponding element of another vector and then adds
the results. For <code class="notranslate" translate="no">vec3f</code> like above, it could be defined as</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">fn dot(a: vec3f, b: vec3f) -&gt; f32 {
  return a.x * b.x + a.y * b.y + a.z * b.z;
}
</pre>
<p>Which is what we had in JavaScript. The major difference is in WGSL we’ll
pass in the color as a <code class="notranslate" translate="no">vec3f</code> instead of the individual channels.</p>
<p>For the main part of computing a histogram, here’s the JavaScript again</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">function computeHistogram(numBins, imgData) {
  const {width, height, data} = imgData;
  const bins = new Array(numBins).fill(0);
  for (let y = 0; y &lt; height; ++y) {
    for (let x = 0; x &lt; width; ++x) {
      const offset = (y * width + x) * 4;

      const r = data[offset + 0] / 255;
      const g = data[offset + 1] / 255;
      const b = data[offset + 2] / 255;
      const v = srgbLuminance(r, g, b);

      const bin = Math.min(numBins - 1, v * numBins) | 0;
      ++bins[bin];
    }
  }
  return bins;
}
</pre>
<p>Here’s the corresponding WGSL</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">@group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;u32&gt;;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

// from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}

@compute @workgroup_size(1) fn cs() {
  let size = textureDimensions(ourTexture, 0);
  let numBins = f32(arrayLength(&amp;bins));
  let lastBinIndex = u32(numBins - 1);
  for (var y = 0u; y &lt; size.y; y++) {
    for (var x = 0u; x &lt; size.x; x++) {
      let position = vec2u(x, y);
      let color = textureLoad(ourTexture, position, 0);
      let v = srgbLuminance(color.rgb);
      let bin = min(u32(v * numBins), lastBinIndex);
      bins[bin] += 1;
    }
  }
}
</pre>
<p>Above, not much changed. In JavaScript we get the data, width, and height
from <code class="notranslate" translate="no">imgData</code>. In WGSL we get the width and height from the texture by
passing it to the <code class="notranslate" translate="no">textureDimensions</code> function.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">  let size = textureDimensions(ourTexture, 0);
</pre>
<p><code class="notranslate" translate="no">textureDimensions</code> takes a texture and a mip level (the <code class="notranslate" translate="no">0</code> above) and returns the
size of the mip level for that texture.</p>
<p>We loop through all of the pixels of the texture, just like we did in
JavaScript.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">  for (var y = 0u; y &lt; size.y; y++) {
    for (var x = 0u; x &lt; size.x; x++) {
</pre>
<p>We call <code class="notranslate" translate="no">textureLoad</code> to get the color from the texture.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">      let position = vec2u(x, y);
      let color = textureLoad(ourTexture, position, 0);
</pre>
<p><code class="notranslate" translate="no">textureLoad</code> returns a single texel from a single mip level of a texture.
It takes a texture, an <code class="notranslate" translate="no">vec2u</code> texel position, and a mip level
(the <code class="notranslate" translate="no">0</code>).</p>
<p>We compute a luminance value, convert it to a bin index and increment that bin.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">      let position = vec2u(x, y);
      let color = textureLoad(ourTexture, position, 0);
+      let v = srgbLuminance(color.rgb);
+      let bin = min(u32(v * numBins), lastBinIndex);
+      bins[bin] += 1;
</pre>
<p>Now the we have a compute shader, let’s use it</p>
<p>We have our pretty standard initialization code</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
  const device = await adapter?.requestDevice();
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }
</pre>
<p>then we create our shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const module = device.createShaderModule({
    label: 'histogram shader',
    code: `
      @group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;u32&gt;;
      @group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

      // from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
      const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
      fn srgbLuminance(color: vec3f) -&gt; f32 {
        return saturate(dot(color, kSRGBLuminanceFactors));
      }

      @compute @workgroup_size(1) fn cs() {
        let size = textureDimensions(ourTexture, 0);
        let numBins = f32(arrayLength(&amp;bins));
        let lastBinIndex = u32(numBins - 1);
        for (var y = 0u; y &lt; size.y; y++) {
          for (var x = 0u; x &lt; size.x; x++) {
            let position = vec2u(x, y);
            let color = textureLoad(ourTexture, position, 0);
            let v = srgbLuminance(color.rgb);
            let bin = min(u32(v * numBins), lastBinIndex);
            bins[bin] += 1;
          }
        }
      }
    `,
  });
</pre>
<p>We create a compute pipeline to run the shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const pipeline = device.createComputePipeline({
    label: 'histogram',
    layout: 'auto',
    compute: {
      module,
    },
  });
</pre>
<p>After we load the image we need to make a texture and copy the data to it.
We’ll use the <code class="notranslate" translate="no">createTextureFromSource</code> function we wrote in
<a href="webgpu-importing-textures.html#a-create-texture-from-source">the article on loading images into textures</a>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const imgBitmap = await loadImageBitmap('resources/images/pexels-francesco-ungaro-96938-mid.jpg');
  const texture = createTextureFromSource(device, imgBitmap);
</pre>
<p>We need to create a storage buffer for the shader to sum up the color values with</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const numBins = 256;
  const histogramBuffer = device.createBuffer({
    size: numBins * 4, // 256 entries * 4 bytes per (u32)
    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
  });
</pre>
<p>and a buffer to get back the results so we can draw them</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const resultBuffer = device.createBuffer({
    size: histogramBuffer.size,
    usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
  });
</pre>
<p>We need a bind group to pass the texture and histogram buffer to
our pipeline</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const bindGroup = device.createBindGroup({
    label: 'histogram bindGroup',
    layout: pipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: histogramBuffer }},
      { binding: 1, resource: texture.createView() },
    ],
  });
</pre>
<p>We can now setup the commands to run the compute shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const encoder = device.createCommandEncoder({ label: 'histogram encoder' });
  const pass = encoder.beginComputePass();
  pass.setPipeline(pipeline);
  pass.setBindGroup(0, bindGroup);
  pass.dispatchWorkgroups(1);
  pass.end();
</pre>
<p>We need to copy the histogram buffer to the result buffer</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const encoder = device.createCommandEncoder({ label: 'histogram encoder' });
  const pass = encoder.beginComputePass();
  pass.setPipeline(pipeline);
  pass.setBindGroup(0, bindGroup);
  pass.dispatchWorkgroups(1);
  pass.end();

+  encoder.copyBufferToBuffer(histogramBuffer, 0, resultBuffer, 0, resultBuffer.size);
</pre>
<p>and then execute the commands</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const encoder = device.createCommandEncoder({ label: 'histogram encoder' });
  const pass = encoder.beginComputePass();
  pass.setPipeline(pipeline);
  pass.setBindGroup(0, bindGroup);
  pass.dispatchWorkgroups(1);
  pass.end();

  encoder.copyBufferToBuffer(histogramBuffer, 0, resultBuffer, 0, resultBuffer.size);

+  const commandBuffer = encoder.finish();
+  device.queue.submit([commandBuffer]);
</pre>
<p>Finally we can get the data from the result buffer and pass it to our existing functions
to draw the histogram</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  await resultBuffer.mapAsync(GPUMapMode.READ);
  const histogram = new Uint32Array(resultBuffer.getMappedRange());

  showImageBitmap(imgBitmap);

  const numEntries = texture.width * texture.height;
  drawHistogram(histogram, numEntries);

  resultBuffer.unmap();
</pre>
<p>And it should work</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-slow.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-slow.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Timing the results I found <strong>this is about 30x slower than the JavaScript version!!!</strong> 😱😱😱 (YMMV).</p>
<p>What’s up with that? We designed our solution above with a single loop and used
a single workgroup invocation with a size of 1. That means just a single “core” of
the GPU was used to compute the histogram. GPU cores are generally not as fast
as CPU cores. CPU cores have tons of extra circuitry to try to speed them up.
GPUs get their speed from massive parallelization but need to keep their design simpler.
Given our shader above we didn’t take advantage of any parallelization.</p>
<p>Here’s a diagram of what’s happening using our small example texture.</p>
<div class="webgpu_center compute-diagram">
  <div data-diagram="single"></div>
</div>
<blockquote>
<h2 id="diagram-vs-shader-differences">Diagram vs Shader Differences</h2>
<p>These diagrams are not a perfect representation of our shaders</p>
<ul>
<li>They show only 3 bins where as our shader has 256 bins</li>
<li>The code is simplified.</li>
<li>▢ is the texel color</li>
<li>◯ is the bin selection represented as luminance</li>
<li>Many things are abbreviated.
<ul>
<li><code class="notranslate" translate="no">wid</code> = <code class="notranslate" translate="no">workgroup_id</code></li>
<li><code class="notranslate" translate="no">gid</code> = <code class="notranslate" translate="no">global_invocation_id</code></li>
<li><code class="notranslate" translate="no">lid</code> = <code class="notranslate" translate="no">local_invocation_id</code></li>
<li><code class="notranslate" translate="no">ourTex</code> = <code class="notranslate" translate="no">ourTexture</code></li>
<li><code class="notranslate" translate="no">texLoad</code> = <code class="notranslate" translate="no">textureLoad</code></li>
<li>etc…</li>
</ul>
</li>
</ul>
<p>Many of these changes are because there is only so much room to try
to display many details. While this first example uses a single
invocation, as we progress we’ll need to cram more info in less space.
I hope the diagrams aid in understanding rather than make things more
confusing. 😅</p>
</blockquote>
<p>Given a single GPU invocation is slower than a CPU we need to find a way to
parallelize our approach.</p>
<h2 id="optimize---more-invocations">Optimize - More Invocations</h2>
<p>Possibly the easiest and most obvious way to speed this up use to use one
workgroup per pixel. In our code above we have for loop</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">for (y) {
   for (x) {
      ...
   }
}
</pre>
<p>We could change the code use instead use <code class="notranslate" translate="no">global_invocation_id</code>
as an input and then process every single pixel in a separate invocation.</p>
<p>Here’s the needed changes to the shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">@group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;vec4u&gt;;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

// from: https://www.w3.org/WAI/GL/wiki/Relative_luminance
const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}

@compute @workgroup_size(1, 1, 1)
-fn cs() {
+fn cs(@builtin(global_invocation_id) global_invocation_id: vec3u) {
-  let size = textureDimensions(ourTexture, 0);
  let numBins = f32(arrayLength(&amp;bins));
  let lastBinIndex = u32(numBins - 1);
-  for (var y = 0u; y &lt; size.y; y++) {
-    for (var x = 0u; x &lt; size.x; x++) {
-      let position = vec2u(x, y);
+  let position = global_invocation_id.xy;
  let color = textureLoad(ourTexture, position, 0);
  let v = srgbLuminance(color.rgb);
  let bin = min(u32(v * numBins), lastBinIndex);
  bins[bin] += 1;
-    }
-  }
}
</pre>
<p>As you can see, we got rid of the loop, instead we use the
<code class="notranslate" translate="no">@builtin(global_invocation_id)</code> value to make each workgroup
responsible for a single pixel. Theoretically this would mean
all of the pixels could be processed in parallel.
Our image is 2448 × 1505 which is almost 3.7 million pixels so
there are lots of chances for parallelization.</p>
<p>The only other change needed is to actually run one workgroup
per pixel.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const encoder = device.createCommandEncoder({ label: 'histogram encoder' });
  const pass = encoder.beginComputePass();
  pass.setPipeline(pipeline);
  pass.setBindGroup(0, bindGroup);
-  pass.dispatchWorkgroups(1);
+  pass.dispatchWorkgroups(texture.width, texture.height);
  pass.end();
</pre>
<p>Here it is running</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-with-race.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-with-race.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>What’s wrong? Why doesn’t this histogram match the previous histogram
and why don’t the totals match? Note: your computer might get different
results than mine. On mine, this is the histogram from the previous
version on the top, and then 4 results from the new version on the bottom.</p>
<style>
.local-img img {
  border: 1px solid #888;
  margin: 0.5em;
}
</style>
<div class="webgpu_center local-img">
  <div>
      <img src="resources/histogram-slow-luminosity.png" class="histogram-img">
      <div style="text-align: center;">Previous Result</div>
  </div>
  <div>
    <div>
        <img src="resources/histogram-race-01.png" class="histogram-img">
        <img src="resources/histogram-race-02.png" class="histogram-img">
    </div>
    <div>
        <img src="resources/histogram-race-03.png" class="histogram-img">
        <img src="resources/histogram-race-04.png" class="histogram-img">
    </div>
    <div style="text-align: center;">New Results</div>
  </div>
</div>
<p>Our new version gets inconsistent results (at least on my machine).</p>
<p>What happened?</p>
<p>This is a classic <em>race condition</em> like we mentioned in <a href="../webgpu-compute-shaders.html#a-race-conditions">the previous article</a>.</p>
<p>This line in our shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">        bins[bin] += 1;
</pre>
<p>Actually translates to this</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">   let value = bins[bin];
   value = value + 1
   bins[bin] = value;
</pre>
<p>What happens when 2 or more invocations are running in parallel
and happen to have the same <code class="notranslate" translate="no">bin</code> value?</p>
<p>Imagine 2 invocations, where <code class="notranslate" translate="no">bin = 1</code> and
<code class="notranslate" translate="no">bins[1] = 3</code>. If they run in parallel both invocations will load
3 and both invocations will write 4, when the correct answer would be
5.</p>
<div class="webgpu_center data-table">
  <style>
    .local-race th { text-align: center; }
    .local-race td { white-space: pre; }
    .local-race .step { color: #969896; }
  </style>
  <div>
  <table class="local-race">
    <thead>
      <tr><th>Invocation 1</th>
      <th>Invocation 2</th>
    </tr></thead>
    <tbody>
      <tr>
        <td>value = bins[bin]     <span class="step">// loads 3</span></td>
        <td>value = bins[bin]     <span class="step">// loads 3</span></td>
      </tr><tr>
        <td>value = value + 1     <span class="step">// adds 1</span></td>
        <td>value = value + 1     <span class="step">// adds 1</span></td>
      </tr>
      <tr>
        <td>bins[bin] = value     <span class="step">// stores 4</span></td>
        <td>bins[bin] = value     <span class="step">// stores 4</span></td>
      </tr>
    </tbody>
  </table>
  </div>
</div>
<p>You can see the problem visually in the diagram below. You’ll see several invocations
go and fetch the current value in the bin, add one to it, and put it back, each of
oblivious that another invocation is reading and updating the same bin at the same time.</p>
<div class="webgpu_center compute-diagram"><div data-diagram="race"></div></div>
<p>WGSL has special “atomic” instructions to solve this issue. This case we
can use <code class="notranslate" translate="no">atomicAdd</code>. <code class="notranslate" translate="no">atomicAdd</code> makes the addition “atomic” which
means rather than 3 operations, load-&gt;add-&gt;store, all 3 operations
happen at once, “atomically”. This effectively prevents more than
two invocations from updating a value at the same time.</p>
<p>Atomic functions have the requirement that they only work on
<code class="notranslate" translate="no">i32</code> or <code class="notranslate" translate="no">u32</code> and they require to data itself to be of type <code class="notranslate" translate="no">atomic</code>.</p>
<p>Here’s the changes to our shaders</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-@group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;u32&gt;;
+@group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;atomic&lt;u32&gt;&gt;;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}

@compute @workgroup_size(1, 1, 1)
fn cs(@builtin(global_invocation_id) global_invocation_id: vec3u) {
  let numBins = f32(arrayLength(&amp;bins));
  let lastBinIndex = u32(numBins - 1);
  let position = global_invocation_id.xy;
  let color = textureLoad(ourTexture, position, 0);
  let v = srgbLuminance(color.rgb);
  let bin = min(u32(v * numBins), lastBinIndex);
-  bins[bin] += 1;
+  atomicAdd(&amp;bins[bin], 1u);
}
</pre>
<p>With that our compute shader, that uses 1 workgroup invocation per pixel, works!</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-race-fixed.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-race-fixed.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Unfortunately we have a new problem. <code class="notranslate" translate="no">atomicAdd</code> effectively needs to block
other invocations from updating the same bin at the same time. We can see
the issue here. The diagram below shows <code class="notranslate" translate="no">atomicAdd</code> as 3 operations
but when an invocation is doing an <code class="notranslate" translate="no">atomicAdd</code> it “locks the bin”
so that another invocation has to wait until it’s done.</p>
<div class="webgpu_center compute-diagram">
  <div>Two workgroups, one locking the bottom bin, the other blocked from using the same bottom bin</div>
  <div data-diagram="lockedBin"></div>
</div>
<p>In the diagrams, when an invocation is locking a bin it will have a line from the invocation to
the bin in the color of the bin. Invocations that are waiting for that bin to
unlock will have a stop sign 🛑 on them.</p>
<div class="webgpu_center compute-diagram"><div data-diagram="noRace"></div></div>
<p>On my machine, this new version runs at around 4x faster than JavaScript though YMMV.</p>
<h2 id="workgroups">Workgroups</h2>
<p>Can we go faster? As mentioned in <a href="../webgpu-compute-shaders.html">the previous article</a>,
the “workgroup” is the smallest unit of work we can ask the GPU can do. You define the size
of a workgroup in 3 dimensions when you create the shader module,
and then you call <code class="notranslate" translate="no">dispatchWorkgroups</code> to run a bunch of these workgroups.</p>
<p>Workgroups can share internal storage and coordinate that storage with in the workgroup
itself. How could we take advantage of that fact?</p>
<p>Let’s try this. We’ll make our workgroup size, 256x1 (so 256 invocations per workgroup).
We’ll have each invocation work on a 256x1 section of the image. This will mean
we will have <code class="notranslate" translate="no">Math.ceil(texture.width / 256) * texture.height</code> total workgroups.
For our image, which is 2448 × 1505, that would be 10 x 1505 or 15050 workgroups.</p>
<p>We’ll have the invocations within the workgroup use workgroup storage to sum up the
luminance values into bins.</p>
<p>Finally we’ll copy the workgroup memory for the workgroup into its own “chunk”.
That way we will not have to coordinate with other workgroups.
When were done, we’ll run another compute shader to sum up the chunks.</p>
<p>Let’s edit our shader. First we’ll change our <code class="notranslate" translate="no">bins</code> from type <code class="notranslate" translate="no">storage</code> to
type <code class="notranslate" translate="no">workgroup</code> so they’ll only be shared with invocations in the same workgroup.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-@group(0) @binding(0) var&lt;storage, read_write&gt; bins: array&lt;atomic&lt;u32&gt;&gt;;
+const chunkWidth = 256;
+const chunkHeight = 1;
+const chunkSize = chunkWidth * chunkHeight;
+var&lt;workgroup&gt; bins: array&lt;atomic&lt;u32&gt;, chunkSize&gt;;
</pre>
<p>Above we declared some constants so we can easily change them.</p>
<p>Then we need storage for all of our chunks</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">+@group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;u32, chunkSize&gt;&gt;;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}
</pre>
<p>We can use the constants to define our workgroup size</p>
<pre class="prettyprint showlinemods notranslate lang-wsgl" translate="no">-@compute @workgroup_size(1, 1, 1)
+@compute @workgroup_size(chunkWidth, chunkHeight, 1)
</pre>
<p>The main part that increments the bins is very similar to our
previous shader.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">fn cs(@builtin(global_invocation_id) global_invocation_id: vec3u) {
  let size = textureDimensions(ourTexture, 0);
  let position = global_invocation_id.xy;
+  if (all(position &lt; size)) {
-    let numBins = f32(arrayLength(&amp;bins));
+    let numBins = f32(chunkSize);
    let lastBinIndex = u32(numBins - 1);
    let color = textureLoad(ourTexture, position, 0);
    let v = srgbLuminance(color.rgb);
    let bin = min(u32(v * numBins), lastBinIndex);
    atomicAdd(&amp;bins[bin], 1u);
  }
</pre>
<p>Because our chunk size is hardcoded into the shader we don’t want to work on
pixels outside of our texture. So for example if our image was 300 pixels
wide, the first workgroup would work on pixels 0 to 255. The second workgroup
would work on pixels 256 to 511. But we only need work up to pixel 299.
This is what the <code class="notranslate" translate="no">if(all(position &lt; size))</code> does. both <code class="notranslate" translate="no">position</code> and <code class="notranslate" translate="no">size</code> are
<code class="notranslate" translate="no">vec2u</code> and so <code class="notranslate" translate="no">position &lt; size</code> will produce 2 boolean values which is a<code class="notranslate" translate="no">vec2&lt;bool&gt;</code>.
the <code class="notranslate" translate="no">all</code> function returns <code class="notranslate" translate="no">true</code> if all of its inputs are true. So, the code
will only go inside the <code class="notranslate" translate="no">if</code> if <code class="notranslate" translate="no">position.x &lt; size.x</code> and <code class="notranslate" translate="no">position.y &lt; size.y</code>.</p>
<p>As for <code class="notranslate" translate="no">numBins</code>, we have as many bins as we defined for the chunk size.
We can no longer lookup the size because we don’t pass in a buffer for
<code class="notranslate" translate="no">var&lt;workgroup&gt;</code> like we did for <code class="notranslate" translate="no">var&lt;storage&gt;</code>. Its size is defined when
we create the shader module.</p>
<p>Finally the most different part of the shader.</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">  workgroupBarrier();

  let chunksAcross = (size.x + chunkWidth - 1) / chunkWidth;
  let chunkDim = vec2u(chunkWidth, chunkHeight);
  let chunkPos = global_invocation_id.xy / chunkDim;
  let chunk = chunkPos.y * chunksAcross + chunkPos.x;
  let binPos = global_invocation_id.xy % chunkDim;
  let bin = binPos.y * chunkWidth + binPos.x;

  chunks[chunk][bin] = atomicLoad(&amp;bins[bin]);
}
</pre>
<p>This part just has each invocation copy one bin to the corresponding bin
of a specific chunk, the chunk being worked on by this workgroup.
Some of the calculations where are to convert <code class="notranslate" translate="no">global_invocation_id</code>
into both a <code class="notranslate" translate="no">chunkPos</code> and a <code class="notranslate" translate="no">binPos</code>. Those values are effectively
the <code class="notranslate" translate="no">workgroup_id</code> and <code class="notranslate" translate="no">local_invocation_id</code> so we could simplify
this code to</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">  workgroupBarrier();

  let chunksAcross = (size.x + chunkWidth - 1) / chunkWidth;
  let chunk = workgroup_id.y * chunksAcross + workgroup_id.x;
  let bin = local_invocation_id.y * chunkWidth + local_invocation_id.x;

  chunks[chunk][bin] = atomicLoad(&amp;bins[bin]);
}
</pre>
<p>We’d then need to add <code class="notranslate" translate="no">workgroup_id</code> and <code class="notranslate" translate="no">local_invocation_id</code> as inputs
to the shader function</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">-fn cs(@builtin(global_invocation_id) global_invocation_id: vec3u) {
+fn cs(
+  @builtin(global_invocation_id) global_invocation_id: vec3u,
+  @builtin(workgroup_id) workgroup_id: vec3u,
+  @builtin(local_invocation_id) local_invocation_id: vec3u,
+) {

  ...
</pre>
<h2 id="workgroupbarrier"><a id="a-workgroup-barrier"></a>workgroupBarrier</h2>
<p>The <code class="notranslate" translate="no">workgroupBarrier()</code> effectively says "stop here until all invocations
in this workgroup reach this point. We need this because each invocation
is updating different elements in <code class="notranslate" translate="no">bins</code> but afterward, each invocation
will copy just one element from <code class="notranslate" translate="no">bins</code> to the correspond element in
one of the <code class="notranslate" translate="no">chunks</code> so we need to make sure all other invocations are done.</p>
<p>To say this another way, any invocation can <code class="notranslate" translate="no">atomicAdd</code> any element in <code class="notranslate" translate="no">bins</code>
depending on what color it reads from the texture. But, only
<code class="notranslate" translate="no">local_invocation_id</code> = 3,0 will copy <code class="notranslate" translate="no">bin[3]</code> to <code class="notranslate" translate="no">chunks[chunk][3]</code> so it
has to wait for all other invocations to have their chance to update <code class="notranslate" translate="no">bin[3]</code>.</p>
<p>Putting it all together here is our new shader</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">const chunkWidth = 256;
const chunkHeight = 1;
const chunkSize = chunkWidth * chunkHeight;
var&lt;workgroup&gt; bins: array&lt;atomic&lt;u32&gt;, chunkSize&gt;;
@group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;u32, chunkSize&gt;&gt;;
@group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

const kSRGBLuminanceFactors = vec3f(0.2126, 0.7152, 0.0722);
fn srgbLuminance(color: vec3f) -&gt; f32 {
  return saturate(dot(color, kSRGBLuminanceFactors));
}

@compute @workgroup_size(chunkWidth, chunkHeight, 1)
fn cs(
  @builtin(global_invocation_id) global_invocation_id: vec3u,
  @builtin(workgroup_id) workgroup_id: vec3u,
  @builtin(local_invocation_id) local_invocation_id: vec3u,
) {
  let size = textureDimensions(ourTexture, 0);
  let position = global_invocation_id.xy;
  if (all(position &lt; size)) {
    let numBins = f32(chunkSize);
    let lastBinIndex = u32(numBins - 1);
    let color = textureLoad(ourTexture, position, 0);
    let v = srgbLuminance(color.rgb);
    let bin = min(u32(v * numBins), lastBinIndex);
    atomicAdd(&amp;bins[bin], 1u);
  }

  workgroupBarrier();

  let chunksAcross = (size.x + chunkWidth - 1) / chunkWidth;
  let chunk = workgroup_id.y * chunksAcross + workgroup_id.x;
  let bin = local_invocation_id.y * chunkWidth + local_invocation_id.x;

  chunks[chunk][bin] = atomicLoad(&amp;bins[bin]);
}
</pre>
<p>One more thing we could do, rather than hardcode <code class="notranslate" translate="no">chunkWidth</code> and <code class="notranslate" translate="no">chunkHeight</code>
we could pass them in from JavaScript like this</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  const k = {
+    chunkWidth: 256,
+    chunkHeight: 1,
+  };
+  const sharedConstants = Object.entries(k)
+    .map(([k, v]) =&gt; `const ${k} = ${v};`)
+    .join('\n');

  const histogramChunkModule = device.createShaderModule({
    label: 'histogram chunk shader',
    code: `
-      const chunkWidth = 256;
-      const chunkHeight = 1;
+      ${sharedConstants}
      const chunkSize = chunkWidth * chunkHeight;
      var&lt;workgroup&gt; bins: array&lt;atomic&lt;u32&gt;, chunkSize&gt;;
      @group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;u32, chunkSize&gt;&gt;;
      @group(0) @binding(1) var ourTexture: texture_2d&lt;f32&gt;;

      ...
    `,
  });
</pre>
<p>If we ran this shader it would work something like this:</p>
<div class="webgpu_center compute-diagram"><div data-diagram="chunks"></div></div>
<p>Above you can see, each workgroup reads one chunk’s worth of pixels and updates
the bins accordingly. Just like before, if 2 invocations need to update the same
bin one of them will have to wait 🛑. Afterwords they all wait for each other at
the <code class="notranslate" translate="no">workgroupBarrier</code> 🚧. After that each invocation copies the bin it’s
responsible for to the corresponding bin in the chunk it’s working on.</p>
<h2 id="summing-the-chunks">Summing the chunks</h2>
<p>All the pixel luminance values have now been counted but we need to sum up the
bins to get the answer. Let’s write a compute shader to do that. We can do one
invocation per bin. Each invocation will just add up all of the values from
the same bin in each chunk and then write the result to the first chunk</p>
<p>Here’s the code</p>
<pre class="prettyprint showlinemods notranslate lang-wgsl" translate="no">const chunkWidth = 256;
const chunkHeight = 1;
const chunkSize = chunkWidth * chunkHeight;
@group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;u32, chunkSize&gt;&gt;;

@compute @workgroup_size(chunkSize, 1, 1)
fn cs(@builtin(local_invocation_id) local_invocation_id: vec3u) {
  var sum = u32(0);
  let numChunks = arrayLength(&amp;chunks);
  for (var i = 0u; i &lt; numChunks; i++) {
    sum += chunks[i][local_invocation_id.x];
  }
  chunks[0][local_invocation_id.x] = sum;
}
</pre>
<p>And, like before, we can inject the <code class="notranslate" translate="no">chunkWidth</code> and <code class="notranslate" translate="no">chunkHeight</code>.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">const chunkSumModule = device.createShaderModule({
  label: 'chunk sum shader',
  code: `
*    ${sharedConstants}
    const chunkSize = chunkWidth * chunkHeight;
    @group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;u32, chunkSize&gt;&gt;;

    @compute @workgroup_size(chunkSize, 1, 1)

    ...
    }
  `,
});
</pre>
<p>This shader will effectively work like this</p>
<div class="webgpu_center compute-diagram"><div data-diagram="sum"></div></div>
<p>Now that we have these 2 shaders, let’s update the code to use them.
We need to create pipelines for both shaders</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const pipeline = device.createComputePipeline({
-    label: 'histogram',
-    layout: 'auto',
-    compute: {
-      module,
--    },
-  });

+  const histogramChunkPipeline = device.createComputePipeline({
+    label: 'histogram',
+    layout: 'auto',
+    compute: {
+      module: histogramChunkModule,
++    },
+  });
+
+  const chunkSumPipeline = device.createComputePipeline({
+    label: 'chunk sum',
+    layout: 'auto',
+    compute: {
+      module: chunkSumModule,
++    },
+  });
</pre>
<p>We need to create a storage buffer large enough for all our chunks so we
compute how many chunks we need to cover the entire image.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const imgBitmap = await loadImageBitmap('resources/images/pexels-francesco-ungaro-96938-mid.jpg');
  const texture = createTextureFromSource(device, imgBitmap);

-  const numBins = 256;
-  const histogramBuffer = device.createBuffer({
-    size: numBins * 4, // 256 entries * 4 bytes per (u32)
-    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
-  });
+  const chunkSize = k.chunkWidth * k.chunkHeight;
+  const chunksAcross = Math.ceil(texture.width / k.chunkWidth);
+  const chunksDown = Math.ceil(texture.height / k.chunkHeight);
+  const numChunks = chunksAcross * chunksDown;
+  const chunksBuffer = device.createBuffer({
+    size: numChunks * chunkSize * 4, // 4 bytes per (u32)
+    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
+  });
</pre>
<p>We still need our result buffer to read the result but it’s no longer
the same size as the previous buffer</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const resultBuffer = device.createBuffer({
-    size: histogramBuffer.size,
+    size: chunkSize * 4,  // 4 bytes per (u32)
    usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
  });
</pre>
<p>We need a bindGroup for each pass. One to pass the texture and chunks
to the first shader and another to pass the chunks to the second shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  const bindGroup = device.createBindGroup({
+  const histogramBindGroup = device.createBindGroup({
    label: 'histogram bindGroup',
    layout: histogramChunkPipeline.getBindGroupLayout(0),
    entries: [
-      { binding: 0, resource: { buffer: histogramBuffer }},
+      { binding: 0, resource: { buffer: chunksBuffer }},
      { binding: 1, resource: texture.createView() },
    ],
  });

  const chunkSumBindGroup = device.createBindGroup({
    label: 'sum bindGroup',
    layout: chunkSumPipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: chunksBuffer }},
    ],
  });
</pre>
<p>Finally we can run our shaders. First, the part that reads
the pixels and sorts them into bins, we dispatch one workgroup for each chunk.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">  const encoder = device.createCommandEncoder({ label: 'histogram encoder' });
  const pass = encoder.beginComputePass();

+  // create a histogram for each area
-  pass.setPipeline(pipeline);
-  pass.setBindGroup(0, bindGroup);
-  pass.dispatchWorkgroups(texture.width, texture.height);
+  pass.setPipeline(histogramChunkPipeline);
+  pass.setBindGroup(0, histogramBindGroup);
+  pass.dispatchWorkgroups(chunksAcross, chunksDown);
</pre>
<p>Then we need to run the shader that sums up the chunks. It’s just 1 workgroup
which uses 1 invocation per bin (256 invocations).</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">+  // sum the areas
+  pass.setPipeline(chunkSumPipeline);
+  pass.setBindGroup(0, chunkSumBindGroup);
+  pass.dispatchWorkgroups(1);
</pre>
<p>The rest of the code is the same.</p>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-optimized.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-optimized.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Timing this on my machine I was happy to see the first shader runs in 0.2ms!
It read the entire image and filled out all the chunks lickety-split!</p>
<p>Unfortunately the part that sums up the chunks took much longer. 11ms
That’s SLOWER than our previous shader!</p>
<p>On a different machine the previous solution was was 4.4ms and this new
was 1.7ms so it wasn’t a complete loss.</p>
<p>Can we do better?</p>
<h2 id="reduce">Reduce</h2>
<p>The solution above used a single workgroup. Even though it has 256 invocations
a modern GPU has 1000s of cores and we’re only use 256 of them.</p>
<p>One technique we could try is sometimes called reducing. We will have each workgroup
only add 2 chunks, writing the result to the first of those 2 chunks. This way, if we
have 1000 chunks we can use 500 workgroups. That’s far more parallelization.
We’ll repeat the process 500 chunks reduced into 250, 250 -&gt; 125, 125 -&gt; 63 etc…
until we’ve reduced to 1 chunk.</p>
<div class="webgpu_center compute-diagram"><div data-diagram="reduceDiagram"></div></div>
<p>We can use just one shader and we just have to pass in a stride to reduce the chunks
down to one chunk. The stride is the number of chunks we need to advance to get to the
second chunk we’re summing with. If we pass in a stride of 1 then we’ll sum adjacent
chunks. If we pass in a stride of 2 then we sum every other chunk. etc…</p>
<p>Here are the changes to our shader</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">const chunkSumModule = device.createShaderModule({
  label: 'chunk sum shader',
  code: `
    ${sharedConstants}
    const chunkSize = chunkWidth * chunkHeight;

+    struct Uniforms {
+      stride: u32,
+    };

    @group(0) @binding(0) var&lt;storage, read_write&gt; chunks: array&lt;array&lt;vec4u, chunkSize&gt;&gt;;
+    @group(0) @binding(1) var&lt;uniform&gt; uni: Uniforms;

    @compute @workgroup_size(chunkSize, 1, 1) fn cs(
      @builtin(local_invocation_id) local_invocation_id: vec3u,
      @builtin(workgroup_id) workgroup_id: vec3u,
    ) {
-      var sum = u32(0);
-      let numChunks = arrayLength(&amp;chunks);
-      for (var i = 0u; i &lt; numChunks; i++) {
-        sum += chunks[i][local_invocation_id.x];
-      }
-      chunks[0][local_invocation_id.x] = sum;
+      let chunk0 = workgroup_id.x * uni.stride * 2;
+      let chunk1 = chunk0 + uni.stride;
+
+      let sum = chunks[chunk0][local_invocation_id.x] +
+                chunks[chunk1][local_invocation_id.x];
+      chunks[chunk0][local_invocation_id.x] = sum;
    }
  `,
});
</pre>
<p>You can see above, we compute a <code class="notranslate" translate="no">chunk0</code> and <code class="notranslate" translate="no">chunk1</code> based on the <code class="notranslate" translate="no">workgroup_id.x</code>
and <code class="notranslate" translate="no">uni.stride</code> that we pass in as a uniform. We then just add the 2 bins from
the 2 chunks and store them back the first.</p>
<p>If we run it with the correct number of invocations and stride settings it will
operate something like this. Note: the darkened chunks are chunks that are no
longer used.</p>
<div class="webgpu_center compute-diagram"><div data-diagram="reduce"></div></div>
<p>To make this new one work we need to add a uniform buffer for each stride value
as well as a bindGroup.</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">const sumBindGroups = [];
const numSteps = Math.ceil(Math.log2(numChunks));
for (let i = 0; i &lt; numSteps; ++i) {
  const stride = 2 ** i;
  const uniformBuffer = device.createBuffer({
    size: 4,
    usage: GPUBufferUsage.UNIFORM,
    mappedAtCreation: true,
  });
  new Uint32Array(uniformBuffer.getMappedRange()).set([stride]);
  uniformBuffer.unmap();

  const chunkSumBindGroup = device.createBindGroup({
    layout: chunkSumPipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: chunksBuffer }},
      { binding: 1, resource: { buffer: uniformBuffer }},
    ],
  });
  sumBindGroups.push(chunkSumBindGroup);
}
</pre>
<p>Then we just need to call these with the correct number of
dispatches until we’ve reduced things to 1 chunk</p>
<pre class="prettyprint showlinemods notranslate lang-js" translate="no">-  // sum the areas
-  pass.setPipeline(chunkSumPipeline);
-  pass.setBindGroup(0, chunkSumBindGroup);
-  pass.dispatchWorkgroups(1);
+  // reduce the chunks
+  const pass = encoder.beginComputePass();
+  pass.setPipeline(chunkSumPipeline);
+  let chunksLeft = numChunks;
+  sumBindGroups.forEach(bindGroup =&gt; {
+    pass.setBindGroup(0, bindGroup);
+    const dispatchCount = Math.floor(chunksLeft / 2);
+    chunksLeft -= dispatchCount;
+    pass.dispatchWorkgroups(dispatchCount);
+  });
</pre>
<p></p><div class="webgpu_example_container">
  <div><iframe class="webgpu_example" style=" " src="/webgpu/resources/editor.html?url=/webgpu/lessons/..%2Fwebgpu-compute-shaders-histogram-optimized-more.html"></iframe></div>
  <a class="webgpu_center" href="/webgpu/lessons/../webgpu-compute-shaders-histogram-optimized-more.html" target="_blank">click here to open in a separate window</a>
</div>

<p></p>
<p>Timing this version I got under 1ms on both machines I tested! 🎉🚀</p>
<p>Here are some timings from various machines</p>
<div class="webgpu_center data-table">
  <div data-diagram="timings"></div>
</div>
<p>There may be a faster way to compute a histogram. It might also be better
to try different chunk sizes. Maybe 16x16 is better than 256x1.
Also, at some point WebGPU will likely support <em>subgroups</em> which is
yet another whole topic and an area for even more optimization.</p>
<p>For now I hope these examples have given you some ideas on how to write
and optimize a compute shader. The takeaways are:</p>
<ul>
<li>
<p>Find a way to use all of the parallelization the GPU provides</p>
</li>
<li>
<p>Be aware of race conditions</p>
</li>
<li>
<p>Use <code class="notranslate" translate="no">var&lt;workgroup&gt;</code> to create storage shared between all invocations of a workgroup</p>
</li>
<li>
<p>Try to design algorithms that require less coordination between invocations.</p>
</li>
<li>
<p>When coordination is required, atomic operations can be a solution as well
as <code class="notranslate" translate="no">workgroupBarrier</code>.</p>
<p>We did so-so on this front. When computing our chunks in workgroup memory
we still have conflicts which we resolved via <code class="notranslate" translate="no">atomicAdd</code> but we have no
conflicts when copying from the <code class="notranslate" translate="no">bins</code> in the workgroup into the <code class="notranslate" translate="no">chunks</code>
and we have no conflicts when we reduce the <code class="notranslate" translate="no">chunks</code> to one final result</p>
</li>
</ul>
<p>Maybe one more</p>
<ul>
<li>
<p>Don’t assume the GPU is fast.</p>
<p>We learned individual cores of a GPU are not so fast. All the speed comes
from parallelization so we need to design parallel solutions.</p>
</li>
</ul>
<p>In <a href="webgpu-compute-shaders-histogram-part-2.html">the next article</a> we’ll
tweak these a little as well as change it so we
graph the results using the GPU instead of pulling them back to JavaScript.
We’ll also try some real time video adjustments based on having created
an image histogram.</p>
<!-- keep this at the bottom of the article -->
<link rel="stylesheet" href="webgpu-compute-shaders-histogram.css">
<script type="module" src="webgpu-compute-shaders-histogram.js"></script>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgpu/lessons/webgpu-compute-shaders-histogram.html" selected="">English
    </option><option value="/webgpu/lessons/es/webgpu-compute-shaders-histogram.html">Spanish
    </option><option value="/webgpu/lessons/ja/webgpu-compute-shaders-histogram.html">日本語
    </option><option value="/webgpu/lessons/ko/webgpu-compute-shaders-histogram.html">한국어
    </option><option value="/webgpu/lessons/ru/webgpu-compute-shaders-histogram.html">Русский
    </option><option value="/webgpu/lessons/tr/webgpu-compute-shaders-histogram.html">Türkçe
    </option><option value="/webgpu/lessons/uk/webgpu-compute-shaders-histogram.html">Українська
    </option><option value="/webgpu/lessons/zh_cn/webgpu-compute-shaders-histogram.html">简体中文
</option></select>


        <div id="toc">
          <ul>  <li>Basics</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgpu/lessons/webgpu-inter-stage-variables.html">Inter-stage Variables</a></li>
<li><a href="/webgpu/lessons/webgpu-uniforms.html">Uniforms</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-buffers.html">Storage Buffers</a></li>
<li><a href="/webgpu/lessons/webgpu-vertex-buffers.html">Vertex Buffers</a></li>
  <li>Textures</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-textures.html">Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-importing-textures.html">Loading Images</a></li>
<li><a href="/webgpu/lessons/webgpu-textures-external-video.html">Using Video</a></li>
<li><a href="/webgpu/lessons/webgpu-cube-maps.html">Cube Maps</a></li>
<li><a href="/webgpu/lessons/webgpu-storage-textures.html">Storage Textures</a></li>
<li><a href="/webgpu/lessons/webgpu-multisampling.html">Multisampling / MSAA</a></li>
        </ul>
<li><a href="/webgpu/lessons/webgpu-constants.html">Constants</a></li>
<li><a href="/webgpu/lessons/webgpu-memory-layout.html">Data Memory Layout</a></li>
<li><a href="/webgpu/lessons/webgpu-transparency.html">Transparency and Blending</a></li>
<li><a href="/webgpu/lessons/webgpu-bind-group-layouts.html">Bind Group Layouts</a></li>
<li><a href="/webgpu/lessons/webgpu-copying-data.html">Copying Data</a></li>
<li><a href="/webgpu/lessons/webgpu-limits-and-features.html">Optional Features and Limits</a></li>
<li><a href="/webgpu/lessons/webgpu-timing.html">Timing Performance</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl.html">WGSL</a></li>
<li><a href="/webgpu/lessons/webgpu-how-it-works.html">How It Works</a></li>
<li><a href="/webgpu/lessons/webgpu-compatibility-mode.html">Compatibility Mode</a></li>
        </ul>
  <li>3D Math</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-translation.html">Translation</a></li>
<li><a href="/webgpu/lessons/webgpu-rotation.html">Rotation</a></li>
<li><a href="/webgpu/lessons/webgpu-scale.html">Scale</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-math.html">Matrix Math</a></li>
<li><a href="/webgpu/lessons/webgpu-orthographic-projection.html">Orthographic Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-perspective-projection.html">Perspective Projection</a></li>
<li><a href="/webgpu/lessons/webgpu-cameras.html">Cameras</a></li>
<li><a href="/webgpu/lessons/webgpu-matrix-stacks.html">Matrix Stacks</a></li>
<li><a href="/webgpu/lessons/webgpu-scene-graphs.html">Scene Graphs</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgpu/lessons/webgpu-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-large-triangle-to-cover-clip-space.html">Large Clip Space Triangle</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-environment-maps.html">Environment maps</a></li>
<li><a href="/webgpu/lessons/webgpu-skybox.html">Skyboxes</a></li>
        </ul>
        </ul>
  <li>Compute Shaders</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-compute-shaders.html">Compute Shader Basics</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram.html">Image Histogram</a></li>
<li><a href="/webgpu/lessons/webgpu-compute-shaders-histogram-part-2.html">Image Histogram Part 2</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgpu/lessons/webgpu-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgpu/lessons/webgpu-multiple-canvases.html">Multiple Canvases</a></li>
<li><a href="/webgpu/lessons/webgpu-points.html">Points</a></li>
<li><a href="/webgpu/lessons/webgpu-from-webgl.html">WebGPU from WebGL</a></li>
<li><a href="/webgpu/lessons/webgpu-optimization.html">Speed and Optimization</a></li>
<li><a href="/webgpu/lessons/webgpu-debugging.html">Debugging and Errors</a></li>
<li><a href="/webgpu/lessons/webgpu-resources.html">Resources / References</a></li>
<li><a href="/webgpu/lessons/webgpu-wgsl-function-reference.html">WGSL Function Reference</a></li>
<li><a href="/webgpu/lessons/resources/wgsl-offset-computer.html">WGSL Offset Computer</a></li>
        </ul></ul>
<ul>
  <li><a href="https://github.com/webgpu/webgpufundamentals">github</a></li>
  <li><a href="https://google.github.io/tour-of-wgsl/">Tour of WGSL</a></li>
  <li><a href="https://gpuweb.github.io/types/">WebGPU API Reference</a></li>
  <li><a href="https://www.w3.org/TR/webgpu/">WebGPU Spec</a></li>
  <li><a href="https://www.w3.org/TR/WGSL/">WGSL Spec</a></li>
  <li><a href="https://webgpureport.org">WebGPUReport.org</a></li>
  <li><a href="https://web3dsurvey.com/webgpu">Web3DSurvey.com</a></li>
</ul>

        </div>
    </div>
    <div class="lesson-comments">
        
<div>Questions? <a href="http://stackoverflow.com/questions/tagged/webgpu">Ask on stackoverflow</a>.</div>
<div>
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=suggested+topic&amp;template=suggest-topic.md&amp;title=%5BSUGGESTION%5D">Suggestion</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=&amp;template=request.md&amp;title=">Request</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Issue</a>?
   <a href="https://github.com/webgpu/webgpufundamentals/issues/new?assignees=&amp;labels=bug+%2F+issue&amp;template=bug-issue-report.md&amp;title=">Bug</a>?
</div>
  

        <div id="disqus_thread"></div>
        <script>
            var disqus_config = function () {
              this.page.url = `${window.location.origin}${window.location.pathname}`;
              this.page.identifier = `WebGPU Compute Shaders - Image Histogram`;
            };
            (function() { // DON'T EDIT BELOW THIS LINE
                if (window.location.hostname.indexOf("webgpufundamentals.org") < 0) {
                    return;
                }
                var d = document, s = d.createElement('script');
                s.src = 'https://webgpufundamentals-org.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgpufundamentals",
};
</script>
<script src="/contributors.js"></script>
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="/3rdparty/jquery-3.3.1.slim.min.js"></script>
<script src="/webgpu/lessons/resources/prettify.js"></script>
<script src="/webgpu/lessons/resources/lesson.js" type="module"></script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-92BFT5PE4H"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-92BFT5PE4H');
</script>






</body></html>